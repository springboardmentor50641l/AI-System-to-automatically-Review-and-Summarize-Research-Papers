This section defines the purpose and procedure outlined in Fig. 1. It
initiates with an annotated dataset and is based on Scikit-Learn, a
Python machine learning library, very famous for compatibility with
Python and its ease of use.


The system reads data from a TSV-formatted file. After that, data is
put through a pre-processing stage to clean and prepare the data so that
machine learning algorithms can act on it. Since machine learning
algorithms require numeric input, textual data gets converted to a
suitable format using the "count-vectorizer" Scikit -Learn module,



yielding a matrix of token counts. Finally, the data is split randomly
with 60% being used to train the classifier and 40% is used to test the
classifier's accuracy.


Two phases of experimentation are performed: N-grams (Length 1-3)
features are extracted, and an accuracy measure using both accuracy
score and F-score is computed in the first phase. Phase 2 incorporated
several additional features: stop words and punctuation removal,
lemmatization along with the N-grams-based feature, all of which
serve the purpose of minimizing noise and complexity, thus
maximizing the accuracy of the system. The experiments are repeated
for thirty iterations with their average result taken into account, making
up a total of six experiments where accuracies are computed for both
phases. Feature engineering is vastly important for contextual
representation, especially N-grams features (Length 1-3). Several
features, like stop and punctuation removal, were incorporated to
reduce noise and increase complexity throughout the data set. In
training and testing the classifiers, we used machine learning
algorithms for sentiment analysis. The training part discussed was
about the parameter selections and any tunings performed to optimize
classifier performance. Evaluation metrics beyond F-score and
accuracy were used in the assessments to provide a complete picture
of the classifier's effectiveness.


The procedure of splitting of data for training and testing purposes was
elaborated upon, emphasizing the randomness of the process to get a
representative sample. Thirty iterations were taken on each experiment
to substantiate the results. The experimental design was justified,
pointing to the chosen features and how they influence sentiment
accuracy. Control variables and constant variables were considered as
part of the research, providing an almost constant environment for the
experiment.


Feature engineering was crucial, wherein N-grams features (Length 13) were selected for easy contextual information extraction. To reduce
noise while building vocabulary complexity, features like removing
stop words and punctuation were identified. Machine learning
algorithms used for sentiment analysis were classified and tested in
training. It was specified how the training was done, what parameters
were put into use, and what tuning was performed to enhance classifier
performance. Besides F-score and accuracy, a few other metric
evaluations were incorporated in order to provide a holistic assessment
of the classifier's effectiveness.


Where applicable, some references were made to statistical analysis to
endorse the significance of observed differences or improvements in
correctness. Information on the computational resources used in the
conduct of the experiments was mentioned for good faith in the
experimental configuration.



ISBN: 979-8-3503-5681-6/24/$31.00©2024 IEEE
571


Authorized licensed use limited to: VIT University. Downloaded on August 17,2025 at 14:21:44 UTC from IEEE Xplore. Restrictions apply.


2024 1 [st] International Conference on Advances in Computing, Communication and Networking (ICAC2N)


B. Lemmatization


The process of lemmatization was used to overcome the
problem of ambiguity in homographic words and in inflectional
word forms. Some examples of inflected forms of the word
"Talk" are "Talking," "Talks," and "Talked." We have chosen
lemmatization over stemming because coming up with rules for
their use is not easy. Both have basically both pros and cons,
but stemming is more suited for shorter retrieval lists, while our
application, which is working with huge batches of input lists,
found lemmatization to be much more effective. Differences in
how derivations are actually represented have not inhibited
lemmatization from achieving any normalizing function upon
inflected forms of the word.


C. Stop Words and Punctuation


In English texts, there is an abundance of meaningless and
non-informative words known as stop words. The stop-word
removal technique was adopted to rid the data of certain
decorations that would otherwise interfere in classification and
increase the size of the data set. This idea is in line with other
studies that have suggested the removal of stop words to reduce
data dimensions.


**3.3 ALGORITHMS USED**


This work attempted to utilize six machine learning techniques for the
task of sentiment analysis. The modelling of all techniques is briefly
discussed below.


Classification:


3.1 **EVALUATION METRICS**


Above all, an assessment of any research is a statement on its
standing and quality. This chapter briefly describes the metrics
that this study utilizes to assess the performance of sentiment
analysis systems. Indeed, performance is gauged through the
computation of classification accuracy F-score and accuracy
score for sentiment analysis systems.


A False Positive has been defined as a type-1 error or false
positive case, while a False Negative has been defined as a type2 error or false negative case. The common metric is F-score,
and it provides an overall indication of performance by acting
as a harmonic mean of precision and recall.


**3.2 DATA PRE-PROCESSING**


The corpus for sentiment analysis classification was created by
preparing a dataset made up of 1500 citation sentences labeled
positively, negatively, and neutrally. The classifier was then
trained on some of these sentences, which had been selected
randomly in a ratio of 60:40 in some arbitrary way, after
cleaning the data thoroughly to enhance the accuracy of the
system and after the application of predefined rules.


A .Features Selection


To build a successful sentiment analysis system, various
features have been used by different machine learning model
inputs. Such features include lemmatisms, n-grams, stop words,
and term-document frequency to assess the accuracy of the
classifier, with the complete evaluation results presented later.



Once the pre-processing and feature selection was done, a plethora of
text classifiers, suggested in the literature, can be applied. In this paper,
six discrimination algorithms were employed:


i. Naïve-Bayes:


Naïve-Bayes is a commonly and widely used classification algorithm
known for its simplicity and efficacy. The classifier works on the basis
of Bayes' theorem, using the concept of probabilities on the level of
classification. Naïve-Bayes is very favorable toward text classification
because it requires smaller data sets for training. These steps include
the removal of numeric, foreign words, HTML tags, and special
symbols such that a set of words remain afresh. This pre-processing
gives the pair word-category to the training samples.


Consider a word 'y' from the test set (unlabeled word set) and a window
of n-words (x1, x2, …xn ) from a document. Based on the Bayes
theorem, the conditional probability of 'y' based on n-words from the
training set may be determined. Because of this simplicity and the
requirement for little data to train, it has been proven to be an effective
technique in text classification.


The conditional probability of given data point ‘y’ to be in the category
of n-words from training set is given by:


���������������������������������������
��������


ii. Support Vector Machine (SVM):


In machine learning, SVMs may be considered as a strong supervised
learning algorithm that has yielded substantial improvements in
various tasks of discourse, especially sentiment analysis. SVM
classifiers are strong at distinguishing complex data, giving excellent
predictions under increasing complexities of data.


iii. Decision Tree:



ISBN: 979-8-3503-5681-6/24/$31.00©2024 IEEE
572


Authorized licensed use limited to: VIT University. Downloaded on August 17,2025 at 14:21:44 UTC from IEEE Xplore. Restrictions apply.


2024 1 [st] International Conference on Advances in Computing, Communication and Networking (ICAC2N)



The Decision Tree classifier is commonly used for text classification
due to its fascinating way of creating classification rules. NLP
researchers are drawn to it because there are just stimulated using data
from the dataset to form decision trees. The advantages of decision
trees include creating understandable prediction rules, constructing the
shortest and fastest tree, and requiring only as many features as there
are to classify all the data. Decision trees, however, face challenges
such as overfitting, testing one attribute at a time before decisionmaking, and inability to cope with numerical attributes and missing
values. Hyperparameters of Decision Trees including max_features,
min_sample_split, and max_depth, etc., are optimized to reduce
overfitting.


iv. Random Forest:


Random Forest, an all-round classifier, is noticed for its efficiency and
discriminative classification capabilities. The performance of this
algorithm stands out against other classifiers, marking it as an
interesting and efficient choice.


v. K-th Nearest Neighbour (KNN):


K-th Nearest Neighbour (KNN) is noted as a simple and effective
classifier, a "lazy learner," because there is no real training phase, save
for keeping all training examples in memory. KNN is very efficient,
but during the storing of training values, much memory space is
required. The algorithm identifies a given value of K for the K nearest
neighbours of an unobserved data point and assigns to it the class of
the majority class of the K neighbours.


**3.4 FEATURES USED**


Word clouds or tag clouds are the graphical representations of how
frequently words are used, giving prominence to the words, which
come frequently in a particular source text. The visualization shows
the words more prominently in the comments as they occur more
frequently, whereby the size of each word corresponds to its frequency.
This visualization offers evaluators some value in exploratory text
analysis, capturing the frequent words in a set of interviews,
documents, or such text. Word clouds can also successfully
communicate key points or themes during reporting.


**4.** **RESULT**


There were various machine learning algorithms employed for
classification and the efficiency of the systems was assessed
accordingly with the help of the evaluation metrics. A thorough
description of the experimental results obtained with the written
metrics is shown in Tables I and II.


Logistic Regression would emerge as the best overall performer in
micro-average, even without the addition of extra features. Use of
unigrams greatly enhanced the performance of Logistic Regression
and Decision Trees. Furthermore, the combination of unigrams with
other features greatly enhances Naive Bayes, k-Nearest Neighbors, and
Random Forest performance. Decision Trees quite consistently
outperform other models in reference to unigrams, bigrams, and
trigrams.


Logistic Regression (LR) demonstrates superior performance in the
micro-average, even without the incorporation of additional features.
The performance of both Logistic Regression (LR) and Decision Trees
(DT) is improved when unigrams are introduced. Beyond that, when
unigrams are combined with other features, Naive Bayes (NB), kNearest Neighbors (KNN), and Random Forest (RF) show significant
performance increases. DT performs best within unigrams, bigrams,
and trigrams.



LR performs admirably with unigrams, while k-th nearest neighbour
does similarly with n-grams, В knowing it to have been remarkable in
full instead with other features in addition. Similarly, it is noticed that
RF works just like KNN, with optimal results under feature expansion.


LR shall be gratified for a lion's share of the credit when it comes to
fruitful unigrams-only performance. The same goes awry for the k-th
nearest neighbour's expectations in this n-grams-game-when other
features come in handy-by giving RF a run for KNN's money.


From every angle, it appears that best performance is yielded on using
unigrams, bigrams, and trigrams alone without feature enhancements,
given that unigrams rank the highest. An examination of Table II
shows SVM, LR, and RF among the most productive yielding the
highest accuracy scores.