[1] M. Abadi, A. Agarwal, P. Barham, E. Brevdo, Z. Chen,
C. Citro, G. S. Corrado, A. Davis, J. Dean, M. Devin, et al.
Tensorflow: Large-scale machine learning on heterogeneous
distributed systems. _arXiv preprint arXiv:1603.04467_, 2016.
4
[2] H. Bagherinezhad, M. Rastegari, and A. Farhadi. Lcnn:
Lookup-based convolutional neural network. _arXiv preprint_
_arXiv:1611.06473_, 2016. 2
[3] F. Chollet. Xception: Deep learning with depthwise separable convolutions. _arXiv preprint arXiv:1610.02357_, 2016. 1,
2, 3, 4, 5, 6
[4] J. Deng, W. Dong, R. Socher, L.-J. Li, K. Li, and L. FeiFei. Imagenet: A large-scale hierarchical image database.
In _Computer Vision and Pattern Recognition, 2009. CVPR_
_2009. IEEE Conference on_, pages 248–255. IEEE, 2009. 1,
4
[5] R. Girshick, J. Donahue, T. Darrell, and J. Malik. Rich feature hierarchies for accurate object detection and semantic
segmentation. In _Proceedings of the IEEE conference on_
_computer vision and pattern recognition_, pages 580–587,
2014. 1
[6] S. Han, H. Mao, and W. J. Dally. Deep compression: Compressing deep neural networks with pruning,
trained quantization and huffman coding. _arXiv preprint_
_arXiv:1510.00149_, 2015. 2
[7] S. Han, J. Pool, J. Tran, and W. Dally. Learning both weights
and connections for efficient neural network. In _Advances in_
_Neural Information Processing Systems_, pages 1135–1143,
2015. 2
[8] K. He and J. Sun. Convolutional neural networks at constrained time cost. In _Proceedings of the IEEE Conference_
_on Computer Vision and Pattern Recognition_, pages 5353–
5360, 2015. 1
[9] K. He, X. Zhang, S. Ren, and J. Sun. Deep residual learning for image recognition. In _Proceedings of the IEEE Con-_
_ference on Computer Vision and Pattern Recognition_, pages
770–778, 2016. 1, 2, 3, 4, 5, 6
[10] K. He, X. Zhang, S. Ren, and J. Sun. Identity mappings in
deep residual networks. In _European Conference on Com-_
_puter Vision_, pages 630–645. Springer, 2016. 1, 2
[11] G. Hinton, O. Vinyals, and J. Dean. Distilling the knowledge
in a neural network. _arXiv preprint arXiv:1503.02531_, 2015.
2
[12] A. G. Howard, M. Zhu, B. Chen, D. Kalenichenko, W. Wang,
T. Weyand, M. Andreetto, and H. Adam. Mobilenets: Efficient convolutional neural networks for mobile vision applications. _arXiv preprint arXiv:1704.04861_, 2017. 1, 2, 3, 5,
6, 7
[13] J. Hu, L. Shen, and G. Sun. Squeeze-and-excitation networks. _arXiv preprint arXiv:1709.01507_, 2017. 1, 6, 7
[14] F. N. Iandola, S. Han, M. W. Moskewicz, K. Ashraf, W. J.
Dally, and K. Keutzer. Squeezenet: Alexnet-level accuracy
with 50x fewer parameters and¡ 0.5 mb model size. _arXiv_
_preprint arXiv:1602.07360_, 2016. 1, 7, 8
[15] S. Ioffe and C. Szegedy. Batch normalization: Accelerating
deep network training by reducing internal covariate shift.
_arXiv preprint arXiv:1502.03167_, 2015. 3, 5
[16] M. Jaderberg, A. Vedaldi, and A. Zisserman. Speeding up
convolutional neural networks with low rank expansions.
_arXiv preprint arXiv:1405.3866_, 2014. 1, 2, 8
[17] Y. Jia, E. Shelhamer, J. Donahue, S. Karayev, J. Long, R. Girshick, S. Guadarrama, and T. Darrell. Caffe: Convolutional architecture for fast feature embedding. In _Proceed-_
_ings of the 22nd ACM international conference on Multime-_
_dia_, pages 675–678. ACM, 2014. 7
[18] J. Jin, A. Dundar, and E. Culurciello. Flattened convolutional
neural networks for feedforward acceleration. _arXiv preprint_
_arXiv:1412.5474_, 2014. 2
[19] K.-H. Kim, S. Hong, B. Roh, Y. Cheon, and M. Park. Pvanet:
Deep but lightweight neural networks for real-time object detection. _arXiv preprint arXiv:1608.08021_, 2016. 6
[20] A. Krizhevsky. cuda-convnet: High-performance c++/cuda
implementation of convolutional neural networks, 2012. 2
[21] A. Krizhevsky, I. Sutskever, and G. E. Hinton. Imagenet
classification with deep convolutional neural networks. In
_Advances in neural information processing systems_, pages
1097–1105, 2012. 1, 2, 7, 8
[22] V. Lebedev, Y. Ganin, M. Rakhuba, I. Oseledets, and
V. Lempitsky. Speeding-up convolutional neural networks using fine-tuned cp-decomposition. _arXiv preprint_
_arXiv:1412.6553_, 2014. 1, 2, 8
[23] T.-Y. Lin, M. Maire, S. Belongie, J. Hays, P. Perona, D. Ramanan, P. Doll´ar, and C. L. Zitnick. Microsoft coco: Common objects in context. In _European Conference on Com-_
_puter Vision_, pages 740–755. Springer, 2014. 1, 7
[24] J. Long, E. Shelhamer, and T. Darrell. Fully convolutional
networks for semantic segmentation. In _Proceedings of the_
_IEEE Conference on Computer Vision and Pattern Recogni-_
_tion_, pages 3431–3440, 2015. 1
[25] M. Mathieu, M. Henaff, and Y. LeCun. Fast training
of convolutional networks through ffts. _arXiv preprint_
_arXiv:1312.5851_, 2013. 2
[26] P. Ramachandran, B. Zoph, and Q. V. Le. Swish: a self-gated
activation function. _arXiv preprint arXiv:1710.05941_, 2017.
7
[27] M. Rastegari, V. Ordonez, J. Redmon, and A. Farhadi. Xnornet: Imagenet classification using binary convolutional neural networks. In _European Conference on Computer Vision_,
pages 525–542. Springer, 2016. 1, 2
[28] S. Ren, K. He, R. Girshick, and J. Sun. Faster r-cnn: Towards
real-time object detection with region proposal networks. In
_Advances in neural information processing systems_, pages
91–99, 2015. 1, 7
[29] O. Russakovsky, J. Deng, H. Su, J. Krause, S. Satheesh,
S. Ma, Z. Huang, A. Karpathy, A. Khosla, M. Bernstein,
et al. Imagenet large scale visual recognition challenge.
_International Journal of Computer Vision_, 115(3):211–252,
2015. 1, 4
[30] K. Simonyan and A. Zisserman. Very deep convolutional
networks for large-scale image recognition. _arXiv preprint_
_arXiv:1409.1556_, 2014. 1, 2, 5, 7
[31] D. Soudry, I. Hubara, and R. Meir. Expectation backpropagation: Parameter-free training of multilayer neural networks
with continuous or discrete weights. In _Advances in Neural_
_Information Processing Systems_, pages 963–971, 2014. 2
[32] C. Szegedy, S. Ioffe, V. Vanhoucke, and A. Alemi. Inceptionv4, inception-resnet and the impact of residual connections
on learning. _arXiv preprint arXiv:1602.07261_, 2016. 1, 2, 6
[33] C. Szegedy, W. Liu, Y. Jia, P. Sermanet, S. Reed,
D. Anguelov, D. Erhan, V. Vanhoucke, and A. Rabinovich.
Going deeper with convolutions. In _Proceedings of the IEEE_
_Conference on Computer Vision and Pattern Recognition_,
pages 1–9, 2015. 1, 2, 5, 6, 7
[34] C. Szegedy, V. Vanhoucke, S. Ioffe, J. Shlens, and Z. Wojna.
Rethinking the inception architecture for computer vision.
In _Proceedings of the IEEE Conference on Computer Vision_
_and Pattern Recognition_, pages 2818–2826, 2016. 1, 2, 6
[35] N. Vasilache, J. Johnson, M. Mathieu, S. Chintala, S. Piantino, and Y. LeCun. Fast convolutional nets with
fbfft: A gpu performance evaluation. _arXiv preprint_
_arXiv:1412.7580_, 2014. 2
[36] O. Vinyals, A. Toshev, S. Bengio, and D. Erhan. Show and
tell: A neural image caption generator. In _Proceedings of the_
_IEEE Conference on Computer Vision and Pattern Recogni-_
_tion_, pages 3156–3164, 2015. 1
[37] M. Wang, B. Liu, and H. Foroosh. Design of efficient
convolutional layers using single intra-channel convolution,
topological subdivisioning and spatial ”bottleneck” structure. _arXiv preprint arXiv:1608.04337_, 2016. 2
[38] W. Wen, C. Wu, Y. Wang, Y. Chen, and H. Li. Learning
structured sparsity in deep neural networks. In _Advances in_
_Neural Information Processing Systems_, pages 2074–2082,
2016. 1, 2, 8
[39] J. Wu, C. Leng, Y. Wang, Q. Hu, and J. Cheng. Quantized
convolutional neural networks for mobile devices. In _Pro-_
_ceedings of the IEEE Conference on Computer Vision and_
_Pattern Recognition_, pages 4820–4828, 2016. 2
[40] S. Xie, R. Girshick, P. Doll´ar, Z. Tu, and K. He. Aggregated
residual transformations for deep neural networks. _arXiv_
_preprint arXiv:1611.05431_, 2016. 1, 2, 3, 4, 5, 6
[41] T. Zhang, G.-J. Qi, B. Xiao, and J. Wang. Interleaved group
convolutions for deep neural networks. In _International Con-_
_ference on Computer Vision_, 2017. 2
[42] X. Zhang, J. Zou, K. He, and J. Sun. Accelerating very
deep convolutional networks for classification and detection.
_IEEE transactions on pattern analysis and machine intelli-_
_gence_, 38(10):1943–1955, 2016. 1, 8
[43] X. Zhang, J. Zou, X. Ming, K. He, and J. Sun. Efficient
and accurate approximations of nonlinear convolutional networks. In _Proceedings of the IEEE Conference on Computer_
_Vision and Pattern Recognition_, pages 1984–1992, 2015. 1,
8
[44] A. Zhou, A. Yao, Y. Guo, L. Xu, and Y. Chen. Incremental network quantization: Towards lossless cnns with lowprecision weights. _arXiv preprint arXiv:1702.03044_, 2017.
2
[45] S. Zhou, Y. Wu, Z. Ni, X. Zhou, H. Wen, and Y. Zou.
Dorefa-net: Training low bitwidth convolutional neural
networks with low bitwidth gradients. _arXiv preprint_
_arXiv:1606.06160_, 2016. 2
[46] B. Zoph, V. Vasudevan, J. Shlens, and Q. V. Le. Learning transferable architectures for scalable image recognition.
_arXiv preprint arXiv:1707.07012_, 2017. 1, 2