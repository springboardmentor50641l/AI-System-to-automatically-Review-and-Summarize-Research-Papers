<!DOCTYPE html>
<html lang="en" class="grade-c">
<head>
    <title>Shifting machine learning for healthcare from development to deployment and from models to data | Nature Biomedical Engineering</title>
    
        
<link rel="alternate" type="application/rss+xml" href="https://www.nature.com/natbiomedeng.rss"/>


    
        

        <script id="save-data-connection-testing">
            function hasConnection() {
                return navigator.connection || navigator.mozConnection || navigator.webkitConnection || navigator.msConnection;
            }

            function createLink(src) {
                var preloadLink = document.createElement("link");
                preloadLink.rel = "preload";
                preloadLink.href = src;
                preloadLink.as = "font";
                preloadLink.type = "font/woff2";
                preloadLink.crossOrigin = "";
                document.head.insertBefore(preloadLink, document.head.firstChild);
            }

            var connectionDetail = {
                saveDataEnabled: false,
                slowConnection: false
            };

            var connection = hasConnection();
            if (connection) {
                connectionDetail.saveDataEnabled = connection.saveData;
                if (/\slow-2g|2g/.test(connection.effectiveType)) {
                    connectionDetail.slowConnection = true;
                }
            }

            if (!(connectionDetail.saveDataEnabled || connectionDetail.slowConnection)) {
                createLink("/static/fonts/HardingText-Regular-Web-cecd90984f.woff2");
            } else {
                document.documentElement.classList.add('save-data');
            }
        </script>
    

<link rel="preconnect" href="https://cmp.nature.com" crossorigin>

<meta http-equiv="X-UA-Compatible" content="IE=edge">
<meta name="applicable-device" content="pc,mobile">
<meta name="viewport" content="width=device-width,initial-scale=1.0,maximum-scale=5,user-scalable=yes">
<meta name="360-site-verification" content="5a2dc4ab3fcb9b0393241ffbbb490480" />

<script data-test="dataLayer">
    window.dataLayer = [{"content":{"category":{"contentType":"review article","legacy":{"webtrendsPrimaryArticleType":"reviews","webtrendsSubjectTerms":"biomedical-engineering;computational-science;machine-learning;medical-imaging;translational-research","webtrendsContentCategory":null,"webtrendsContentCollection":"Electrical Engineering;Machine learning in healthcare","webtrendsContentGroup":"Nature Biomedical Engineering","webtrendsContentGroupType":null,"webtrendsContentSubGroup":"Review Article","status":null}},"article":{"doi":"10.1038/s41551-022-00898-y"},"attributes":{"cms":null,"deliveryPlatform":"oscar","copyright":{"open":false,"legacy":{"webtrendsLicenceType":null}}},"contentInfo":{"authors":["Angela Zhang","Lei Xing","James Zou","Joseph C. Wu"],"publishedAt":1656892800,"publishedAtString":"2022-07-04","title":"Shifting machine learning for healthcare from development to deployment and from models to data","legacy":null,"publishedAtTime":null,"documentType":"aplusplus","subjects":"Biomedical engineering,Computational science,Machine learning,Medical imaging,Translational research"},"journal":{"pcode":"natbiomedeng","title":"nature biomedical engineering","volume":"6","issue":"12","id":41551,"publishingModel":"Hybrid Access"},"authorization":{"status":false},"features":[{"name":"furtherReadingSection","present":true}],"collection":{"id":"dedffgdgjf;zbkpvddmhm"}},"page":{"category":{"pageType":"article"},"attributes":{"template":"mosaic","featureFlags":[{"name":"nature-onwards-journey","active":false}],"testGroup":null},"search":null},"privacy":{},"version":"1.0.0","product":null,"session":null,"user":null,"backHalfContent":true,"country":"IN","hasBody":true,"uneditedManuscript":false,"twitterId":["o3xnx","o43y9","o3ef7"],"baiduId":"d38bce82bcb44717ccc29a90c4b781ea","japan":false}];
    window.dataLayer.push({
        ga4MeasurementId: 'G-ERRNTNZ807',
        ga360TrackingId: 'UA-71668177-1',
        twitterId: ['3xnx', 'o43y9', 'o3ef7'],
        baiduId: 'd38bce82bcb44717ccc29a90c4b781ea',
        ga4ServerUrl: 'https://collect.nature.com',
        imprint: 'nature'
    });
</script>

<script>
    (function(w, d) {
        w.config = w.config || {};
        w.config.mustardcut = false;

        
        if (w.matchMedia && w.matchMedia('only print, only all and (prefers-color-scheme: no-preference), only all and (prefers-color-scheme: light), only all and (prefers-color-scheme: dark)').matches) {
            w.config.mustardcut = true;
            d.classList.add('js');
            d.classList.remove('grade-c');
            d.classList.remove('no-js');
        }
    })(window, document.documentElement);
</script>
 



     
    
    
        
    
    <style>@media only print, only all and (prefers-color-scheme: no-preference), only all and (prefers-color-scheme: light), only all and (prefers-color-scheme: dark) {  .c-article-editorial-summary__container .c-article-editorial-summary__article-title,.c-card--major .c-card__title,.c-card__title,.u-h2,.u-h3,h2,h3{font-weight:700;-webkit-font-smoothing:antialiased;font-family:Harding,Palatino,serif;letter-spacing:-.0117156rem}.c-article-editorial-summary__container .c-article-editorial-summary__article-title,.c-card__title,.u-h3,h3{font-size:1.25rem;line-height:1.4rem}.c-reading-companion__figure-title,.u-h4{font-weight:700;-webkit-font-smoothing:antialiased;line-height:1.4rem}html{line-height:1.15;text-size-adjust:100%;box-sizing:border-box;font-size:100%;height:100%;overflow-y:scroll}body{background:#eee;color:#222;font-family:-apple-system,BlinkMacSystemFont,Segoe UI,Roboto,Oxygen-Sans,Ubuntu,Cantarell,Helvetica Neue,sans-serif;font-size:1.125rem;line-height:1.76;margin:0;min-height:100%}details,main{display:block}h1{font-size:2em;margin:.67em 0}a,sup{vertical-align:baseline}a{background-color:transparent;color:#069;overflow-wrap:break-word;text-decoration:underline;text-decoration-skip-ink:auto;word-break:break-word}b{font-weight:bolder}sup{font-size:75%;line-height:0;position:relative;top:-.5em}img{border:0;height:auto;max-width:100%;vertical-align:middle}button,input,select{font-family:inherit;font-size:100%;line-height:1.15;margin:0}button,input{overflow:visible}button,select{text-transform:none}[type=submit],button{-webkit-appearance:button}[type=checkbox]{box-sizing:border-box;padding:0}summary{display:list-item}[hidden]{display:none}button{border-radius:0;cursor:pointer;font-family:-apple-system,BlinkMacSystemFont,Segoe UI,Roboto,Oxygen-Sans,Ubuntu,Cantarell,Helvetica Neue,sans-serif}h1{font-weight:700;-webkit-font-smoothing:antialiased;font-family:Harding,Palatino,serif;font-size:2rem;letter-spacing:-.0390625rem;line-height:2.25rem}.c-card--major .c-card__title,.u-h2,.u-h3,h2{font-family:Harding,Palatino,serif;letter-spacing:-.0117156rem}.c-card--major .c-card__title,.u-h2,h2,h2.app-access-wall__title{-webkit-font-smoothing:antialiased}.c-card--major .c-card__title,.u-h2,h2{font-size:1.5rem;font-weight:700;line-height:1.6rem}.u-h3{font-size:1.25rem}.c-card__title,.c-reading-companion__figure-title,.u-h3,.u-h4,h4,h5,h6{font-weight:700;-webkit-font-smoothing:antialiased;line-height:1.4rem}.c-article-editorial-summary__container .c-article-editorial-summary__article-title,.c-card__title,h3{font-family:Harding,Palatino,serif;font-size:1.25rem}.c-article-editorial-summary__container .c-article-editorial-summary__article-title,h3{font-weight:700;-webkit-font-smoothing:antialiased;letter-spacing:-.0117156rem;line-height:1.4rem}.c-reading-companion__figure-title,.u-h4{font-family:-apple-system,BlinkMacSystemFont,Segoe UI,Roboto,Oxygen-Sans,Ubuntu,Cantarell,Helvetica Neue,sans-serif;font-size:1.125rem;letter-spacing:-.0117156rem}input+label{padding-left:.5em}nav ol,nav ul{list-style:none none}p:empty{display:none}.c-nature-box{background-color:#fff;border:1px solid #d5d5d5;border-radius:2px;box-shadow:0 0 5px 0 rgba(51,51,51,.1);line-height:1.3;margin-bottom:24px;padding:16px 16px 3px}.c-nature-box__text{font-size:1rem;margin-bottom:16px}.c-nature-box--access-to-pdf{display:none}@media only screen and (min-width:1024px){.c-nature-box--mobile{display:none}}.c-nature-box .c-pdf-download{margin-bottom:16px!important}.c-nature-box svg+.c-article__button-text{margin-left:8px}.c-nature-box--version{background-color:#eee}.c-nature-box__wrapper{transform:translateZ(0)}.c-nature-box__wrapper--placeholder{min-height:165px}.sans-serif{font-family:-apple-system,BlinkMacSystemFont,Segoe UI,Roboto,Oxygen-Sans,Ubuntu,Cantarell,Helvetica Neue,sans-serif}.article-page{background:#fff}p{overflow-wrap:break-word;word-break:break-word}.c-article-header{font-family:-apple-system,BlinkMacSystemFont,Segoe UI,Roboto,Oxygen-Sans,Ubuntu,Cantarell,Helvetica Neue,sans-serif;margin-bottom:40px}.c-article-identifiers{color:#6f6f6f;display:flex;flex-wrap:wrap;font-size:1rem;line-height:1.3;list-style:none;padding:0}.c-article-identifiers__item{list-style:none;margin-right:8px;padding-right:8px}.c-article-identifiers__item:last-child{margin-right:0;padding-right:0}.c-article-title{font-size:1.5rem;line-height:1.25;margin:0 0 16px}@media only screen and (min-width:768px){.c-article-title{font-size:1.875rem;line-height:1.2}}.c-article-author-list{display:inline;font-size:1rem;list-style:none;margin:0 8px 0 0;padding:0;width:100%}.c-article-author-list__item{display:inline;padding-right:0}.c-article-author-list svg{margin-left:4px}.c-article-author-list__show-more{display:none;margin-right:4px}.c-article-author-list__button,.js .c-article-author-list__item--hide,.js .c-article-author-list__show-more{display:none}.js .c-article-author-list--long .c-article-author-list__show-more,.js .c-article-author-list--long+.c-article-author-list__button{display:inline}@media only screen and (max-width:539px){.js .c-article-author-list__item--hide-small-screen{display:none}.js .c-article-author-list--short .c-article-author-list__show-more,.js .c-article-author-list--short+.c-article-author-list__button{display:inline}}#uptodate-client,.js .c-article-author-list--expanded .c-article-author-list__show-more{display:none!important}.js .c-article-author-list--expanded .c-article-author-list__item--hide-small-screen{display:inline!important}.c-article-author-list__button,.c-button-author-list{background:#ebf1f5;border:4px solid #ebf1f5;border-radius:20px;color:#666;font-size:.875rem;line-height:1.4;padding:2px 11px 2px 8px;text-decoration:none}.c-article-author-list__button svg,.c-button-author-list svg{margin:1px 4px 0 0}.c-article-author-list__button:hover,.c-button-author-list:hover{background:#069;border-color:transparent;color:#fff}.c-article-info-details{font-size:1rem;margin-bottom:8px;margin-top:16px}.c-article-info-details__cite-as{border-left:1px solid #6f6f6f;margin-left:8px;padding-left:8px}.c-article-metrics-bar{display:flex;flex-wrap:wrap;font-size:1rem;line-height:1.3}.c-article-metrics-bar__wrapper{margin:16px 0}.c-article-metrics-bar__item{align-items:baseline;border-right:1px solid #6f6f6f;margin-right:8px}.c-article-metrics-bar__item:last-child{border-right:0}.c-article-metrics-bar__count{font-weight:700;margin:0}.c-article-metrics-bar__label{color:#626262;font-style:normal;font-weight:400;margin:0 10px 0 5px}.c-article-metrics-bar__details{margin:0}.c-article-main-column{font-family:Harding,Palatino,serif;margin-right:8.6%;width:60.2%}@media only screen and (max-width:1023px){.c-article-main-column{margin-right:0;width:100%}}.c-article-extras{float:left;font-family:-apple-system,BlinkMacSystemFont,Segoe UI,Roboto,Oxygen-Sans,Ubuntu,Cantarell,Helvetica Neue,sans-serif;width:31.2%}@media only screen and (max-width:1023px){.c-article-extras{display:none}}.c-article-associated-content__container .c-article-associated-content__title,.c-article-section__title{border-bottom:2px solid #d5d5d5;font-size:1.25rem;margin:0;padding-bottom:8px}@media only screen and (min-width:768px){.c-article-associated-content__container .c-article-associated-content__title,.c-article-section__title{font-size:1.5rem;line-height:1.24}}.c-article-associated-content__container .c-article-associated-content__title{margin-bottom:8px}.c-article-body p{margin-bottom:24px;margin-top:0}.c-article-section{clear:both}.c-article-section__content{margin-bottom:40px;padding-top:8px}@media only screen and (max-width:1023px){.c-article-section__content{padding-left:0}}.c-article-authors-search{margin-bottom:24px;margin-top:0}.c-article-authors-search__item,.c-article-authors-search__title{font-family:-apple-system,BlinkMacSystemFont,Segoe UI,Roboto,Oxygen-Sans,Ubuntu,Cantarell,Helvetica Neue,sans-serif}.c-article-authors-search__title{color:#626262;font-size:1.05rem;font-weight:700;margin:0;padding:0}.c-article-authors-search__item{font-size:1rem}.c-article-authors-search__text{margin:0}.c-code-block{border:1px solid #fff;font-family:monospace;margin:0 0 24px;padding:20px}.c-code-block__heading{font-weight:400;margin-bottom:16px}.c-code-block__line{display:block;overflow-wrap:break-word;white-space:pre-wrap}.c-article-share-box__no-sharelink-info{font-size:.813rem;font-weight:700;margin-bottom:24px;padding-top:4px}.c-article-share-box__only-read-input{border:1px solid #d5d5d5;box-sizing:content-box;display:inline-block;font-size:.875rem;font-weight:700;height:24px;margin-bottom:8px;padding:8px 10px}.c-article-share-box__button--link-like{background-color:transparent;border:0;color:#069;cursor:pointer;font-size:.875rem;margin-bottom:8px;margin-left:10px}.c-article-editorial-summary__container{font-family:-apple-system,BlinkMacSystemFont,Segoe UI,Roboto,Oxygen-Sans,Ubuntu,Cantarell,Helvetica Neue,sans-serif;font-size:1rem}.c-article-editorial-summary__container .c-article-editorial-summary__content p:last-child{margin-bottom:0}.c-article-editorial-summary__container .c-article-editorial-summary__content--less{max-height:9.5rem;overflow:hidden}.c-article-editorial-summary__container .c-article-editorial-summary__button{background-color:#fff;border:0;color:#069;font-size:.875rem;margin-bottom:16px}.c-article-editorial-summary__container .c-article-editorial-summary__button.active,.c-article-editorial-summary__container .c-article-editorial-summary__button.hover,.c-article-editorial-summary__container .c-article-editorial-summary__button:active,.c-article-editorial-summary__container .c-article-editorial-summary__button:hover{text-decoration:underline;text-decoration-skip-ink:auto}.c-article-associated-content__container .c-article-associated-content__collection-label{font-size:.875rem;line-height:1.4}.c-article-associated-content__container .c-article-associated-content__collection-title{line-height:1.3}.c-reading-companion{clear:both;min-height:389px}.c-reading-companion__sticky{max-width:389px}.c-reading-companion__scroll-pane{margin:0;min-height:200px;overflow:hidden auto}.c-reading-companion__tabs{display:flex;flex-flow:row nowrap;font-size:1rem;list-style:none;margin:0 0 8px;padding:0}.c-reading-companion__tabs>li{flex-grow:1}.c-reading-companion__tab{background-color:#eee;border:1px solid #d5d5d5;border-image:initial;border-left-width:0;color:#0067c5;font-size:1rem;padding:8px 8px 8px 15px;text-align:left;width:100%}.c-reading-companion__tabs li:first-child .c-reading-companion__tab{border-left-width:1px}.c-reading-companion__tab--active{background-color:#fff;border-bottom:1px solid #fff;color:#222;font-weight:700}.c-reading-companion__sections-list{list-style:none;padding:0}.c-reading-companion__figures-list,.c-reading-companion__references-list{list-style:none;min-height:389px;padding:0}.c-reading-companion__references-list--numeric{list-style:decimal inside}.c-reading-companion__sections-list{margin:0 0 8px;min-height:50px}.c-reading-companion__section-item{font-size:1rem;padding:0}.c-reading-companion__section-item a{display:block;line-height:1.5;overflow:hidden;padding:8px 0 8px 16px;text-overflow:ellipsis;white-space:nowrap}.c-reading-companion__figure-item{border-top:1px solid #d5d5d5;font-size:1rem;padding:16px 8px 16px 0}.c-reading-companion__figure-item:first-child{border-top:none;padding-top:8px}.c-reading-companion__reference-item{border-top:1px solid #d5d5d5;font-size:1rem;padding:8px 8px 8px 16px}.c-reading-companion__reference-item:first-child{border-top:none}.c-reading-companion__reference-item a{word-break:break-word}.c-reading-companion__reference-citation{display:inline}.c-reading-companion__reference-links{font-size:.813rem;font-weight:700;list-style:none;margin:8px 0 0;padding:0;text-align:right}.c-reading-companion__reference-links>a{display:inline-block;padding-left:8px}.c-reading-companion__reference-links>a:first-child{display:inline-block;padding-left:0}.c-reading-companion__figure-title{display:block;margin:0 0 8px}.c-reading-companion__figure-links{display:flex;justify-content:space-between;margin:8px 0 0}.c-reading-companion__figure-links>a{align-items:center;display:flex}.c-reading-companion__figure-full-link svg{height:.8em;margin-left:2px}.c-reading-companion__panel{border-top:none;display:none;margin-top:0;padding-top:0}.c-cod,.c-reading-companion__panel--active{display:block}.c-cod{font-size:1rem;width:100%}.c-cod__form{background:#ebf0f3}.c-cod__prompt{font-size:1.125rem;line-height:1.3;margin:0 0 24px}.c-cod__label{display:block;margin:0 0 4px}.c-cod__row{display:flex;margin:0 0 16px}.c-cod__row:last-child{margin:0}.c-cod__input{border:1px solid #d5d5d5;border-radius:2px;flex:1 1 auto;margin:0;padding:13px}.c-cod__input--submit{background-color:#069;border:1px solid #069;color:#fff;flex-shrink:1;margin-left:8px;transition:background-color .2s ease-out 0s,color .2s ease-out 0s}.c-cod__input--submit-single{flex-basis:100%;flex-shrink:0;margin:0}.c-cod__input--submit:focus,.c-cod__input--submit:hover{background-color:#fff;color:#069}.c-pdf-download__link .u-icon{padding-top:2px}.c-pdf-download{display:flex;margin-bottom:24px;max-height:48px}@media only screen and (min-width:540px){.c-pdf-download{max-height:none}}@media only screen and (min-width:1024px){.c-pdf-download{max-height:48px}}.c-pdf-download__link{display:flex;flex:1 1 0%}.c-pdf-download__link:hover{text-decoration:none}.c-pdf-download__text{padding-right:4px}@media only screen and (max-width:539px){.c-pdf-download__text{text-transform:capitalize}}@media only screen and (min-width:540px){.c-pdf-download__text{padding-right:8px}}.c-context-bar--sticky .c-pdf-download{display:block;margin-bottom:0;white-space:nowrap}@media only screen and (max-width:539px){.c-pdf-download .u-sticky-visually-hidden{border:0;clip:rect(0,0,0,0);height:1px;margin:-100%;overflow:hidden;padding:0;position:absolute!important;width:1px}}.c-pdf-container{display:flex;justify-content:flex-end}@media only screen and (max-width:539px){.c-pdf-container .c-pdf-download{display:flex;flex-basis:100%}}.c-pdf-container .c-pdf-download+.c-pdf-download{margin-left:16px}.c-article-extras .c-pdf-container .c-pdf-download{width:100%}.c-article-extras .c-pdf-container .c-pdf-download+.c-pdf-download{margin-left:0}@media only screen and (min-width:540px){.c-context-bar--sticky .c-pdf-download__link{align-items:center;flex:1 1 183px}}@media only screen and (max-width:320px){.c-context-bar--sticky .c-pdf-download__link{padding:16px}}.article-page--commercial .c-article-main-column .c-pdf-button__container .c-pdf-download{display:none}@media only screen and (max-width:1023px){.article-page--commercial .c-article-main-column .c-pdf-button__container .c-pdf-download{display:block}}.c-recommendations-column-switch .c-meta{margin-top:auto}.c-context-bar{box-shadow:0 0 10px 0 rgba(51,51,51,.2);position:relative;width:100%}.c-context-bar__container{margin:0 auto;max-width:1280px;padding:0 16px}.c-context-bar__title{display:none}.app-researcher-popup__link.hover,.app-researcher-popup__link.visited,.app-researcher-popup__link:hover,.app-researcher-popup__link:visited,.c-article-metrics__heading a,.c-article-metrics__posts .c-card__title a{color:inherit}.c-article-authors-search__list{align-items:center;display:flex;flex-wrap:wrap;gap:16px 16px;justify-content:center}@media only screen and (min-width:320px){.c-article-authors-search__list{justify-content:normal}}.c-article-authors-search__text{align-items:center;display:flex;flex-flow:column wrap;font-size:14px;justify-content:center}@media only screen and (min-width:320px){.c-article-authors-search__text{flex-direction:row;font-size:16px}}.c-article-authors-search__links-text{font-weight:700;margin-right:8px;text-align:center}@media only screen and (min-width:320px){.c-article-authors-search__links-text{text-align:left}}.c-article-authors-search__list-item--left{flex:1 1 100%}@media only screen and (min-width:320px){.c-article-authors-search__list-item--left{flex-basis:auto}}.c-article-authors-search__list-item--right{flex:1 1 auto}.c-article-identifiers{margin:0}.c-article-identifiers__item{border-right:2px solid #cedbe0;color:#222;font-size:14px}@media only screen and (min-width:320px){.c-article-identifiers__item{font-size:16px}}.c-article-identifiers__item:last-child{border-right:none}.c-article-metrics__posts .c-card__title{font-size:1.05rem}.c-article-metrics__posts .c-card__title+span{color:#6f6f6f;font-size:1rem}.app-author-list{color:#222;font-family:-apple-system,BlinkMacSystemFont,Segoe UI,Roboto,Oxygen-Sans,Ubuntu,Cantarell,Helvetica Neue,sans-serif;font-size:1rem;line-height:1.4;list-style:none;margin:0;padding:0}.app-author-list>li,.c-breadcrumbs>li,.c-footer__links>li,.js .app-author-list,.u-list-comma-separated>li,.u-list-inline>li{display:inline}.app-author-list>li:not(:first-child):not(:last-child):before{content:", "}.app-author-list>li:not(:only-child):last-child:before{content:" & "}.app-author-list--compact{font-size:.875rem;line-height:1.4}.app-author-list--truncated>li:not(:only-child):last-child:before{content:" ... "}.js .app-author-list__hide{display:none;visibility:hidden}.js .app-author-list__hide:first-child+*{margin-block-start:0}.c-ad{text-align:center}@media only screen and (min-width:320px){.c-ad{padding:8px}}.c-ad--728x90{background-color:#ccc;display:none}.c-ad--728x90 .c-ad__inner{min-height:calc(1.5em + 94px)}@media only screen and (min-width:768px){.js .c-ad--728x90{display:none}.js .u-show-following-ad+.c-ad--728x90{display:block}}.c-ad__label{color:#333;font-weight:400;line-height:1.5;margin-bottom:4px}.c-ad__label,.c-meta{font-family:-apple-system,BlinkMacSystemFont,Segoe UI,Roboto,Oxygen-Sans,Ubuntu,Cantarell,Helvetica Neue,sans-serif;font-size:.875rem}.c-meta{color:inherit;line-height:1.4;list-style:none;margin:0;padding:0}.c-meta--large{font-size:1rem}.c-meta--large .c-meta__item{margin-bottom:8px}.c-meta__item{display:inline-block;margin-bottom:4px}.c-meta__item:not(:last-child){border-right:1px solid #d5d5d5;margin-right:4px;padding-right:4px}@media only screen and (max-width:539px){.c-meta__item--block-sm-max{display:block}.c-meta__item--block-sm-max:not(:last-child){border-right:none;margin-right:0;padding-right:0}}@media only screen and (min-width:1024px){.c-meta__item--block-at-lg{display:block}.c-meta__item--block-at-lg:not(:last-child){border-right:none;margin-right:0;padding-right:0}}.c-meta__type{font-weight:700;text-transform:none}.c-skip-link{background:#069;bottom:auto;color:#fff;font-family:-apple-system,BlinkMacSystemFont,Segoe UI,Roboto,Oxygen-Sans,Ubuntu,Cantarell,Helvetica Neue,sans-serif;font-size:.875rem;padding:8px;position:absolute;text-align:center;transform:translateY(-100%);z-index:9999}@media (prefers-reduced-motion:reduce){.c-skip-link{transition:top .3s ease-in-out 0s}}@media print{.c-skip-link{display:none}}.c-skip-link:link{color:#fff}.c-status-message{align-items:center;box-sizing:border-box;display:flex;font-family:-apple-system,BlinkMacSystemFont,Segoe UI,Roboto,Oxygen-Sans,Ubuntu,Cantarell,Helvetica Neue,sans-serif;font-size:1rem;position:relative;width:100%}.c-card__summary>p:last-child,.c-status-message :last-child{margin-bottom:0}.c-status-message--boxed{background-color:#fff;border:1px solid #eee;border-radius:2px;line-height:1.4;padding:16px}.c-status-message__heading{font-family:-apple-system,BlinkMacSystemFont,Segoe UI,Roboto,Oxygen-Sans,Ubuntu,Cantarell,Helvetica Neue,sans-serif;font-size:1rem;font-weight:700}.c-status-message__icon{fill:currentcolor;display:inline-block;flex:0 0 auto;height:1.5em;margin-right:8px;transform:translate(0);vertical-align:text-top;width:1.5em}.c-status-message__icon--top{align-self:flex-start}.c-status-message--info .c-status-message__icon{color:#003f8d}.c-status-message--boxed.c-status-message--info{border-bottom:4px solid #003f8d}.c-status-message--error .c-status-message__icon{color:#c40606}.c-status-message--boxed.c-status-message--error{border-bottom:4px solid #c40606}.c-status-message--success .c-status-message__icon{color:#00b8b0}.c-status-message--boxed.c-status-message--success{border-bottom:4px solid #00b8b0}.c-status-message--warning .c-status-message__icon{color:#edbc53}.c-status-message--boxed.c-status-message--warning{border-bottom:4px solid #edbc53}.c-breadcrumbs{color:#000;font-family:-apple-system,BlinkMacSystemFont,Segoe UI,Roboto,Oxygen-Sans,Ubuntu,Cantarell,Helvetica Neue,sans-serif;font-size:1rem;list-style:none;margin:0;padding:0}.c-breadcrumbs__link{color:#666}svg.c-breadcrumbs__chevron{margin:4px 4px 0;fill:#888;height:10px;width:10px}@media only screen and (max-width:539px){.c-breadcrumbs .c-breadcrumbs__item{display:none}.c-breadcrumbs .c-breadcrumbs__item:last-child,.c-breadcrumbs .c-breadcrumbs__item:nth-last-child(2){display:inline}}.c-card{background-color:transparent;border:0;box-shadow:none;display:flex;flex-direction:column;font-size:14px;min-width:0;overflow:hidden;padding:0;position:relative}.c-card--no-shape{background:0 0;border:0;box-shadow:none}.c-card__image{display:flex;justify-content:center;overflow:hidden;padding-bottom:56.25%;position:relative}@supports (aspect-ratio:1/1){.c-card__image{padding-bottom:0}}.c-card__image img{left:0;min-height:100%;min-width:100%;position:absolute}@supports ((-o-object-fit:cover) or (object-fit:cover)){.c-card__image img{height:100%;object-fit:cover;width:100%}}.c-card__body{flex:1 1 auto;padding:16px}.c-card--no-shape .c-card__body{padding:0}.c-card--no-shape .c-card__body:not(:first-child){padding-top:16px}.c-card__title{letter-spacing:-.01875rem;margin-bottom:8px;margin-top:0}[lang=de] .c-card__title{hyphens:auto}.c-card__summary{line-height:1.4}.c-card__summary>p{margin-bottom:5px}.c-card__summary a{text-decoration:underline}.c-card__link:not(.c-card__link--no-block-link):before{bottom:0;content:"";left:0;position:absolute;right:0;top:0}.c-card--flush .c-card__body{padding:0}.c-card--major{font-size:1rem}.c-card--dark{background-color:#29303c;border-width:0;color:#e3e4e5}.c-card--dark .c-card__title{color:#fff}.c-card--dark .c-card__link,.c-card--dark .c-card__summary a{color:inherit}.c-header{background-color:#fff;border-bottom:5px solid #000;font-size:1rem;line-height:1.4;margin-bottom:16px}.c-header__row{padding:0;position:relative}.c-header__row:not(:last-child){border-bottom:1px solid #eee}.c-header__split{align-items:center;display:flex;justify-content:space-between}.c-header__logo-container{flex:1 1 0px;line-height:0;margin:8px 24px 8px 0}.c-header__logo{transform:translateZ(0)}.c-header__logo img{max-height:32px}.c-header__container{margin:0 auto;max-width:1280px}.c-header__menu{align-items:center;display:flex;flex:0 1 auto;flex-wrap:wrap;font-weight:700;gap:8px 8px;line-height:1.4;list-style:none;margin:0 -4px;padding:0}@media print{.c-header__menu{display:none}}@media only screen and (max-width:1023px){.c-header__menu--hide-lg-max{display:none;visibility:hidden}}.c-header__menu--global{font-weight:400;justify-content:flex-end}.c-header__menu--global svg{display:none;visibility:hidden}.c-header__menu--global svg:first-child+*{margin-block-start:0}@media only screen and (min-width:540px){.c-header__menu--global svg{display:block;visibility:visible}}.c-header__menu--journal{font-size:.875rem;margin:8px 0 8px -8px}@media only screen and (min-width:540px){.c-header__menu--journal{flex-wrap:nowrap;font-size:1rem}}.c-header__item{padding-bottom:0;padding-top:0;position:static}.c-header__item--pipe{border-left:2px solid #eee;padding-left:8px}.c-header__item--padding{padding-bottom:8px;padding-top:8px}@media only screen and (min-width:540px){.c-header__item--dropdown-menu{position:relative}}@media only screen and (min-width:1024px){.c-header__item--hide-lg{display:none;visibility:hidden}}@media only screen and (max-width:767px){.c-header__item--hide-md-max{display:none;visibility:hidden}.c-header__item--hide-md-max:first-child+*{margin-block-start:0}}.c-header__link{align-items:center;color:inherit;display:inline-flex;gap:4px 4px;padding:8px;white-space:nowrap}.c-header__link svg{transition-duration:.2s}.c-header__show-text{display:none;visibility:hidden}.has-tethered .c-header__heading--js-hide:first-child+*{margin-block-start:0}@media only screen and (min-width:540px){.c-header__show-text{display:inline;visibility:visible}}.c-header__show-text-sm{display:inline;visibility:visible}@media only screen and (min-width:540px){.c-header__show-text-sm{display:none;visibility:hidden}.c-header__show-text-sm:first-child+*{margin-block-start:0}}.c-header__dropdown{background-color:#000;border-bottom:1px solid #2f2f2f;color:#eee;font-size:.875rem;line-height:1.2;padding:16px 0}@media print{.c-header__dropdown{display:none}}.c-header__heading{display:inline-block;font-family:-apple-system,BlinkMacSystemFont,Segoe UI,Roboto,Oxygen-Sans,Ubuntu,Cantarell,Helvetica Neue,sans-serif;font-size:1.25rem;font-weight:400;line-height:1.4;margin-bottom:8px}.c-header__heading--keyline{border-top:1px solid;border-color:#2f2f2f;margin-top:16px;padding-top:16px;width:100%}.c-header__list{display:flex;flex-wrap:wrap;gap:0 16px;list-style:none;margin:0 -8px}.c-header__flush{margin:0 -8px}.c-header__visually-hidden{border:0;clip:rect(0,0,0,0);height:1px;margin:-100%;overflow:hidden;padding:0;position:absolute!important;width:1px}.c-header__search-form{margin-bottom:8px}.c-header__search-layout{display:flex;flex-wrap:wrap;gap:16px 16px}.c-header__search-layout>:first-child{flex:999 1 auto}.c-header__search-layout>*{flex:1 1 auto}.c-header__search-layout--max-width{max-width:720px}.c-header__search-button{align-items:center;background-color:transparent;background-image:none;border:1px solid #fff;border-radius:2px;color:#fff;cursor:pointer;display:flex;font-family:sans-serif;font-size:1rem;justify-content:center;line-height:1.15;margin:0;padding:8px 16px;position:relative;text-decoration:none;transition:all .25s ease 0s,color .25s ease 0s,border-color .25s ease 0s;width:100%}.c-header__input,.c-header__select{border:1px solid;border-radius:3px;box-sizing:border-box;font-size:1rem;padding:8px 16px;width:100%}.c-header__select{-webkit-appearance:none;background-image:url("data:image/svg+xml,%3Csvg height='16' viewBox='0 0 16 16' width='16' xmlns='http://www.w3.org/2000/svg'%3E%3Cpath d='m5.58578644 3-3.29289322-3.29289322c-.39052429-.39052429-.39052429-1.02368927 0-1.41421356s1.02368927-.39052429 1.41421356 0l4 4c.39052429.39052429.39052429 1.02368927 0 1.41421356l-4 4c-.39052429.39052429-1.02368927.39052429-1.41421356 0s-.39052429-1.02368927 0-1.41421356z' fill='%23333' fill-rule='evenodd' transform='matrix(0 1 -1 0 11 3)'/%3E%3C/svg%3E");background-position:right .7em top 50%;background-repeat:no-repeat;background-size:1em;box-shadow:0 1px 0 1px rgba(0,0,0,.04);display:block;margin:0;max-width:100%;min-width:150px}@media only screen and (min-width:540px){.c-header__menu--journal .c-header__item--dropdown-menu:last-child .c-header__dropdown.has-tethered{left:auto;right:0}}@media only screen and (min-width:768px){.c-header__menu--journal .c-header__item--dropdown-menu:last-child .c-header__dropdown.has-tethered{left:0;right:auto}}.c-header__dropdown.has-tethered{border-bottom:0;border-radius:0 0 2px 2px;left:0;position:absolute;top:100%;transform:translateY(5px);width:100%;z-index:1}@media only screen and (min-width:540px){.c-header__dropdown.has-tethered{transform:translateY(8px);width:auto}}@media only screen and (min-width:768px){.c-header__dropdown.has-tethered{min-width:225px}}.c-header__dropdown--full-width.has-tethered{padding:32px 0 24px;transform:none;width:100%}.has-tethered .c-header__heading--js-hide{display:none;visibility:hidden}.has-tethered .c-header__list--js-stack{flex-direction:column}.has-tethered .c-header__item--keyline,.has-tethered .c-header__list~.c-header__list .c-header__item:first-child{border-top:1px solid #d5d5d5;margin-top:8px;padding-top:8px}.c-header__item--snid-account-widget{display:flex}.c-header__container{padding:0 4px}.c-header__list{padding:0 12px}.c-header__menu .c-header__link{font-size:14px}.c-header__item--snid-account-widget .c-header__link{padding:8px}.c-header__menu--journal{margin-left:0}@media only screen and (min-width:540px){.c-header__container{padding:0 16px}.c-header__menu--journal{margin-left:-8px}.c-header__menu .c-header__link{font-size:16px}.c-header__link--search{gap:13px 13px}}.u-button{align-items:center;background-color:transparent;background-image:none;border-radius:2px;cursor:pointer;display:inline-flex;font-family:sans-serif;font-size:1rem;justify-content:center;line-height:1.3;margin:0;padding:8px;position:relative;text-decoration:none;transition:all .25s ease 0s,color .25s ease 0s,border-color .25s ease 0s;width:auto}.u-button svg,.u-button--primary svg{fill:currentcolor}.u-button{border:1px solid #069;color:#069}.u-button--primary{background-color:#069;background-image:none;border:1px solid #069;color:#fff}.u-button--full-width{display:flex;width:100%}.u-display-none{display:none}.js .u-js-hide,.u-hide{display:none;visibility:hidden}.u-hide:first-child+*{margin-block-start:0}.u-visually-hidden{border:0;clip:rect(0,0,0,0);height:1px;margin:-100%;overflow:hidden;padding:0;position:absolute!important;width:1px}@media print{.u-hide-print{display:none}}@media only screen and (min-width:1024px){.u-hide-at-lg{display:none;visibility:hidden}.u-hide-at-lg:first-child+*{margin-block-start:0}}.u-clearfix:after,.u-clearfix:before{content:"";display:table}.u-clearfix:after{clear:both}.u-color-open-access{color:#b74616}.u-float-left{float:left}.u-icon{fill:currentcolor;display:inline-block;height:1em;transform:translate(0);vertical-align:text-top;width:1em}.u-full-height{height:100%}.u-list-reset{list-style:none;margin:0;padding:0}.u-container{margin:0 auto;max-width:1280px;padding:0 16px}.u-justify-content-space-between{justify-content:space-between}.u-mt-32{margin-top:32px}.u-mb-8{margin-bottom:8px}.u-mb-16{margin-bottom:16px}.u-mb-24{margin-bottom:24px}.u-mb-32{margin-bottom:32px}.u-mb-48{margin-bottom:48px}.u-pa-16{padding:16px}html *,html :after,html :before{box-sizing:inherit}.c-article-section__title,.c-article-title{font-weight:700}.c-card__title{line-height:1.4em}.c-article__button{background-color:#069;border:1px solid #069;border-radius:2px;color:#fff;display:flex;font-family:-apple-system,BlinkMacSystemFont,Segoe UI,Roboto,Oxygen-Sans,Ubuntu,Cantarell,Helvetica Neue,sans-serif;font-size:.875rem;line-height:1.4;margin-bottom:16px;padding:13px;transition:background-color .2s ease-out 0s,color .2s ease-out 0s}.c-article__button,.c-article__button:hover{text-decoration:none}.c-article__button--inverted,.c-article__button:hover{background-color:#fff;color:#069}.c-article__button--inverted:hover{background-color:#069;color:#fff}.c-header__link{text-decoration:inherit}.grade-c-hide{display:block}.c-pdf-download__link{padding:13px 24px} } </style>




    
        <link data-test="critical-css-handler" data-inline-css-source="critical-css" rel="stylesheet" href="/static/css/enhanced-article-nature-branded-315a16c812.css" media="print" onload="this.media='only print, only all and (prefers-color-scheme: no-preference), only all and (prefers-color-scheme: light), only all and (prefers-color-scheme: dark)';this.onload=null">
    
    <noscript>
        <link rel="stylesheet" type="text/css" href="/static/css/enhanced-article-nature-branded-315a16c812.css" media="only print, only all and (prefers-color-scheme: no-preference), only all and (prefers-color-scheme: light), only all and (prefers-color-scheme: dark)">
    </noscript>

<link rel="stylesheet" type="text/css" href="/static/css/article-print-fb7cb72232.css" media="print">
    



<link rel="apple-touch-icon" sizes="180x180" href=/static/images/favicons/nature/apple-touch-icon-f39cb19454.png>
<link rel="icon" type="image/png" sizes="48x48" href=/static/images/favicons/nature/favicon-48x48-b52890008c.png>
<link rel="icon" type="image/png" sizes="32x32" href=/static/images/favicons/nature/favicon-32x32-3fe59ece92.png>
<link rel="icon" type="image/png" sizes="16x16" href=/static/images/favicons/nature/favicon-16x16-951651ab72.png>
<link rel="manifest" href=/static/manifest.json crossorigin="use-credentials">
<link rel="mask-icon" href=/static/images/favicons/nature/safari-pinned-tab-69bff48fe6.svg color="#000000">
<link rel="shortcut icon" href=/static/images/favicons/nature/favicon.ico>
<meta name="msapplication-TileColor" content="#000000">
<meta name="msapplication-config" content=/static/browserconfig.xml>
<meta name="theme-color" content="#000000">
<meta name="application-name" content="Nature">


<script>
    (function () {
        if ( typeof window.CustomEvent === "function" ) return false;
        function CustomEvent ( event, params ) {
            params = params || { bubbles: false, cancelable: false, detail: null };
            var evt = document.createEvent( 'CustomEvent' );
            evt.initCustomEvent( event, params.bubbles, params.cancelable, params.detail );
            return evt;
        }

        CustomEvent.prototype = window.Event.prototype;

        window.CustomEvent = CustomEvent;
    })();
</script>


<script>
    (function (w, d, s) {
        var urlParams = new URLSearchParams(w.location.search);
        if (urlParams.get('gptAdsTest') !== null) {
            d.addEventListener('sncc:initialise', function (e) {
                var t = d.createElement(s);
                var h = d.getElementsByTagName(s)[0];
                t.src = 'https://' + (e.detail.C03 ? 'securepubads.g.doubleclick' : 'pagead2.googlesyndication') + '.net/tag/js/gpt.js';
                t.async = false;
                t.onload = function () {
                    var n = d.createElement(s);
                    n.src = 'https://fed-libs.nature.com/production/gpt-ads-gtm.min.js';
                    n.async = false;
                    h.insertAdjacentElement('afterend', n);
                };
                h.insertAdjacentElement('afterend', t);
            })
        }
    })(window, document, 'script');
</script>
    
<!-- Google Tag Manager -->
<script data-test="gtm-head">
    window.initGTM = function() {
        if (window.config.mustardcut) {
            (function (w, d, s, l, i) {
                w[l] = w[l] || [];
                w[l].push({'gtm.start': new Date().getTime(), event: 'gtm.js'});
                var f = d.getElementsByTagName(s)[0],
                        j = d.createElement(s),
                        dl = l != 'dataLayer' ? '&l=' + l : '';
                j.async = true;
                j.src = 'https://sgtm.nature.com/gtm.js?id=' + i + dl;
                f.parentNode.insertBefore(j, f);
            })(window, document, 'script', 'dataLayer', 'GTM-MRVXSHQ');
        }
    }
</script>
<!-- End Google Tag Manager -->

    <script>
    (function(w,d,t) {
        function cc() {
            var h = w.location.hostname;
            if (h === 'preview-www.nature.com') return;
            var e = d.createElement(t),
                s = d.getElementsByTagName(t)[0];
            if (h === 'nature.com' || h.endsWith('.nature.com')) {
                e.src = 'https://cmp.nature.com/production_live/en/consent-bundle-8-102.js';
                e.setAttribute('onload', "initGTM(window,document,'script','dataLayer','GTM-MRVXSHQ')");
            } else {
                e.src = '/static/js/cookie-consent-es5-bundle-8d962b73c2.js';
                e.setAttribute('data-consent', h);
            }
            s.insertAdjacentElement('afterend', e);
        }
        cc();
    })(window,document,'script');
</script>


<script id="js-position0">
    (function(w, d) {
        w.idpVerifyPrefix = 'https://verify.nature.com';
        w.ra21Host = 'https://wayf.springernature.com';
        var moduleSupport = (function() {
            return 'noModule' in d.createElement('script');
        })();

        if (w.config.mustardcut === true) {
            w.loader = {
                index: 0,
                registered: [],
                scripts: [
                    
                        {src: '/static/js/global-article-es6-bundle-e979e7e7bc.js', test: 'global-article-js', module: true},
                        {src: '/static/js/global-article-es5-bundle-597536b0e3.js', test: 'global-article-js', nomodule: true},
                        {src: '/static/js/shared-es6-bundle-0c7392804a.js', test: 'shared-js', module: true},
                        {src: '/static/js/shared-es5-bundle-f97043df39.js', test: 'shared-js', nomodule: true},
                        {src: '/static/js/header-150-es6-bundle-5bb959eaa1.js', test: 'header-150-js', module: true},
                        {src: '/static/js/header-150-es5-bundle-994fde5b1d.js', test: 'header-150-js', nomodule: true}
                    
                ].filter(function (s) {
                    if (s.src === null) return false;
                    if (moduleSupport && s.nomodule) return false;
                    return !(!moduleSupport && s.module);
                }),

                register: function (value) {
                    this.registered.push(value);
                },

                ready: function () {
                    if (this.registered.length === this.scripts.length) {
                        this.registered.forEach(function (fn) {
                            if (typeof fn === 'function') {
                                setTimeout(fn, 0); 
                            }
                        });
                        this.ready = function () {};
                    }
                },

                insert: function (s) {
                    var t = d.getElementById('js-position' + this.index);
                    if (t && t.insertAdjacentElement) {
                        t.insertAdjacentElement('afterend', s);
                    } else {
                        d.head.appendChild(s);
                    }
                    ++this.index;
                },

                createScript: function (script, beforeLoad) {
                    var s = d.createElement('script');
                    s.id = 'js-position' + (this.index + 1);
                    s.setAttribute('data-test', script.test);
                    if (beforeLoad) {
                        s.defer = 'defer';
                        s.onload = function () {
                            if (script.noinit) {
                                loader.register(true);
                            }
                            if (d.readyState === 'interactive' || d.readyState === 'complete') {
                                loader.ready();
                            }
                        };
                    } else {
                        s.async = 'async';
                    }
                    s.src = script.src;
                    return s;
                },

                init: function () {
                    this.scripts.forEach(function (s) {
                        loader.insert(loader.createScript(s, true));
                    });

                    d.addEventListener('DOMContentLoaded', function () {
                        loader.ready();
                        var conditionalScripts;
                        
                            conditionalScripts = [
                                {match: 'div[data-pan-container]', src: '/static/js/pan-zoom-es6-bundle-464a2af269.js', test: 'pan-zoom-js',  module: true },
                                {match: 'div[data-pan-container]', src: '/static/js/pan-zoom-es5-bundle-98fb9b653b.js', test: 'pan-zoom-js',  nomodule: true },
                                {match: 'math,span.mathjax-tex', src: '/static/js/math-es6-bundle-55688a0084.js', test: 'math-js', module: true},
                                {match: 'math,span.mathjax-tex', src: '/static/js/math-es5-bundle-6a270012ec.js', test: 'math-js', nomodule: true}
                            ];
                        

                        if (conditionalScripts) {
                            conditionalScripts.filter(function (script) {
                                return !!document.querySelector(script.match) && !((moduleSupport && script.nomodule) || (!moduleSupport && script.module));
                            }).forEach(function (script) {
                                loader.insert(loader.createScript(script));
                            });
                        }
                    }, false);
                }
            };
            loader.init();
        }
    })(window, document);
</script>










<meta name="robots" content="noarchive">
<meta name="access" content="No">


<link rel="search" href="https://www.nature.com/search">
<link rel="search" href="https://www.nature.com/opensearch/opensearch.xml" type="application/opensearchdescription+xml" title="nature.com">
<link rel="search" href="https://www.nature.com/opensearch/request" type="application/sru+xml" title="nature.com">





    
    <script type="application/ld+json">{"mainEntity":{"headline":"Shifting machine learning for healthcare from development to deployment and from models to data","description":"In the past decade, the application of machine learning (ML) to healthcare has helped drive the automation of physician tasks as well as enhancements in clinical capabilities and access to care. This progress has emphasized that, from model development to model deployment, data play central roles. In this Review, we provide a data-centric view of the innovations and challenges that are defining ML for healthcare. We discuss deep generative models and federated learning as strategies to augment datasets for improved model performance, as well as the use of the more recent transformer models for handling larger datasets and enhancing the modelling of clinical text. We also discuss data-focused problems in the deployment of ML, emphasizing the need to efficiently deliver data to ML models for timely clinical predictions and to account for natural data shifts that can deteriorate model performance. This Review discusses the use of deep generative models, federated learning and transformer models to address challenges in the deployment of machine learning for healthcare.","datePublished":"2022-07-04T00:00:00Z","dateModified":"2022-07-04T00:00:00Z","pageStart":"1330","pageEnd":"1345","sameAs":"https://doi.org/10.1038/s41551-022-00898-y","keywords":["Biomedical engineering","Computational science","Machine learning","Medical imaging","Translational research","Biomedicine","general","Biomedical Engineering/Biotechnology"],"image":["https://media.springernature.com/lw1200/springer-static/image/art%3A10.1038%2Fs41551-022-00898-y/MediaObjects/41551_2022_898_Fig1_HTML.png","https://media.springernature.com/lw1200/springer-static/image/art%3A10.1038%2Fs41551-022-00898-y/MediaObjects/41551_2022_898_Fig2_HTML.png","https://media.springernature.com/lw1200/springer-static/image/art%3A10.1038%2Fs41551-022-00898-y/MediaObjects/41551_2022_898_Fig3_HTML.png","https://media.springernature.com/lw1200/springer-static/image/art%3A10.1038%2Fs41551-022-00898-y/MediaObjects/41551_2022_898_Fig4_HTML.png"],"isPartOf":{"name":"Nature Biomedical Engineering","issn":["2157-846X"],"volumeNumber":"6","@type":["Periodical","PublicationVolume"]},"publisher":{"name":"Nature Publishing Group UK","logo":{"url":"https://www.springernature.com/app-sn/public/images/logo-springernature.png","@type":"ImageObject"},"@type":"Organization"},"author":[{"name":"Angela Zhang","url":"http://orcid.org/0000-0003-0906-6770","affiliation":[{"name":"Stanford University","address":{"name":"Stanford Cardiovascular Institute, School of Medicine, Stanford University, Stanford, USA","@type":"PostalAddress"},"@type":"Organization"},{"name":"Stanford University","address":{"name":"Department of Genetics, School of Medicine, Stanford University, Stanford, USA","@type":"PostalAddress"},"@type":"Organization"},{"name":"Greenstone Biosciences","address":{"name":"Greenstone Biosciences, Palo Alto, USA","@type":"PostalAddress"},"@type":"Organization"},{"name":"Stanford University","address":{"name":"Department of Computer Science, Stanford University, Stanford, USA","@type":"PostalAddress"},"@type":"Organization"}],"email":"angelazhang@greenstonebio.com","@type":"Person"},{"name":"Lei Xing","url":"http://orcid.org/0000-0003-2536-5359","affiliation":[{"name":"Stanford University","address":{"name":"Department of Radiation Oncology, School of Medicine, Stanford University, Stanford, USA","@type":"PostalAddress"},"@type":"Organization"}],"@type":"Person"},{"name":"James Zou","url":"http://orcid.org/0000-0001-8880-4764","affiliation":[{"name":"Stanford University","address":{"name":"Department of Computer Science, Stanford University, Stanford, USA","@type":"PostalAddress"},"@type":"Organization"},{"name":"Stanford University","address":{"name":"Department of Biomedical Informatics, School of Medicine, Stanford University, Stanford, USA","@type":"PostalAddress"},"@type":"Organization"}],"@type":"Person"},{"name":"Joseph C. Wu","url":"http://orcid.org/0000-0002-6068-8041","affiliation":[{"name":"Stanford University","address":{"name":"Stanford Cardiovascular Institute, School of Medicine, Stanford University, Stanford, USA","@type":"PostalAddress"},"@type":"Organization"},{"name":"Greenstone Biosciences","address":{"name":"Greenstone Biosciences, Palo Alto, USA","@type":"PostalAddress"},"@type":"Organization"},{"name":"Division of Cardiovascular Medicine Stanford University","address":{"name":"Departments of Medicine, Division of Cardiovascular Medicine Stanford University, Stanford, USA","@type":"PostalAddress"},"@type":"Organization"},{"name":"Stanford University","address":{"name":"Department of Radiology, School of Medicine, Stanford University, Stanford, USA","@type":"PostalAddress"},"@type":"Organization"}],"email":"joewu@stanford.edu","@type":"Person"}],"isAccessibleForFree":false,"hasPart":{"isAccessibleForFree":false,"cssSelector":".main-content","@type":"WebPageElement"},"@type":"ScholarlyArticle"},"@context":"https://schema.org","@type":"WebPage"}</script>




    
    
    


    
    <link rel="canonical" href="https://www.nature.com/articles/s41551-022-00898-y">
    
    
    <meta name="journal_id" content="41551"/>
    <meta name="dc.title" content="Shifting machine learning for healthcare from development to deployment and from models to data"/>
    <meta name="dc.source" content="Nature Biomedical Engineering 2022 6:12"/>
    <meta name="dc.format" content="text/html"/>
    <meta name="dc.publisher" content="Nature Publishing Group"/>
    <meta name="dc.date" content="2022-07-04"/>
    <meta name="dc.type" content="ReviewPaper"/>
    <meta name="dc.language" content="En"/>
    <meta name="dc.copyright" content="2022 Springer Nature Limited"/>
    <meta name="dc.rights" content="2022 Springer Nature Limited"/>
    <meta name="dc.rightsAgent" content="journalpermissions@springernature.com"/>
    <meta name="dc.description" content="In the past decade, the application of machine learning (ML) to healthcare has helped drive the automation of physician tasks as well as enhancements in clinical capabilities and access to care. This progress has emphasized that, from model development to model deployment, data play central roles. In this Review, we provide a data-centric view of the innovations and challenges that are defining ML for healthcare. We discuss deep generative models and federated learning as strategies to augment datasets for improved model performance, as well as the use of the more recent transformer models for handling larger datasets and enhancing the modelling of clinical text. We also discuss data-focused problems in the deployment of ML, emphasizing the need to efficiently deliver data to ML models for timely clinical predictions and to account for natural data shifts that can deteriorate model performance. This Review discusses the use of deep generative models, federated learning and transformer models to address challenges in the deployment of machine learning for healthcare."/>
    <meta name="prism.issn" content="2157-846X"/>
    <meta name="prism.publicationName" content="Nature Biomedical Engineering"/>
    <meta name="prism.publicationDate" content="2022-07-04"/>
    <meta name="prism.volume" content="6"/>
    <meta name="prism.number" content="12"/>
    <meta name="prism.section" content="ReviewPaper"/>
    <meta name="prism.startingPage" content="1330"/>
    <meta name="prism.endingPage" content="1345"/>
    <meta name="prism.copyright" content="2022 Springer Nature Limited"/>
    <meta name="prism.rightsAgent" content="journalpermissions@springernature.com"/>
    <meta name="prism.url" content="https://www.nature.com/articles/s41551-022-00898-y"/>
    <meta name="prism.doi" content="doi:10.1038/s41551-022-00898-y"/>
    <meta name="citation_pdf_url" content="https://www.nature.com/articles/s41551-022-00898-y.pdf"/>
    <meta name="citation_fulltext_html_url" content="https://www.nature.com/articles/s41551-022-00898-y"/>
    <meta name="citation_journal_title" content="Nature Biomedical Engineering"/>
    <meta name="citation_journal_abbrev" content="Nat. Biomed. Eng"/>
    <meta name="citation_publisher" content="Nature Publishing Group"/>
    <meta name="citation_issn" content="2157-846X"/>
    <meta name="citation_title" content="Shifting machine learning for healthcare from development to deployment and from models to data"/>
    <meta name="citation_volume" content="6"/>
    <meta name="citation_issue" content="12"/>
    <meta name="citation_publication_date" content="2022/12"/>
    <meta name="citation_online_date" content="2022/07/04"/>
    <meta name="citation_firstpage" content="1330"/>
    <meta name="citation_lastpage" content="1345"/>
    <meta name="citation_article_type" content="Review Article"/>
    <meta name="citation_language" content="en"/>
    <meta name="dc.identifier" content="doi:10.1038/s41551-022-00898-y"/>
    <meta name="DOI" content="10.1038/s41551-022-00898-y"/>
    <meta name="size" content="323607"/>
    <meta name="citation_doi" content="10.1038/s41551-022-00898-y"/>
    <meta name="citation_springer_api_url" content="http://api.springer.com/xmldata/jats?q=doi:10.1038/s41551-022-00898-y&amp;api_key="/>
    <meta name="description" content="In the past decade, the application of machine learning (ML) to healthcare has helped drive the automation of physician tasks as well as enhancements in clinical capabilities and access to care. This progress has emphasized that, from model development to model deployment, data play central roles. In this Review, we provide a data-centric view of the innovations and challenges that are defining ML for healthcare. We discuss deep generative models and federated learning as strategies to augment datasets for improved model performance, as well as the use of the more recent transformer models for handling larger datasets and enhancing the modelling of clinical text. We also discuss data-focused problems in the deployment of ML, emphasizing the need to efficiently deliver data to ML models for timely clinical predictions and to account for natural data shifts that can deteriorate model performance. This Review discusses the use of deep generative models, federated learning and transformer models to address challenges in the deployment of machine learning for healthcare."/>
    <meta name="dc.creator" content="Zhang, Angela"/>
    <meta name="dc.creator" content="Xing, Lei"/>
    <meta name="dc.creator" content="Zou, James"/>
    <meta name="dc.creator" content="Wu, Joseph C."/>
    <meta name="dc.subject" content="Biomedical engineering"/>
    <meta name="dc.subject" content="Computational science"/>
    <meta name="dc.subject" content="Machine learning"/>
    <meta name="dc.subject" content="Medical imaging"/>
    <meta name="dc.subject" content="Translational research"/>
    <meta name="citation_reference" content="citation_journal_title=Nat. Med.; citation_title=High-performance medicine: the convergence of human and artificial intelligence; citation_author=EJ Topol; citation_volume=25; citation_publication_date=2019; citation_pages=44-56; citation_doi=10.1038/s41591-018-0300-7; citation_id=CR1"/>
    <meta name="citation_reference" content="citation_journal_title=JAMA; citation_title=Development and validation of a deep learning algorithm for detection of diabetic retinopathy in retinal fundus photographs; citation_author=V Gulshan; citation_volume=316; citation_publication_date=2016; citation_pages=2402-2410; citation_doi=10.1001/jama.2016.17216; citation_id=CR2"/>
    <meta name="citation_reference" content="citation_journal_title=Nature; citation_title=Dermatologist-level classification of skin cancer with deep neural networks; citation_author=A Esteva; citation_volume=542; citation_publication_date=2017; citation_pages=115-118; citation_doi=10.1038/nature21056; citation_id=CR3"/>
    <meta name="citation_reference" content="citation_journal_title=npj Digit. Med.; citation_title=Scalable and accurate deep learning with electronic health records; citation_author=A Rajkomar; citation_volume=1; citation_publication_date=2018; citation_pages=18; citation_doi=10.1038/s41746-018-0029-1; citation_id=CR4"/>
    <meta name="citation_reference" content="citation_journal_title=JAMA Intern. Med.; citation_title=Automatically charting symptoms from patient-physician conversations using machine learning; citation_author=A Rajkomar; citation_volume=179; citation_publication_date=2019; citation_pages=836-838; citation_doi=10.1001/jamainternmed.2018.8558; citation_id=CR5"/>
    <meta name="citation_reference" content="citation_journal_title=Sci. Transl. Med.; citation_title=A targeted real-time early warning score (TREWScore) for septic shock; citation_author=KE Henry, DN Hager, PJ Pronovost, S Saria; citation_volume=7; citation_publication_date=2015; citation_pages=299ra122; citation_doi=10.1126/scitranslmed.aab3719; citation_id=CR6"/>
    <meta name="citation_reference" content="citation_journal_title=Nat. Med.; citation_title=The Artificial Intelligence Clinician learns optimal treatment strategies for sepsis in intensive care; citation_author=M Komorowski, LA Celi, O Badawi, AC Gordon, AA Faisal; citation_volume=24; citation_publication_date=2018; citation_pages=1716-1720; citation_doi=10.1038/s41591-018-0213-5; citation_id=CR7"/>
    <meta name="citation_reference" content="citation_journal_title=npj Digit. Med.; citation_title=Pivotal trial of an autonomous AI-based diagnostic system for detection of diabetic retinopathy in primary care offices; citation_author=MD Abr&#224;moff, PT Lavin, M Birch, N Shah, JC Folk; citation_volume=1; citation_publication_date=2018; citation_pages=39; citation_doi=10.1038/s41746-018-0040-6; citation_id=CR8"/>
    <meta name="citation_reference" content="citation_journal_title=Brit. Med. J.; citation_title=Babylon Health holds talks with &#8216;significant&#8217; number of NHS trusts; citation_author=G Iacobucci; citation_volume=368; citation_publication_date=2020; citation_pages=m266; citation_doi=10.1136/bmj.m266; citation_id=CR9"/>
    <meta name="citation_reference" content="Hale, C. Medtronic to distribute Viz.ai&#8217;s stroke-spotting AI imaging software. Fierce Biotech (23 July 2019); 
                  https://www.fiercebiotech.com/medtech/medtronic-to-distribute-viz-ai-s-stroke-spotting-ai-imaging-software
                  
                "/>
    <meta name="citation_reference" content="citation_journal_title=Interv. Neuroradiol.; citation_title=Early experience utilizing artificial intelligence shows significant reduction in transfer times and length of stay in a hub and spoke model; citation_author=AE Hassan; citation_volume=26; citation_publication_date=2020; citation_pages=615-622; citation_doi=10.1177/1591019920953055; citation_id=CR11"/>
    <meta name="citation_reference" content="citation_journal_title=JAMA; citation_title=Development and validation of a deep learning system for diabetic retinopathy and related eye diseases using retinal images from multiethnic populations with diabetes; citation_author=DSW Ting; citation_volume=318; citation_publication_date=2017; citation_pages=2211-2223; citation_doi=10.1001/jama.2017.18152; citation_id=CR12"/>
    <meta name="citation_reference" content="citation_journal_title=Nature; citation_title=International evaluation of an AI system for breast cancer screening; citation_author=SM McKinney; citation_volume=577; citation_publication_date=2020; citation_pages=89-94; citation_doi=10.1038/s41586-019-1799-6; citation_id=CR13"/>
    <meta name="citation_reference" content="citation_journal_title=Nat. Med.; citation_title=A deep learning system for differential diagnosis of skin diseases; citation_author=Y Liu; citation_volume=26; citation_publication_date=2020; citation_pages=900-908; citation_doi=10.1038/s41591-020-0842-3; citation_id=CR14"/>
    <meta name="citation_reference" content="citation_journal_title=Pac. Symp. Biocomput.; citation_title=CheXclusion: fairness gaps in deep chest X-ray classifiers; citation_author=L Seyyed-Kalantari, G Liu, M McDermott, IY Chen, M Ghassemi; citation_volume=26; citation_publication_date=2021; citation_pages=232-243; citation_id=CR15"/>
    <meta name="citation_reference" content="citation_journal_title=Nat. Biomed. Eng.; citation_title=Artificial intelligence in healthcare; citation_author=K-H Yu, AL Beam, IS Kohane; citation_volume=2; citation_publication_date=2018; citation_pages=719-731; citation_doi=10.1038/s41551-018-0305-z; citation_id=CR16"/>
    <meta name="citation_reference" content="citation_journal_title=Nat. Med.; citation_title=A guide to deep learning in healthcare; citation_author=A Esteva; citation_volume=25; citation_publication_date=2019; citation_pages=24-29; citation_doi=10.1038/s41591-018-0316-z; citation_id=CR17"/>
    <meta name="citation_reference" content="citation_journal_title=Neurocomputing; citation_title=GAN-based synthetic medical image augmentation for increased CNN performance in liver lesion classification; citation_author=M Frid-Adar; citation_volume=321; citation_publication_date=2018; citation_pages=321-331; citation_doi=10.1016/j.neucom.2018.09.013; citation_id=CR18"/>
    <meta name="citation_reference" content="Shin, H.-C. et al. Medical image synthesis for data augmentation and anonymization using generative adversarial networks. In Simulation and Synthesis in Medical Imaging SASHIMI 2018 (eds Gooya, A., Goksel, O., Oguz, I. &amp; Burgos, N.) 1&#8211;11 (Springer Cham, 2018)."/>
    <meta name="citation_reference" content="Salehinejad, H., Valaee, S., Dowdell, T., Colak, E. &amp; Barfett, J. Generalization of deep neural networks for chest pathology classification in X-rays using generative adversarial networks. In IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP) 990&#8211;994 (ieeexplore.ieee.org, 2018)."/>
    <meta name="citation_reference" content="Zhang, Z., Yang, L. &amp; Zheng, Y. Translating and segmenting multimodal medical volumes with cycle-and shape-consistency generative adversarial network. In Proceedings of IEEE/CVF Conference on Computer Vision and Pattern Recognition 9242&#8211;9251 (IEEE, 2018)."/>
    <meta name="citation_reference" content="Xu, F., Zhang, J., Shi, Y., Kang, K. &amp; Yang, S. A fast low-rank matrix factorization method for dynamic magnetic resonance imaging restoration. In 5th International Conference on Big Data Computing and Communications (BIGCOM) 38&#8211;42 (2019)."/>
    <meta name="citation_reference" content="Goodfellow, I. J. et al. Generative adversarial networks. In Advances in Neural Information Processing Systems 27 (eds .Ghahramani, Z., Welling, M., Cortes, C., Lawrence, N. &amp; Weinbergerm, K.Q.) Paper 1384 (Curran, 2014)."/>
    <meta name="citation_reference" content="citation_journal_title=ACM Comput. Surv.; citation_title=Generative adversarial networks in computer vision: a survey and taxonomy; citation_author=Z Wang, Q She, TE Ward; citation_volume=54; citation_publication_date=2021; citation_pages=1-38; citation_id=CR24"/>
    <meta name="citation_reference" content="Radford, A., Metz, L. &amp; Chintala, S. Unsupervised representation learning with deep convolutional generative adversarial networks. Preprint at 
                  https://arxiv.org/abs/1511.06434v2
                  
                 (2016)."/>
    <meta name="citation_reference" content="Denton, E. L., Chintala, S. &amp; Fergus, R. Deep generative image models using a Laplacian pyramid of adversarial networks. In Advances in Neural Information Processing Systems 28 (eds Cortes, C., Lawrence, N., Lee, D., Sugiyama, M. &amp; Garnett, R.) Paper 903 (Curran, 2015)."/>
    <meta name="citation_reference" content="Karras, T., Aila, T., Laine, S. &amp; Lehtinen, J. Progressive growing of GANs for improved quality, stability, and variation. In International Conference on Learning Representations 2018 Paper 447 (ICLR, 2018)."/>
    <meta name="citation_reference" content="Mirza, M. &amp; Osindero, S. Conditional generative adversarial nets. Preprint at 
                  https://arxiv.org/abs/1411.1784v1
                  
                 (2014)."/>
    <meta name="citation_reference" content="Odena, A., Olah, C. &amp; Shlens, J. Conditional image synthesis with auxiliary classifier GANs. In Proceedings of the 34th International Conference on Machine Learning (eds. Precup, D. &amp; Teh, Y. W.) 2642&#8211;2651 (PMLR, 2017)."/>
    <meta name="citation_reference" content="Isola, P., Zhu, J.-Y., Zhou, T. &amp; Efros, A. A. Image-to-image translation with conditional adversarial networks. In Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition 5967&#8211;5976 (2018)."/>
    <meta name="citation_reference" content="Zhang, H., Goodfellow, I., Metaxas, D. &amp; Odena, A. Self-attention generative adversarial networks. In Proceedings of the 36th International Conference on Machine Learning (eds. Chaudhuri, K. &amp; Salakhutdinov, R.) 7354&#8211;7363 (PMLR, 2019)."/>
    <meta name="citation_reference" content="citation_journal_title=Inf. Sci.; citation_title=Self-attention convolutional neural network for improved MR image reconstruction; citation_author=Y Wu, Y Ma, J Liu, J Du, L Xing; citation_volume=490; citation_publication_date=2019; citation_pages=317-328; citation_doi=10.1016/j.ins.2019.03.080; citation_id=CR32"/>
    <meta name="citation_reference" content="Brock, A., Donahue, J. &amp; Simonyan, K. Large scale GAN training for high fidelity natural image synthesis. In International Conference on Learning Representations Paper 564 (ICLR, 2019)."/>
    <meta name="citation_reference" content="Arjovsky, M., Chintala, S. &amp; Bottou, L. Wasserstein generative adversarial networks. In Proceedings of the 34th International Conference on Machine Learning (eds. Precup, D. &amp; Teh, Y. W.) 214&#8211;223 (PMLR, 2017)."/>
    <meta name="citation_reference" content="Gulrajani, I., Ahmed, F., Arjovsky, M., Dumoulin, V. &amp; Courville, A. C. Improved training of Wasserstein GANs. In Advances in Neural Information Processing Systems 30 (eds. Guyon, I. et al.) Paper 2945 (Curran, 2017)."/>
    <meta name="citation_reference" content="Hindupur, A. The-gan-zoo. 
                  https://github.com/hindupuravinash/the-gan-zoo
                  
                 (2018)."/>
    <meta name="citation_reference" content="citation_journal_title=PLoS Med.; citation_title=Deep learning for chest radiograph diagnosis: a retrospective comparison of the CheXNeXt algorithm to practicing radiologists; citation_author=P Rajpurkar; citation_volume=15; citation_publication_date=2018; citation_pages=e1002686; citation_doi=10.1371/journal.pmed.1002686; citation_id=CR37"/>
    <meta name="citation_reference" content="citation_journal_title=Nature; citation_title=Video-based AI for beat-to-beat assessment of cardiac function; citation_author=D Ouyang; citation_volume=580; citation_publication_date=2020; citation_pages=252-256; citation_doi=10.1038/s41586-020-2145-8; citation_id=CR38"/>
    <meta name="citation_reference" content="citation_journal_title=Neuroinformatics; citation_title=SegAN: adversarial network with multi-scale L1 loss for medical image segmentation; citation_author=Y Xue, T Xu, H Zhang, LR Long, X Huang; citation_volume=16; citation_publication_date=2018; citation_pages=383-392; citation_doi=10.1007/s12021-018-9377-x; citation_id=CR39"/>
    <meta name="citation_reference" content="citation_journal_title=Nature; citation_title=Illuminating the dark spaces of healthcare with ambient intelligence; citation_author=A Haque, A Milstein, L Fei-Fei; citation_volume=585; citation_publication_date=2020; citation_pages=193-202; citation_doi=10.1038/s41586-020-2669-y; citation_id=CR40"/>
    <meta name="citation_reference" content="citation_journal_title=PLoS Med.; citation_title=Variable generalization performance of a deep learning model to detect pneumonia in chest radiographs: a cross-sectional study; citation_author=JR Zech; citation_volume=15; citation_publication_date=2018; citation_pages=e1002683; citation_doi=10.1371/journal.pmed.1002683; citation_id=CR41"/>
    <meta name="citation_reference" content="citation_journal_title=Nature; citation_title=AI can be sexist and racist &#8212; it&#8217;s time to make it fair; citation_author=J Zou, L Schiebinger; citation_volume=559; citation_publication_date=2018; citation_pages=324-326; citation_doi=10.1038/d41586-018-05707-8; citation_id=CR42"/>
    <meta name="citation_reference" content="Perez, L. &amp; Wang, J. The effectiveness of data augmentation in image classification using deep learning. Preprint at 
                  https://arxiv.org/abs/1712.04621v1
                  
                 (2017)."/>
    <meta name="citation_reference" content="Madani, A., Moradi, M., Karargyris, A. &amp; Syeda-Mahmood, T. Semi-supervised learning with generative adversarial networks for chest X-ray classification with ability of data domain adaptation. In IEEE 15th International Symposium on Biomedical Imaging (ISBI) 1038&#8211;1042 (IEEE, 2018)."/>
    <meta name="citation_reference" content="citation_journal_title=Nat. Med.; citation_title=The practical implementation of artificial intelligence technologies in medicine; citation_author=J He; citation_volume=25; citation_publication_date=2019; citation_pages=30-36; citation_doi=10.1038/s41591-018-0307-0; citation_id=CR45"/>
    <meta name="citation_reference" content="citation_journal_title=BMC Med.; citation_title=Key challenges for delivering clinical impact with artificial intelligence; citation_author=CJ Kelly, A Karthikesalingam, M Suleyman, G Corrado, D King; citation_volume=17; citation_publication_date=2019; citation_doi=10.1186/s12916-019-1426-2; citation_id=CR46"/>
    <meta name="citation_reference" content="citation_journal_title=Nat. Commun.; citation_title=Estimating the success of re-identifications in incomplete datasets using generative models; citation_author=L Rocher, JM Hendrickx, Y-A Montjoye; citation_volume=10; citation_publication_date=2019; citation_doi=10.1038/s41467-019-10933-3; citation_id=CR47"/>
    <meta name="citation_reference" content="citation_journal_title=N. Engl. J. Med.; citation_title=Identification of anonymous MRI research participants with face-recognition software; citation_author=CG Schwarz; citation_volume=381; citation_publication_date=2019; citation_pages=1684-1686; citation_doi=10.1056/NEJMc1908881; citation_id=CR48"/>
    <meta name="citation_reference" content="Chartsias, A., Joyce, T., Dharmakumar, R. &amp; Tsaftaris, S. A. Adversarial image synthesis for unpaired multi-modal cardiac data. in Simulation and Synthesis in Medical Imaging (eds. Tsaftaris, S. A., Gooya, A., Frangi, A. F. &amp; Prince, J. L.) 3&#8211;13 (Springer International Publishing, 2017)."/>
    <meta name="citation_reference" content="Emami, H., Dong, M., Nejad-Davarani, S. P. &amp; Glide-Hurst, C. K. Generating synthetic CTs from magnetic resonance images using generative adversarial networks. Med. Phys. 
                  https://doi.org/10.1002/mp.13047
                  
                 (2018)."/>
    <meta name="citation_reference" content="citation_journal_title=Sensors; citation_title=Deep CT to MR synthesis using paired and unpaired data; citation_author=C-B Jin; citation_volume=19; citation_publication_date=2019; citation_pages=2361; citation_doi=10.3390/s19102361; citation_id=CR51"/>
    <meta name="citation_reference" content="Bi, L., Kim, J., Kumar, A., Feng, D. &amp; Fulham, M. In Molecular Imaging, Reconstruction and Analysis of Moving Body Organs, and Stroke Imaging and Treatment (eds. Cardoso, M. J. et al.) 43&#8211;51 (Springer International Publishing, 2017)."/>
    <meta name="citation_reference" content="Ben-Cohen, A. et al. Cross-modality synthesis from CT to PET using FCN and GAN networks for improved automated lesion detection. Eng. Appl. Artif. Intell. 78, 186&#8211;194 (2019)."/>
    <meta name="citation_reference" content="citation_journal_title=Comput. Med. Imaging Graph.; citation_title=MedGAN: medical image translation using GANs; citation_author=K Armanious; citation_volume=79; citation_publication_date=2020; citation_pages=101684; citation_doi=10.1016/j.compmedimag.2019.101684; citation_id=CR54"/>
    <meta name="citation_reference" content="citation_journal_title=J. Nucl. Med.; citation_title=Alzheimer&#8217;s Disease Neuroimaging Initiative. Generation of structural MR images from amyloid PET: application to MR-less quantification; citation_author=H Choi, DS Lee; citation_volume=59; citation_publication_date=2018; citation_pages=1111-1117; citation_doi=10.2967/jnumed.117.199414; citation_id=CR55"/>
    <meta name="citation_reference" content="Wei, W. et al. Learning myelin content in multiple sclerosis from multimodal MRI through adversarial training. In Medical Image Computing and Computer Assisted Intervention &#8212; MICCAI 2018 (eds. Frangi, A. F., Schnabel, J. A., Davatzikos, C., Alberola-L&#243;pez, C. &amp; Fichtinger, G.) 514&#8211;522 (Springer Cham, 2018)."/>
    <meta name="citation_reference" content="Pan, Y. et al. Synthesizing missing PET from MRI with cycle-consistent generative adversarial networks for Alzheimer&#8217;s disease diagnosis. In Medical Image Computing and Computer Assisted Intervention &#8212; MICCAI 2018 (eds. Frangi, A. F., Schnabel, J. A., Davatzikos, C., Alberola-L&#243;pez, C. &amp; Fichtinger, G.) 455&#8211;463 (Springer Cham, 2018)."/>
    <meta name="citation_reference" content="Welander, P., Karlsson, S. &amp; Eklund, A. Generative adversarial networks for image-to-image translation on multi-contrast MR images - a comparison of CycleGAN and UNIT. Preprint at 
                  https://arxiv.org/abs/1806.07777v1
                  
                 (2018)."/>
    <meta name="citation_reference" content="Dar, S. U. H. et al. Image synthesis in multi-contrast MRI with conditional generative adversarial networks. IEEE Trans. Med. Imaging 38, 2375&#8211;2388 (2019)."/>
    <meta name="citation_reference" content="Zhu, J.-Y., Park, T., Isola, P. &amp; Efros, A. A. Unpaired image-to-image translation using cycle-consistent adversarial networks. In 2017 IEEE International Conference on Computer Vision (ICCV) (IEEE, 2017); 
                  https://doi.org/10.1109/iccv.2017.244
                  
                "/>
    <meta name="citation_reference" content="citation_journal_title=Phys. Med. Biol.; citation_title=Dose evaluation of fast synthetic-CT generation using a generative adversarial network for general pelvis MR-only radiotherapy; citation_author=M Maspero; citation_volume=63; citation_publication_date=2018; citation_pages=185001; citation_doi=10.1088/1361-6560/aada6d; citation_id=CR61"/>
    <meta name="citation_reference" content="Olut, S., Sahin, Y.H., Demir, U., Unal, G. Generative adversarial training for MRA image synthesis using multi-contrast MRI. In PRedictive Intelligence in MEdicine. PRIME 2018. Lecture Notes in Computer Science (eds Rekik, I., Unal, G., Adeli, E. &amp; Park, S.) (Springer Cham, 2018); 
                  https://doi.org/10.1007/978-3-030-00320-3_18
                  
                "/>
    <meta name="citation_reference" content="citation_journal_title=Nat. Biomed. Eng.; citation_title=Synthetic data in machine learning for medicine and healthcare; citation_author=RJ Chen, MY Lu, TY Chen, DFK Williamson, F Mahmood; citation_volume=5; citation_publication_date=2021; citation_pages=493-497; citation_doi=10.1038/s41551-021-00751-8; citation_id=CR63"/>
    <meta name="citation_reference" content="citation_journal_title=Nat. Biomed. Eng.; citation_title=Adaptive adversarial neural networks for the analysis of lossy and domain-shifted datasets of medical images; citation_author=MK Kanakasabapathy; citation_volume=5; citation_publication_date=2021; citation_pages=571-585; citation_doi=10.1038/s41551-021-00733-w; citation_id=CR64"/>
    <meta name="citation_reference" content="Bowles, C., Gunn, R., Hammers, A. &amp; Rueckert, D. Modelling the progression of Alzheimer&#8217;s disease in MRI using generative adversarial networks. In Medical Imaging 2018: Image Processing (eds. Angelini, E. D. &amp; Landman, B. A.) 397&#8211; 407 (International Society for Optics and Photonics, 2018)."/>
    <meta name="citation_reference" content="Ravi, D., Alexander, D.C., Oxtoby, N.P. &amp; Alzheimer&#8217;s Disease Neuroimaging Initiative. Degenerative adversarial neuroImage nets: generating images that mimic disease progression. In Medical Image Computing and Computer Assisted Intervention &#8212; MICCAI 2019. Lecture Notes in Computer Science. (eds Shen, D. et al) 164&#8211;172 (Springer, 2019)."/>
    <meta name="citation_reference" content="citation_journal_title=Comput. Vis. Image Underst.; citation_title=Pros and cons of GAN evaluation measures; citation_author=A Borji; citation_volume=179; citation_publication_date=2019; citation_pages=41-65; citation_doi=10.1016/j.cviu.2018.10.009; citation_id=CR67"/>
    <meta name="citation_reference" content="Vincent, J. Nvidia uses AI to make it snow on streets that are always sunny. The Verge 
                  https://www.theverge.com/2017/12/5/16737260/ai-image-translation-nvidia-data-self-driving-cars
                  
                 (2017)."/>
    <meta name="citation_reference" content="Kairouz, P. et al. Advances and open problems in federated learning. Found. Trends Mach. Learn. 
                  https://doi.org/10.1561/2200000083
                  
                 (2021)"/>
    <meta name="citation_reference" content="McMahan, B., Moore, E., Ramage, D., Hampson, S. &amp; Aguera y Arcas, B. Communication-efficient learning of deep networks from decentralized data. In Proceedings of the 20th International Conference on Artificial Intelligence and Statistics (eds. Singh, A. &amp; Zhu, J.) 1273&#8211;1282 (ML Research Press, 2017)."/>
    <meta name="citation_reference" content="citation_journal_title=Med. Image Anal.; citation_title=Multi-site fMRI analysis using privacy-preserving federated learning and domain adaptation: ABIDE results; citation_author=X Li; citation_volume=65; citation_publication_date=2020; citation_pages=101765; citation_doi=10.1016/j.media.2020.101765; citation_id=CR71"/>
    <meta name="citation_reference" content="citation_journal_title=Int. J. Med. Inform.; citation_title=Federated learning of predictive models from federated Electronic Health Records; citation_author=TS Brisimi; citation_volume=112; citation_publication_date=2018; citation_pages=59-67; citation_doi=10.1016/j.ijmedinf.2018.01.007; citation_id=CR72"/>
    <meta name="citation_reference" content="citation_journal_title=JMIR Med. Inform.; citation_title=Privacy-preserving patient similarity learning in a federated environment: development and analysis; citation_author=J Lee; citation_volume=6; citation_publication_date=2018; citation_pages=e20; citation_doi=10.2196/medinform.7744; citation_id=CR73"/>
    <meta name="citation_reference" content="citation_journal_title=npj Digit. Med.; citation_title=Federated deep learning for detecting COVID-19 lung abnormalities in CT: a privacy-preserving multinational validation study; citation_author=Q Dou; citation_volume=4; citation_publication_date=2021; citation_pages=60; citation_doi=10.1038/s41746-021-00431-6; citation_id=CR74"/>
    <meta name="citation_reference" content="Silva, S. et al. Federated learning in distributed medical databases: meta-analysis of large-scale subcortical brain data. In 2019 IEEE 16th International Symposium on Biomedical Imaging ISBI 2019 18822077 (IEEE, 2019)."/>
    <meta name="citation_reference" content="citation_journal_title=Brainlesion; citation_title=Multi-institutional deep learning modeling without sharing patient data: a feasibility study on brain tumor segmentation; citation_author=MJ Sheller, GA Reina, B Edwards, J Martin, S Bakas; citation_volume=11383; citation_publication_date=2019; citation_pages=92-104; citation_id=CR76"/>
    <meta name="citation_reference" content="citation_journal_title=Sci. Rep.; citation_title=Federated learning in medicine: facilitating multi-institutional collaborations without sharing patient data; citation_author=MJ Sheller; citation_volume=10; citation_publication_date=2020; citation_doi=10.1038/s41598-020-69250-1; citation_id=CR77"/>
    <meta name="citation_reference" content="citation_journal_title=J. Am. Med. Inform. Assoc.; citation_title=Federated learning improves site performance in multicenter deep learning without data sharing; citation_author=KV Sarma; citation_volume=28; citation_publication_date=2021; citation_pages=1259-1264; citation_doi=10.1093/jamia/ocaa341; citation_id=CR78"/>
    <meta name="citation_reference" content="Li, W. et al. Privacy-preserving federated brain tumour segmentation. In Machine Learning in Medical Imaging (eds. Suk, H.-I., Liu, M., Yan, P. &amp; Lian, C.) 133&#8211;141 (Springer International Publishing, 2019)."/>
    <meta name="citation_reference" content="Shokri, R., Stronati, M., Song, C. &amp; Shmatikov, V. Membership inference attacks against machine learning models. In IEEE Symposium on Security and Privacy SP 2017 3&#8211;18 (IEEE, 2017)."/>
    <meta name="citation_reference" content="Fredrikson, M., Jha, S. &amp; Ristenpart, T. Model inversion attacks that exploit confidence information and basic countermeasures. In Proceedings of the 22nd ACM SIGSAC Conference on Computer and Communications Security 1322&#8211;1333 (Association for Computing Machinery, 2015)."/>
    <meta name="citation_reference" content="citation_journal_title=Commun. ACM; citation_title=Understanding deep learning (still) requires rethinking generalization; citation_author=C Zhang, S Bengio, M Hardt, B Recht, O Vinyals; citation_volume=64; citation_publication_date=2021; citation_pages=107-115; citation_doi=10.1145/3446776; citation_id=CR82"/>
    <meta name="citation_reference" content="Zhu, L., Liu, Z. &amp; Han, S. Deep leakage from gradients. In Advances in Neural Information Processing Systems 32 (eds Wallach, H. et al.) Paper 8389 (Curran, 2019)"/>
    <meta name="citation_reference" content="Abadi, M. et al. Deep learning with differential privacy. In Proceedings of the 2016 ACM SIGSAC Conference on Computer and Communications Security 308&#8211;318 (Association for Computing Machinery, 2016)."/>
    <meta name="citation_reference" content="Brendan McMahan, H. et al. A general approach to adding differential privacy to iterative training procedures. Preprint at 
                  https://arxiv.org/abs/1812.06210v2
                  
                 (2018)."/>
    <meta name="citation_reference" content="McMahan, H. B., Ramage, D., Talwar, K. &amp; Zhang, L. Learning differentially private recurrent language models. In ICLR 2018 Sixth International Conference on Learning Representations Paper 504 (ICLR, 2018)."/>
    <meta name="citation_reference" content="Shokri, R. &amp; Shmatikov, V. Privacy-preserving deep learning. In Proceedings of the 22nd ACM SIGSAC Conference on Computer and Communications Security 1310&#8211;1321 (Association for Computing Machinery, 2015)."/>
    <meta name="citation_reference" content="citation_journal_title=Proc. VLDB Endow.; citation_title=Understanding the sparse vector technique for differential privacy; citation_author=M Lyu, D Su, N Li; citation_volume=10; citation_publication_date=2017; citation_pages=637-648; citation_doi=10.14778/3055330.3055331; citation_id=CR88"/>
    <meta name="citation_reference" content="Hitaj, B., Ateniese, G. &amp; Perez-Cruz, F. Deep models under the GAN: information leakage from collaborative deep learning. In Proceedings of the 2017 ACM SIGSAC Conference on Computer and Communications Security 603&#8211;618 (Association for Computing Machinery, 2017)."/>
    <meta name="citation_reference" content="Li, X., Huang, K., Yang, W., Wang, S. &amp; Zhang, Z. On the convergence of FedAvg on Non-IID Data. In ICLR 2020 Eighth International Conference on Learning Representations Paper 261 (2020)."/>
    <meta name="citation_reference" content="Smith, V., Chiang, C.-K., Sanjabi, M. &amp; Talwalkar, A. S. Federated multi-task learning. In Advances in Neural Information Processing Systems 30 (eds Guyon, I. et al.) Paper 2307 (NeuIPS, 2017)."/>
    <meta name="citation_reference" content="citation_journal_title=J. Healthc. Inform. Res.; citation_title=Federated learning for healthcare informatics; citation_author=J Xu; citation_volume=5; citation_publication_date=2021; citation_pages=1-19; citation_doi=10.1007/s41666-020-00082-4; citation_id=CR92"/>
    <meta name="citation_reference" content="citation_journal_title=PLoS ONE; citation_title=LoAdaBoost: loss-based AdaBoost federated machine learning with reduced computational complexity on IID and non-IID intensive care data; citation_author=L Huang; citation_volume=15; citation_publication_date=2020; citation_pages=e0230706; citation_doi=10.1371/journal.pone.0230706; citation_id=CR93"/>
    <meta name="citation_reference" content="Zhao, Y. et al. Federated learning with non-IID data. Preprint at 
                  https://arxiv.org/abs/1806.00582v1
                  
                 (2018)."/>
    <meta name="citation_reference" content="citation_journal_title=npj Digit. Med.; citation_title=Multi-task deep learning for cardiac rhythm detection in wearable devices; citation_author=J Torres-Soto, EA Ashley; citation_volume=3; citation_publication_date=2020; citation_pages=116; citation_doi=10.1038/s41746-020-00320-4; citation_id=CR95"/>
    <meta name="citation_reference" content="citation_journal_title=Am. Heart J.; citation_title=Rationale and design of a large-scale, app-based study to identify cardiac arrhythmias using a smartwatch: The Apple Heart Study; citation_author=MP Turakhia; citation_volume=207; citation_publication_date=2019; citation_pages=66-75; citation_doi=10.1016/j.ahj.2018.09.002; citation_id=CR96"/>
    <meta name="citation_reference" content="Synced. Apple reveals design of its on-device ML system for federated evaluation and tuning SyncedReview 
                  https://syncedreview.com/2021/02/19/apple-reveals-design-of-its-on-device-ml-system-for-federated-evaluation-and-tuning
                  
                 (2021)."/>
    <meta name="citation_reference" content="McMahan, B. &amp; Ramage, D. Federated learning: collaborative machine learning without centralized training data Google AI Blog 
                  https://ai.googleblog.com/2017/04/federated-learning-collaborative.html
                  
                 (2017)."/>
    <meta name="citation_reference" content="citation_journal_title=IEEE Intell. Syst.; citation_title=FedHealth: a federated transfer learning framework for wearable healthcare; citation_author=Y Chen, X Qin, J Wang, C Yu, W Gao; citation_volume=35; citation_publication_date=2020; citation_pages=83-93; citation_doi=10.1109/MIS.2020.2988604; citation_id=CR99"/>
    <meta name="citation_reference" content="Ramage, D. &amp; Mazzocchi, S. Federated analytics: collaborative data science without data collection Google AI Blog 
                  https://ai.googleblog.com/2020/05/federated-analytics-collaborative-data.html
                  
                 (2020)."/>
    <meta name="citation_reference" content="Augenstein, S. et al. Generative models for effective ML on private, decentralized datasets. In ICLR 2020 Eighth International Conference on Learning Representations Paper 1448 (ICLR, 2020)."/>
    <meta name="citation_reference" content="Pati, S. et al. The federated tumor segmentation (FeTS) challenge. Preprint at 
                  https://arxiv.org/abs/2105.05874v2
                  
                 (2021)."/>
    <meta name="citation_reference" content="Flores, M. Medical institutions collaborate to improve mammogram assessment AI with Nvidia Clara federated learning The AI Podcast 
                  https://blogs.nvidia.com/blog/2020/04/15/federated-learning-mammogram-assessment/
                  
                 (2020)."/>
    <meta name="citation_reference" content="Kannan, A., Chen, K., Jaunzeikare, D. &amp; Rajkomar, A. Semi-supervised learning for information extraction from dialogue. In Proc. Interspeech 2018 2077&#8211;2081 (ISCA, 2018); 
                  https://doi.org/10.21437/interspeech.2018-1318
                  
                "/>
    <meta name="citation_reference" content="Chiu, C.-C. et al. Speech recognition for medical conversations. Preprint at 
                  https://arxiv.org/abs/1711.07274v2
                  
                ; 
                  https://doi.org/10.1093/jamia/ocx073
                  
                 (2017)."/>
    <meta name="citation_reference" content="citation_journal_title=J. Am. Med. Inform. Assoc.; citation_title=Enhancing clinical concept extraction with contextual embeddings; citation_author=Y Si, J Wang, H Xu, K Roberts; citation_volume=26; citation_publication_date=2019; citation_pages=1297-1304; citation_doi=10.1093/jamia/ocz096; citation_id=CR106"/>
    <meta name="citation_reference" content="Shin, H.-C. et al. Learning to read chest X-rays: recurrent neural cascade model for automated image annotation. In 2016 IEEE Conference on Computer Vision and Pattern Recognition (CVPR) (IEEE, 2016); 
                  https://doi.org/10.1109/cvpr.2016.274
                  
                "/>
    <meta name="citation_reference" content="Wang, X., Peng, Y., Lu, L., Lu, Z. &amp; Summers, R. M. TieNet: text-image embedding network for common thorax disease classification and reporting in chest X-rays. In IEEE/CVF Conference on Computer Vision and Pattern Recognition 2018 (IEEE, 2018); 
                  https://doi.org/10.1109/cvpr.2018.00943
                  
                "/>
    <meta name="citation_reference" content="citation_journal_title=Neural Comput.; citation_title=Long short-term memory; citation_author=S Hochreiter, J Schmidhuber; citation_volume=9; citation_publication_date=1997; citation_pages=1735-1780; citation_doi=10.1162/neco.1997.9.8.1735; citation_id=CR109"/>
    <meta name="citation_reference" content="Cho, K. et al. Learning phrase representations using RNN encoder-decoder for statistical machine translation. In Proceedings of the 2014 Conference on Empirical Methods in Natural Language Processing (EMNLP) (eds Moschitti, A., Pang, B. &amp; Daelemans, W.) 1724&#8211;1734 (Association for Computational Linguistics, 2014)."/>
    <meta name="citation_reference" content="Lipton, Z. C., Kale, D. C., Elkan, C. &amp; Wetzel, R. Learning to diagnose with LSTM recurrent neural networks. Preprint at 
                  https://arxiv.org/abs/1511.03677v7
                  
                 (2015)."/>
    <meta name="citation_reference" content="citation_journal_title=JMLR Workshop Conf. Proc.; citation_title=Doctor AI: predicting clinical events via recurrent neural networks; citation_author=E Choi, MT Bahadori, A Schuetz, WF Stewart, J Sun; citation_volume=56; citation_publication_date=2016; citation_pages=301-318; citation_id=CR112"/>
    <meta name="citation_reference" content="Zhu, Paschalidis &amp; Tahmasebi. Clinical concept extraction with contextual word embedding. Preprint at 
                  https://doi.org/10.48550/arXiv.1810.10566
                  
                 (2018)."/>
    <meta name="citation_reference" content="Cho, K., van Merri&#235;nboer, B., Bahdanau, D. &amp; Bengio, Y. On the properties of neural machine translation: encoder&#8211;decoder approaches. In Proceedings of SSST-8, Eighth Workshop on Syntax, Semantics and Structure in Statistical Translation (eds Wu, D., Carpuat, M., Carreras, X. &amp; Vecchi, E. M.) 103&#8211;111 (Association for Computational Linguistics, 2014)."/>
    <meta name="citation_reference" content="Gehring, J., Auli, M., Grangier, D., Yarats, D. &amp; Dauphin, Y. N. Convolutional sequence to sequence learning. In Proceedings of the 34th International Conference on Machine Learning (eds Precup, D. &amp; Teh, Y. W.) 1243&#8211;1252 (PMLR, 2017)."/>
    <meta name="citation_reference" content="Vaswani, A. et al. Attention is all you need. In Advances in Neural Information Processing Systems 30 (eds Guyon, I. et al.) Paper 3058 (Curran, 2017)."/>
    <meta name="citation_reference" content="Bahdanau, D., Cho, K. H. &amp; Bengio, Y. Neural machine translation by jointly learning to align and translate. In 3rd International Conference on Learning Representations ICLR 2015 (ICLR, 2015)."/>
    <meta name="citation_reference" content="Luong, T., Pham, H. &amp; Manning, C. D. Effective approaches to attention-based neural machine translation. In Proceedings of the 2015 Conference on Empirical Methods in Natural Language Processing (eds M&#224;rquez, L., Callison-Burch, C. &amp; Su, J.) 1412&#8211;1421 (Association for Computational Linguistics, 2015); 
                  https://doi.org/10.18653/v1/d15-1166
                  
                "/>
    <meta name="citation_reference" content="Sutskever, I., Vinyals, O. &amp; Le, Q. V. Sequence to sequence learning with neural networks. In Advances in Neural Information Processing Systems 27 (eds Ghahramani, Z., Welling, M., Cortes, C., Lawrence, N. &amp; Weinberger, K. Q.) Paper 1610 (Curran, 2014)."/>
    <meta name="citation_reference" content="Krizhevsky, A., Sutskever, I. &amp; Hinton, G. E. in Advances in Neural Information Processing Systems 25 (eds Bartlett, P. et al.) 1097&#8211;1105 (Curran, 2012)."/>
    <meta name="citation_reference" content="citation_journal_title=npj Digit. Med.; citation_title=Impact of a deep learning assistant on the histopathologic classification of liver cancer; citation_author=A Kiani; citation_volume=3; citation_publication_date=2020; citation_pages=23; citation_doi=10.1038/s41746-020-0232-8; citation_id=CR121"/>
    <meta name="citation_reference" content="citation_journal_title=Nat. Biomed. Eng.; citation_title=A mountable toilet system for personalized health monitoring via the analysis of excreta; citation_author=S-M Park; citation_volume=4; citation_publication_date=2020; citation_pages=624-635; citation_doi=10.1038/s41551-020-0534-9; citation_id=CR122"/>
    <meta name="citation_reference" content="Howard, J. &amp; Ruder, S. Universal language model fine-tuning for text classification. In Proceedings of the 56th Annual Meeting of the Association for Computational Linguistics (eds Gurevych, I. &amp; Miyao, Y.) 328&#8211;339 (Association for Computational Linguistics, 2018)."/>
    <meta name="citation_reference" content="Peters, M. E. et al. Deep contextualized word representations. In Proceedings of the 2018 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies (eds Walker, M., Ji, H. &amp; Stent, A.) 2227&#8211;2237 (Association for Computational Linguistics, 2018)."/>
    <meta name="citation_reference" content="Brown, T. et al. Language models are few-shot learners. In Advances in Neural Information Processing Systems 33 (eds. Larochelle, H., Ranzato, M., Hadsell, R., Balcan, M. F. &amp; Lin, H.) 1877&#8211;1901 (Curran, 2020)."/>
    <meta name="citation_reference" content="Kenton, J. D. M.-W. C. &amp; Toutanova, L. K. BERT: pre-training of deep bidirectional transformers for language understanding. in Proceedings of the 2019 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies (eds Burstein, J., Doran, C. &amp; Solorio, T.) 4171&#8211;4186 (Association for Computational Linguistics, 2019)."/>
    <meta name="citation_reference" content="Mikolov, T., Chen, K., Corrado, G. &amp; Dean, J. Efficient estimation of word representations in vector space. Preprint at 
                  https://arxiv.org/abs/1301.3781v3
                  
                 (2013)."/>
    <meta name="citation_reference" content="Pennington, J., Socher, R. &amp; Manning, C. GloVe: global vectors for word representation. In Proceedings of the 2014 Conference on Empirical Methods in Natural Language Processing (eds Moschitti, A., Pang, B., Daelemans, W.) 1532&#8211;1543 (Association for Computational Linguistics, 2014)."/>
    <meta name="citation_reference" content="Alsentzer, E. et al. Publicly available clinical BERT embeddings. In Proceedings of the 2nd Clinical Natural Language Processing Workshop (eds Rumshisky, A., Roberts, K., Bethard, S. &amp; Naumann, T.) 72&#8211;78 (Association for Computational Linguistics, 2019)."/>
    <meta name="citation_reference" content="Huang, K., Altosaar, J. &amp; Ranganath, R. ClinicalBERT: modeling clinical notes and predicting hospital readmission. Preprint at 
                  https://arxiv.org/abs/1904.05342v3
                  
                 (2019)."/>
    <meta name="citation_reference" content="Peng, Y., Yan, S. &amp; Lu, Z. Transfer learning in biomedical natural language processing: an evaluation of BERT and ELMo on ten benchmarking datasets. In Proceedings of the 18th BioNLP Workshop and Shared Task (eds Demner-Fushman, D., Bretonnel Cohen, K., Ananiadou, S. &amp; Tsujii, J.) 58&#8211;65 (Association for Computational Linguistics, 2019)."/>
    <meta name="citation_reference" content="citation_journal_title=Sci. Data; citation_title=MIMIC-III, a freely accessible critical care database; citation_author=AEW Johnson; citation_volume=3; citation_publication_date=2016; citation_doi=10.1038/sdata.2016.35; citation_id=CR132"/>
    <meta name="citation_reference" content="Sharir, O., Peleg, B. &amp; Shoham, Y. The cost of training NLP models: a concise overview. Preprint at 
                  https://arxiv.org/abs/2004.08900v1
                  
                 (2020)."/>
    <meta name="citation_reference" content="citation_journal_title=Bioinformatics; citation_title=BioBERT: a pre-trained biomedical language representation model for biomedical text mining; citation_author=J Lee; citation_volume=36; citation_publication_date=2020; citation_pages=1234-1240; citation_doi=10.1093/bioinformatics/btz682; citation_id=CR134"/>
    <meta name="citation_reference" content="Beltagy, I., Lo, K. &amp; Cohan, A. SciBERT: A pretrained language model for scientific text. In Proceedings of the 2019 Conference on Empirical Methods in Natural Language Processing and the 9th International Joint Conference on Natural Language Processing (eds Inui, K., Jiang, J., Ng, V. &amp; Wan, X.) 3615&#8211;3620 (Association for Computational Linguistics, 2019)."/>
    <meta name="citation_reference" content="citation_journal_title=J. Biomed. Inform.; citation_title=A comparison of models for predicting early hospital readmissions; citation_author=J Futoma, J Morris, J Lucas; citation_volume=56; citation_publication_date=2015; citation_pages=229-238; citation_doi=10.1016/j.jbi.2015.05.016; citation_id=CR136"/>
    <meta name="citation_reference" content="Caruana, R. et al. Intelligible models for healthcare: predicting pneumonia risk and hospital 30-day readmission. In Proc. 21st ACM SIGKDD International Conference on Knowledge Discovery and Data Mining 1721&#8211;1730 (Association for Computing Machinery, 2015)."/>
    <meta name="citation_reference" content="citation_journal_title=Elife; citation_title=Augmented curation of clinical notes from a massive EHR system reveals symptoms of impending COVID-19 diagnosis; citation_author=T Wagner; citation_volume=9; citation_publication_date=2020; citation_pages=e58227; citation_doi=10.7554/eLife.58227; citation_id=CR138"/>
    <meta name="citation_reference" content="Eisman, A. S. et al. Extracting angina symptoms from clinical notes using pre-trained transformer architectures. AMIA Annu. Symp. Proc. 2020, 412&#8211;421 (American Medical Informatics Association, 2020)."/>
    <meta name="citation_reference" content="Smit, A. et al. Combining automatic labelers and expert annotations for accurate radiology report labeling using BERT. In Proceedings of the 2020 Conference on Empirical Methods in Natural Language Processing (eds Webber, B., Cohn, T., He, Y. &amp; Liu, Y.) 1500&#8211;1519 (Association for Computational Linguistics, 2020)."/>
    <meta name="citation_reference" content="Soni, S. &amp; Roberts, K. Evaluation of dataset selection for pre-training and fine-tuning transformer language models for clinical question answering. In Proc. 12th Language Resources and Evaluation Conference 5532&#8211;5538 (European Language Resources Association, 2020)."/>
    <meta name="citation_reference" content="citation_journal_title=npj Digit. Med.; citation_title=Readiness for voice assistants to support healthcare delivery during a health crisis and pandemic; citation_author=E Sezgin, Y Huang, U Ramtekkar, S Lin; citation_volume=3; citation_publication_date=2020; citation_pages=122; citation_doi=10.1038/s41746-020-00332-0; citation_id=CR142"/>
    <meta name="citation_reference" content="citation_journal_title=Int. J. Commun. Computer Technol.; citation_title=Integrated platform and response system for healthcare using Alexa; citation_author=V Sakthive, MPV Kesaven, JM William, SKM Kumar; citation_volume=7; citation_publication_date=2019; citation_pages=14-22; citation_id=CR143"/>
    <meta name="citation_reference" content="Comstock, J. Buoy Health, CVS MinuteClinic partner to send patients from chatbot to care. mobihealthnews 
                  https://www.mobihealthnews.com/content/buoy-health-cvs-minuteclinic-partner-send-patients-chatbot-care
                  
                 (2018)."/>
    <meta name="citation_reference" content="Razzaki, S. et al. A comparative study of artificial intelligence and human doctors for the purpose of triage and diagnosis. Preprint at 
                  https://doi.org/10.48550/arXiv.1806.10698
                  
                 (2018)."/>
    <meta name="citation_reference" content="Xiong, Y., Du, B. &amp; Yan, P. Reinforced transformer for medical image captioning. In Machine Learning in Medical Imaging (eds. Suk, H.-I., Liu, M., Yan, P. &amp; Lian, C.) 673&#8211;680 (Springer International Publishing, 2019)."/>
    <meta name="citation_reference" content="citation_journal_title=IEEE J. Biomed. Health Inform.; citation_title=Bidirectional representation learning from transformers using multimodal electronic health record data to predict depression; citation_author=Y Meng, W Speier, MK Ong, CW Arnold; citation_volume=25; citation_publication_date=2021; citation_pages=3121-3129; citation_doi=10.1109/JBHI.2021.3063721; citation_id=CR147"/>
    <meta name="citation_reference" content="citation_journal_title=Proc. Conf. AAAI Artif. Intell.; citation_title=Learning the graphical structure of electronic health records with graph convolutional transformer; citation_author=E Choi; citation_volume=34; citation_publication_date=2020; citation_pages=606-613; citation_id=CR148"/>
    <meta name="citation_reference" content="citation_journal_title=JMIR Med. Inform.; citation_title=Fine-tuning bidirectional encoder representations from transformers (BERT)&#8211;based models on large-scale electronic health record notes: an empirical study; citation_author=F Li; citation_volume=7; citation_publication_date=2019; citation_pages=e14830; citation_doi=10.2196/14830; citation_id=CR149"/>
    <meta name="citation_reference" content="citation_journal_title=npj Digital Medicine; citation_title=Med-BERT: pretrained contextualized embeddings on large-scale structured electronic health records for disease prediction; citation_author=L Rasmy, Y Xiang, Z Xie, C Tao, D Zhi; citation_volume=4; citation_publication_date=2021; citation_pages=86; citation_doi=10.1038/s41746-021-00455-y; citation_id=CR150"/>
    <meta name="citation_reference" content="Shang, J., Ma, T., Xiao, C. &amp; Sun, J. Pre-training of graph augmented transformers for medication recommendation. in Proceedings of the Twenty-Eighth International Joint Conference on Artificial Intelligence (ed. Kraus, S.) 5953&#8211;5959 (International Joint Conferences on Artificial Intelligence Organization, 2019); 
                  https://doi.org/10.24963/ijcai.2019/825
                  
                "/>
    <meta name="citation_reference" content="citation_journal_title=Sci. Rep.; citation_title=BEHRT: transformer for electronic health records; citation_author=Y Li; citation_volume=10; citation_publication_date=2020; citation_doi=10.1038/s41598-020-62922-y; citation_id=CR152"/>
    <meta name="citation_reference" content="citation_journal_title=Eur. Heart J.; citation_title=BEHRT-HF: an interpretable transformer-based, deep learning model for prediction of incident heart failure; citation_author=S Rao; citation_volume=41; citation_issue=Suppl. 2; citation_publication_date=2020; citation_pages=ehaa946.3553; citation_doi=10.1093/ehjci/ehaa946.3553; citation_id=CR153"/>
    <meta name="citation_reference" content="citation_journal_title=Nat. Biomed. Eng.; citation_title=Prospective assessment of breast cancer risk from multimodal multiview ultrasound images via clinically applicable deep learning; citation_author=X Qian; citation_volume=5; citation_publication_date=2021; citation_pages=522-532; citation_doi=10.1038/s41551-021-00711-2; citation_id=CR154"/>
    <meta name="citation_reference" content="Xing, L., Giger, M. L. &amp; Min, J. K. Artificial Intelligence in Medicine: Technical Basis and Clinical Applications (Academic Press, 2020)."/>
    <meta name="citation_reference" content="citation_journal_title=P. T.; citation_title=EHRs: the challenge of making electronic data usable and interoperable; citation_author=M Reisman; citation_volume=42; citation_publication_date=2017; citation_pages=572-575; citation_id=CR156"/>
    <meta name="citation_reference" content="citation_journal_title=Procedia Comput. Sci.; citation_title=Stream processing of healthcare sensor data: studying user traces to identify challenges from a big data perspective; citation_author=R Cort&#233;s, X Bonnaire, O Marin, P Sens; citation_volume=52; citation_publication_date=2015; citation_pages=1004-1009; citation_doi=10.1016/j.procs.2015.05.093; citation_id=CR157"/>
    <meta name="citation_reference" content="citation_journal_title=Future Gener. Comput. Syst.; citation_title=A task-level adaptive MapReduce framework for real-time streaming data in healthcare applications; citation_author=F Zhang, J Cao, SU Khan, K Li, K Hwang; citation_volume=43&#8211;44; citation_publication_date=2015; citation_pages=149-160; citation_doi=10.1016/j.future.2014.06.009; citation_id=CR158"/>
    <meta name="citation_reference" content="citation_journal_title=Adv. Bioinformatics; citation_title=Big data management for healthcare systems: architecture, requirements, and implementation; citation_author=N El Aboudi, L Benhlima; citation_volume=2018; citation_publication_date=2018; citation_pages=4059018; citation_doi=10.1155/2018/4059018; citation_id=CR159"/>
    <meta name="citation_reference" content="Ta, V.-D., Liu, C.-M. &amp; Nkabinde, G. W. Big data stream computing in healthcare real-time analytics. In IEEE International Conference on Cloud Computing and Big Data Analysis (ICCCBDA) 37&#8211;42 (ieeexplore.ieee.org, 2016)."/>
    <meta name="citation_reference" content="Data-Driven Healthcare Organizations Use Big Data Analytics for Big Gains White Paper (IBM Software, 2017); 
                  https://silo.tips/download/ibm-software-white-paper-data-driven-healthcare-organizations-use-big-data-analy
                  
                "/>
    <meta name="citation_reference" content="citation_journal_title=Lancet Digit. Health; citation_title=The myth of generalisability in clinical research and machine learning in health care; citation_author=J Futoma, M Simons, T Panch, F Doshi-Velez, LA Celi; citation_volume=2; citation_publication_date=2020; citation_pages=e489-e492; citation_doi=10.1016/S2589-7500(20)30186-2; citation_id=CR162"/>
    <meta name="citation_reference" content="citation_journal_title=J. Am. Coll. Radiol.; citation_title=Inconsistent performance of deep learning models on mammogram classification; citation_author=X Wang; citation_volume=17; citation_publication_date=2020; citation_pages=796-803; citation_doi=10.1016/j.jacr.2020.01.006; citation_id=CR163"/>
    <meta name="citation_reference" content="Nestor, B., McDermott, M. B. A. &amp; Boag, W. Feature robustness in non-stationary health records: caveats to deployable model performance in common clinical machine learning tasks. Preprint at 
                  https://doi.org/10.48550/arXiv.1908.00690
                  
                 (2019)."/>
    <meta name="citation_reference" content="Wu, E. et al. How medical AI devices are evaluated: limitations and recommendations from an analysis of FDA approvals. Nat. Med. 
                  https://doi.org/10.1038/s41591-021-01312-x
                  
                 (2021)."/>
    <meta name="citation_reference" content="citation_journal_title=Nat. Mach. Intell.; citation_title=External validation demonstrates limited clinical utility of the interpretable mortality prediction model for patients with COVID-19; citation_author=M Barish, S Bolourani, LF Lau, S Shah, TP Zanos; citation_volume=3; citation_publication_date=2020; citation_pages=25-27; citation_doi=10.1038/s42256-020-00254-2; citation_id=CR166"/>
    <meta name="citation_reference" content="citation_journal_title=J. Am. Med. Inform. Assoc.; citation_title=Calibration drift in regression and machine learning models for acute kidney injury; citation_author=SE Davis, TA Lasko, G Chen, ED Siew, ME Matheny; citation_volume=24; citation_publication_date=2017; citation_pages=1052-1061; citation_doi=10.1093/jamia/ocx030; citation_id=CR167"/>
    <meta name="citation_reference" content="citation_journal_title=Nat. Biomed. Eng.; citation_title=A deep-learning pipeline for the diagnosis and discrimination of viral, non-viral and COVID-19 pneumonia from chest X-ray images; citation_author=G Wang; citation_volume=5; citation_publication_date=2021; citation_pages=509-521; citation_doi=10.1038/s41551-021-00704-1; citation_id=CR168"/>
    <meta name="citation_reference" content="citation_journal_title=Nat. Biomed. Eng.; citation_title=Open resource of clinical data from patients with pneumonia for the prediction of COVID-19 outcomes via deep learning; citation_author=W Ning; citation_volume=4; citation_publication_date=2020; citation_pages=1197-1207; citation_doi=10.1038/s41551-020-00633-5; citation_id=CR169"/>
    <meta name="citation_reference" content="citation_journal_title=Proc. Natl Acad. Sci. USA; citation_title=Racial disparities in automated speech recognition; citation_author=A Koenecke; citation_volume=117; citation_publication_date=2020; citation_pages=7684-7689; citation_doi=10.1073/pnas.1915768117; citation_id=CR170"/>
    <meta name="citation_reference" content="citation_journal_title=Nat. Mach. Intell.; citation_title=Large language models associate muslims with violence; citation_author=A Abid, M Farooqi, J Zou; citation_volume=3; citation_publication_date=2021; citation_pages=461-463; citation_doi=10.1038/s42256-021-00359-2; citation_id=CR171"/>
    <meta name="citation_reference" content="citation_journal_title=Science; citation_title=Dissecting racial bias in an algorithm used to manage the health of populations; citation_author=Z Obermeyer, B Powers, C Vogeli, S Mullainathan; citation_volume=366; citation_publication_date=2019; citation_pages=447-453; citation_doi=10.1126/science.aax2342; citation_id=CR172"/>
    <meta name="citation_reference" content="citation_journal_title=JAMA Dermatol; citation_title=Machine learning and health care disparities in dermatology; citation_author=AS Adamson, A Smith; citation_volume=154; citation_publication_date=2018; citation_pages=1247-1248; citation_doi=10.1001/jamadermatol.2018.2348; citation_id=CR173"/>
    <meta name="citation_reference" content="citation_journal_title=J. Invest. Dermatol.; citation_title=Classification of the clinical images for benign and malignant cutaneous tumors using a deep learning algorithm; citation_author=SS Han; citation_volume=138; citation_publication_date=2018; citation_pages=1529-1538; citation_doi=10.1016/j.jid.2018.01.028; citation_id=CR174"/>
    <meta name="citation_reference" content="Subbaswamy, A., Adams, R. &amp; Saria, S. Evaluating model robustness and stability to dataset shift. In Proceedings of The 24th International Conference on Artificial Intelligence and Statistics (eds. Banerjee, A. &amp; Fukumizu, K.) 2611&#8211;2619 (PMLR, 2021)."/>
    <meta name="citation_reference" content="Izzo, Z., Ying, L. &amp; Zou, J. How to learn when data reacts to your model: performative gradient descent. In Proceedings of the 38th International Conference on Machine Learning (eds. Meila, M. &amp; Zhang, T.) 4641&#8211;4650 (PMLR, 2021)."/>
    <meta name="citation_reference" content="Ghorbani, A., Kim, M. &amp; Zou, J. A Distributional framework for data valuation. In Proceedings of the 37th International Conference on Machine Learning (eds. Iii, H. D. &amp; Singh, A.) 3535&#8211;3544 (PMLR, 2020)."/>
    <meta name="citation_reference" content="Zhang, L., Deng, Z., Kawaguchi, K., Ghorbani, A. &amp; Zou, J. How does mixup help with robustness and generalization? In International Conference on Learning Representations 2021 Paper 2273 (ICLR, 2021)."/>
    <meta name="citation_reference" content="Schulam, P. &amp; Saria, S. Can you trust this prediction? Auditing pointwise reliability after learning. In Proceedings of the Twenty-Second International Conference on Artificial Intelligence and Statistics (eds. Chaudhuri, K. &amp; Sugiyama, M.) 1022&#8211;1031 (PMLR, 2019)."/>
    <meta name="citation_reference" content="citation_journal_title=Nat. Med.; citation_title=Reporting guidelines for clinical trial reports for interventions involving artificial intelligence: the CONSORT-AI extension; citation_author=X Liu; citation_volume=26; citation_publication_date=2020; citation_pages=1364-1374; citation_doi=10.1038/s41591-020-1034-x; citation_id=CR180"/>
    <meta name="citation_reference" content="citation_journal_title=Nat. Med.; citation_title=Guidelines for clinical trial protocols for interventions involving artificial intelligence: the SPIRIT-AI extension; citation_author=S Cruz Rivera; citation_volume=26; citation_publication_date=2020; citation_pages=1351-1363; citation_doi=10.1038/s41591-020-1037-7; citation_id=CR181"/>
    <meta name="citation_reference" content="Nayak, P. Understanding searches better than ever before. Google The Keyword 
                  https://blog.google/products/search/search-language-understanding-bert/
                  
                 (2019)."/>
    <meta name="citation_reference" content="Baur, C., Albarqouni, S. &amp; Navab, N. in OR 2.0 Context-Aware Operating Theaters, Computer Assisted Robotic Endoscopy, Clinical Image-Based Procedures, and Skin Image Analysis (eds Stoyanov, D. et al.) 260&#8211;267 (Springer International Publishing, 2018)."/>
    <meta name="citation_reference" content="citation_journal_title=Med. Phys.; citation_title=Cycle-consistent adversarial denoising network for multiphase coronary CT angiography; citation_author=E Kang, HJ Koo, DH Yang, JB Seo, JC Ye; citation_volume=46; citation_publication_date=2019; citation_pages=550-562; citation_doi=10.1002/mp.13284; citation_id=CR184"/>
    <meta name="citation_reference" content="Vig, J. A multiscale visualization of attention in the transformer model. In Proceedings of the 57th Annual Meeting of the Association for Computational Linguistics: System Demonstrations (Costa-juss&#224;, M. R. &amp; Alfonseca, E.) 37&#8211;42 (Association for Computational Linguistics, 2019)."/>
    <meta name="citation_author" content="Zhang, Angela"/>
    <meta name="citation_author_institution" content="Stanford Cardiovascular Institute, School of Medicine, Stanford University, Stanford, USA"/>
    <meta name="citation_author_institution" content="Department of Genetics, School of Medicine, Stanford University, Stanford, USA"/>
    <meta name="citation_author_institution" content="Greenstone Biosciences, Palo Alto, USA"/>
    <meta name="citation_author_institution" content="Department of Computer Science, Stanford University, Stanford, USA"/>
    <meta name="citation_author" content="Xing, Lei"/>
    <meta name="citation_author_institution" content="Department of Radiation Oncology, School of Medicine, Stanford University, Stanford, USA"/>
    <meta name="citation_author" content="Zou, James"/>
    <meta name="citation_author_institution" content="Department of Computer Science, Stanford University, Stanford, USA"/>
    <meta name="citation_author_institution" content="Department of Biomedical Informatics, School of Medicine, Stanford University, Stanford, USA"/>
    <meta name="citation_author" content="Wu, Joseph C."/>
    <meta name="citation_author_institution" content="Stanford Cardiovascular Institute, School of Medicine, Stanford University, Stanford, USA"/>
    <meta name="citation_author_institution" content="Greenstone Biosciences, Palo Alto, USA"/>
    <meta name="citation_author_institution" content="Departments of Medicine, Division of Cardiovascular Medicine Stanford University, Stanford, USA"/>
    <meta name="citation_author_institution" content="Department of Radiology, School of Medicine, Stanford University, Stanford, USA"/>
    <meta name="access_endpoint" content="https://www.nature.com/platform/readcube-access"/>
    <meta name="twitter:site" content="@natBME"/>
    <meta name="twitter:card" content="summary_large_image"/>
    <meta name="twitter:image:alt" content="Content cover image"/>
    <meta name="twitter:title" content="Shifting machine learning for healthcare from development to deployment and from models to data"/>
    <meta name="twitter:description" content="Nature Biomedical Engineering - This Review discusses the use of deep generative models, federated learning and transformer models to address challenges in the deployment of machine learning for..."/>
    <meta name="twitter:image" content="https://media.springernature.com/full/springer-static/image/art%3A10.1038%2Fs41551-022-00898-y/MediaObjects/41551_2022_898_Fig1_HTML.png"/>
    

    
    
    <meta property="og:url" content="https://www.nature.com/articles/s41551-022-00898-y"/>
    <meta property="og:type" content="article"/>
    <meta property="og:site_name" content="Nature"/>
    <meta property="og:title" content="Shifting machine learning for healthcare from development to deployment and from models to data - Nature Biomedical Engineering"/>
    <meta property="og:description" content="This Review discusses the use of deep generative models, federated learning and transformer models to address challenges in the deployment of machine learning for healthcare."/>
    <meta property="og:image" content="https://media.springernature.com/m685/springer-static/image/art%3A10.1038%2Fs41551-022-00898-y/MediaObjects/41551_2022_898_Fig1_HTML.png"/>
    

    <script>
        window.eligibleForRa21 = 'true'; 
    </script>
</head>
<body class="article-page">

<div class="position-relative cleared z-index-50 background-white" data-test="top-containers">
    <a class="c-skip-link" href="#content">Skip to main content</a>



<div class="c-grade-c-banner u-hide">
    <div class="c-grade-c-banner__container">
        
        <p>Thank you for visiting nature.com. You are using a browser version with limited support for CSS. To obtain
            the best experience, we recommend you use a more up to date browser (or turn off compatibility mode in
            Internet Explorer). In the meantime, to ensure continued support, we are displaying the site without styles
            and JavaScript.</p>

    </div>
</div>

    

    

    
    
        <div class="u-hide u-show-following-ad"></div>

    <aside class="c-ad c-ad--728x90">
        <div class="c-ad__inner" data-container-type="banner-advert">
            <p class="c-ad__label">Advertisement</p>
            
        
            
    <div id="div-gpt-ad-top-1"
         class="div-gpt-ad advert leaderboard js-ad text-center hide-print grade-c-hide"
         data-ad-type="top"
         data-test="top-ad"
         data-pa11y-ignore
         data-gpt
         data-gpt-unitpath="/285/natbiomedeng.nature.com/article"
         data-gpt-sizes="728x90"
         data-gpt-targeting="type=article;pos=top;artid=s41551-022-00898-y;doi=10.1038/s41551-022-00898-y;subjmeta=1042,114,1305,1421,166,308,575,631,639,692,700,705,985;kwrd=Biomedical+engineering,Computational+science,Machine+learning,Medical+imaging,Translational+research">
        
        <script>
            window.SN = window.SN || {};
            window.SN.libs = window.SN.libs || {};
            window.SN.libs.ads = window.SN.libs.ads || {};
            window.SN.libs.ads.slotConfig = window.SN.libs.ads.slotConfig || {};
            
                window.SN.libs.ads.slotConfig['top'] = {
                    'pos': 'top',
                    'type': 'article',
                    'path': 's41551-022-00898-y'
                };
            
            
            window.SN.libs.ads.slotConfig['kwrd'] = 'Biomedical+engineering,Computational+science,Machine+learning,Medical+imaging,Translational+research';
            
            
            window.SN.libs.ads.slotConfig['subjmeta'] = '1042,114,1305,1421,166,308,575,631,639,692,700,705,985';
            
            
        </script>
        <noscript>
            <a href="//pubads.g.doubleclick.net/gampad/jump?iu=/285/natbiomedeng.nature.com/article&amp;sz=728x90&amp;c=-156904098&amp;t=pos%3Dtop%26type%3Darticle%26artid%3Ds41551-022-00898-y%26doi%3D10.1038/s41551-022-00898-y%26subjmeta%3D1042,114,1305,1421,166,308,575,631,639,692,700,705,985%26kwrd%3DBiomedical+engineering,Computational+science,Machine+learning,Medical+imaging,Translational+research">
                <img data-test="gpt-advert-fallback-img"
                     src="//pubads.g.doubleclick.net/gampad/ad?iu=/285/natbiomedeng.nature.com/article&amp;sz=728x90&amp;c=-156904098&amp;t=pos%3Dtop%26type%3Darticle%26artid%3Ds41551-022-00898-y%26doi%3D10.1038/s41551-022-00898-y%26subjmeta%3D1042,114,1305,1421,166,308,575,631,639,692,700,705,985%26kwrd%3DBiomedical+engineering,Computational+science,Machine+learning,Medical+imaging,Translational+research"
                     alt="Advertisement"
                     width="728"
                     height="90"></a>
        </noscript>
    </div>

        
    
        </div>
    </aside>


    <header class="c-header" id="header" data-header data-track-component="nature-150-split-header" style="border-color:#964091">
        <div class="c-header__row">
            <div class="c-header__container">
                <div class="c-header__split">
                    
                    
                    <div class="c-header__logo-container">
                        
                        <a href="/natbiomedeng"
                           data-track="click" data-track-action="home" data-track-label="image">
                            <picture class="c-header__logo">
                                <source srcset="https://media.springernature.com/full/nature-cms/uploads/product/natbiomedeng/header-b6afc3a71e93789b6d840bbb15de7efc.svg" media="(min-width: 875px)">
                                <img src="https://media.springernature.com/full/nature-cms/uploads/product/natbiomedeng/header-8e114633cc891906a22898658743d641.svg" height="32" alt="Nature Biomedical Engineering">
                            </picture>
                        </a>
                    
                    </div>
                    
                    <ul class="c-header__menu c-header__menu--global">
                        <li class="c-header__item c-header__item--padding c-header__item--hide-md-max">
                            <a class="c-header__link" href="https://www.nature.com/siteindex" data-test="siteindex-link"
                               data-track="click" data-track-action="open nature research index" data-track-label="link">
                                <span>View all journals</span>
                            </a>
                        </li>
                        <li class="c-header__item c-header__item--padding c-header__item--pipe">
                            <a class="c-header__link c-header__link--search"
                                href="#search-menu"
                                data-header-expander
                                data-test="search-link" data-track="click" data-track-action="open search tray" data-track-label="button">
                                <svg role="img" aria-hidden="true" focusable="false" height="22" width="22" viewBox="0 0 18 18" xmlns="http://www.w3.org/2000/svg"><path d="M16.48 15.455c.283.282.29.749.007 1.032a.738.738 0 01-1.032-.007l-3.045-3.044a7 7 0 111.026-1.026zM8 14A6 6 0 108 2a6 6 0 000 12z"/></svg><span>Search</span>
                            </a>
                        </li>
                        <li class="c-header__item c-header__item--padding c-header__item--snid-account-widget c-header__item--pipe">
                            
                                <a class="c-header__link eds-c-header__link" id="identity-account-widget" data-track="click_login" data-track-context="header" href='https://idp.nature.com/auth/personal/springernature?redirect_uri=https://www.nature.com/articles/s41551-022-00898-y'><span class="eds-c-header__widget-fragment-title">Log in</span></a>
                            
                        </li>
                    </ul>
                </div>
            </div>
        </div>
        
            <div class="c-header__row">
                <div class="c-header__container" data-test="navigation-row">
                    <div class="c-header__split">
                        <ul class="c-header__menu c-header__menu--journal">
                            
                                <li class="c-header__item c-header__item--dropdown-menu" data-test="explore-content-button">
                                    <a href="#explore"
                                       class="c-header__link"
                                       data-header-expander
                                       data-test="menu-button--explore"
                                       data-track="click" data-track-action="open explore expander" data-track-label="button">
                                        <span class="c-header__show-text-sm">Content</span>
                                        <span class="c-header__show-text">Explore content</span><svg role="img" aria-hidden="true" focusable="false" height="16" viewBox="0 0 16 16" width="16" xmlns="http://www.w3.org/2000/svg"><path d="m5.58578644 3-3.29289322-3.29289322c-.39052429-.39052429-.39052429-1.02368927 0-1.41421356s1.02368927-.39052429 1.41421356 0l4 4c.39052429.39052429.39052429 1.02368927 0 1.41421356l-4 4c-.39052429.39052429-1.02368927.39052429-1.41421356 0s-.39052429-1.02368927 0-1.41421356z" transform="matrix(0 1 -1 0 11 3)"/></svg>
                                    </a>
                                </li>
                            
                            
                                <li class="c-header__item c-header__item--dropdown-menu">
                                    <a href="#about-the-journal"
                                       class="c-header__link"
                                       data-header-expander
                                       data-test="menu-button--about-the-journal"
                                       data-track="click" data-track-action="open about the journal expander" data-track-label="button">
                                        <span>About <span class="c-header__show-text">the journal</span></span><svg role="img" aria-hidden="true" focusable="false" height="16" viewBox="0 0 16 16" width="16" xmlns="http://www.w3.org/2000/svg"><path d="m5.58578644 3-3.29289322-3.29289322c-.39052429-.39052429-.39052429-1.02368927 0-1.41421356s1.02368927-.39052429 1.41421356 0l4 4c.39052429.39052429.39052429 1.02368927 0 1.41421356l-4 4c-.39052429.39052429-1.02368927.39052429-1.41421356 0s-.39052429-1.02368927 0-1.41421356z" transform="matrix(0 1 -1 0 11 3)"/></svg>
                                    </a>
                                </li>
                                
                                    <li class="c-header__item c-header__item--dropdown-menu" data-test="publish-with-us-button">
                                        <a href="#publish-with-us"
                                           class="c-header__link c-header__link--dropdown-menu"
                                           data-header-expander
                                           data-test="menu-button--publish"
                                           data-track="click" data-track-action="open publish with us expander" data-track-label="button">
                                            <span>Publish <span class="c-header__show-text">with us</span></span><svg role="img" aria-hidden="true" focusable="false" height="16" viewBox="0 0 16 16" width="16" xmlns="http://www.w3.org/2000/svg"><path d="m5.58578644 3-3.29289322-3.29289322c-.39052429-.39052429-.39052429-1.02368927 0-1.41421356s1.02368927-.39052429 1.41421356 0l4 4c.39052429.39052429.39052429 1.02368927 0 1.41421356l-4 4c-.39052429.39052429-1.02368927.39052429-1.41421356 0s-.39052429-1.02368927 0-1.41421356z" transform="matrix(0 1 -1 0 11 3)"/></svg>
                                        </a>
                                    </li>
                                
                            
                            
                                <li class="c-header__item c-header__item--pipe c-header__item--hide-lg-max">
                                    <a class="c-header__link"
                                       href="/natbiomedeng/subscribe"
                                       data-track="click"
                                       data-track-action="subscribe"
                                       data-track-label="link"
                                       data-test="menu-button-subscribe">
                                        <span>Subscribe</span>
                                    </a>
                                </li>
                            
                        </ul>
                        <ul class="c-header__menu c-header__menu--hide-lg-max">
                            
                                <li class="c-header__item" data-test="alert-link">
                                    <a class="c-header__link"
                                       href="https://journal-alerts.springernature.com/subscribe?journal_id&#x3D;41551"
                                       rel="nofollow"
                                       data-track="nav_sign_up_for_alerts"
                                       data-track-action="Sign up for alerts"
                                       data-track-label="link (desktop site header)"
                                       data-track-external>
                                        <span>Sign up for alerts</span><svg role="img" aria-hidden="true" focusable="false" height="18" viewBox="0 0 18 18" width="18" xmlns="http://www.w3.org/2000/svg"><path d="m4 10h2.5c.27614237 0 .5.2238576.5.5s-.22385763.5-.5.5h-3.08578644l-1.12132034 1.1213203c-.18753638.1875364-.29289322.4418903-.29289322.7071068v.1715729h14v-.1715729c0-.2652165-.1053568-.5195704-.2928932-.7071068l-1.7071068-1.7071067v-3.4142136c0-2.76142375-2.2385763-5-5-5-2.76142375 0-5 2.23857625-5 5zm3 4c0 1.1045695.8954305 2 2 2s2-.8954305 2-2zm-5 0c-.55228475 0-1-.4477153-1-1v-.1715729c0-.530433.21071368-1.0391408.58578644-1.4142135l1.41421356-1.4142136v-3c0-3.3137085 2.6862915-6 6-6s6 2.6862915 6 6v3l1.4142136 1.4142136c.3750727.3750727.5857864.8837805.5857864 1.4142135v.1715729c0 .5522847-.4477153 1-1 1h-4c0 1.6568542-1.3431458 3-3 3-1.65685425 0-3-1.3431458-3-3z" fill="#222"/></svg>
                                    </a>
                                </li>
                            
                            
                                <li class="c-header__item c-header__item--pipe">
                                    <a class="c-header__link"
                                       href="https://www.nature.com/natbiomedeng.rss"
                                       data-track="click"
                                       data-track-action="rss feed"
                                       data-track-label="link">
                                            <span>RSS feed</span>
                                    </a>
                                </li>
                            
                        </ul>
                    </div>
                </div>
            </div>
        
    </header>


    
    
        <nav class="u-mb-16" aria-label="breadcrumbs">
            <div class="u-container">
                <ol class="c-breadcrumbs" itemscope itemtype="https://schema.org/BreadcrumbList">
                    <li class="c-breadcrumbs__item" id="breadcrumb0" itemprop="itemListElement" itemscope itemtype="https://schema.org/ListItem"><a class="c-breadcrumbs__link"
                               href="/" itemprop="item"
                               data-track="click" data-track-action="breadcrumb" data-track-category="header" data-track-label="link:nature"><span itemprop="name">nature</span></a><meta itemprop="position" content="1">
                                    <svg class="c-breadcrumbs__chevron" role="img" aria-hidden="true" focusable="false" height="10" viewBox="0 0 10 10" width="10"
                                         xmlns="http://www.w3.org/2000/svg">
                                        <path d="m5.96738168 4.70639573 2.39518594-2.41447274c.37913917-.38219212.98637524-.38972225 1.35419292-.01894278.37750606.38054586.37784436.99719163-.00013556 1.37821513l-4.03074001 4.06319683c-.37758093.38062133-.98937525.38100976-1.367372-.00003075l-4.03091981-4.06337806c-.37759778-.38063832-.38381821-.99150444-.01600053-1.3622839.37750607-.38054587.98772445-.38240057 1.37006824.00302197l2.39538588 2.4146743.96295325.98624457z"
                                              fill="#666" fill-rule="evenodd" transform="matrix(0 -1 1 0 0 10)"/>
                                    </svg>
                                </li><li class="c-breadcrumbs__item" id="breadcrumb1" itemprop="itemListElement" itemscope itemtype="https://schema.org/ListItem"><a class="c-breadcrumbs__link"
                               href="/natbiomedeng" itemprop="item"
                               data-track="click" data-track-action="breadcrumb" data-track-category="header" data-track-label="link:nature biomedical engineering"><span itemprop="name">nature biomedical engineering</span></a><meta itemprop="position" content="2">
                                    <svg class="c-breadcrumbs__chevron" role="img" aria-hidden="true" focusable="false" height="10" viewBox="0 0 10 10" width="10"
                                         xmlns="http://www.w3.org/2000/svg">
                                        <path d="m5.96738168 4.70639573 2.39518594-2.41447274c.37913917-.38219212.98637524-.38972225 1.35419292-.01894278.37750606.38054586.37784436.99719163-.00013556 1.37821513l-4.03074001 4.06319683c-.37758093.38062133-.98937525.38100976-1.367372-.00003075l-4.03091981-4.06337806c-.37759778-.38063832-.38381821-.99150444-.01600053-1.3622839.37750607-.38054587.98772445-.38240057 1.37006824.00302197l2.39538588 2.4146743.96295325.98624457z"
                                              fill="#666" fill-rule="evenodd" transform="matrix(0 -1 1 0 0 10)"/>
                                    </svg>
                                </li><li class="c-breadcrumbs__item" id="breadcrumb2" itemprop="itemListElement" itemscope itemtype="https://schema.org/ListItem"><a class="c-breadcrumbs__link"
                               href="/natbiomedeng/articles?type&#x3D;review-article" itemprop="item"
                               data-track="click" data-track-action="breadcrumb" data-track-category="header" data-track-label="link:review articles"><span itemprop="name">review articles</span></a><meta itemprop="position" content="3">
                                    <svg class="c-breadcrumbs__chevron" role="img" aria-hidden="true" focusable="false" height="10" viewBox="0 0 10 10" width="10"
                                         xmlns="http://www.w3.org/2000/svg">
                                        <path d="m5.96738168 4.70639573 2.39518594-2.41447274c.37913917-.38219212.98637524-.38972225 1.35419292-.01894278.37750606.38054586.37784436.99719163-.00013556 1.37821513l-4.03074001 4.06319683c-.37758093.38062133-.98937525.38100976-1.367372-.00003075l-4.03091981-4.06337806c-.37759778-.38063832-.38381821-.99150444-.01600053-1.3622839.37750607-.38054587.98772445-.38240057 1.37006824.00302197l2.39538588 2.4146743.96295325.98624457z"
                                              fill="#666" fill-rule="evenodd" transform="matrix(0 -1 1 0 0 10)"/>
                                    </svg>
                                </li><li class="c-breadcrumbs__item" id="breadcrumb3" itemprop="itemListElement" itemscope itemtype="https://schema.org/ListItem">
                                    <span itemprop="name">article</span><meta itemprop="position" content="4"></li>
                </ol>
            </div>
        </nav>
    



    

</div>


<div class="u-container u-mt-32 u-mb-32 u-clearfix" id="content" data-component="article-container"  data-container-type="article">
    <main class="c-article-main-column u-float-left js-main-column" data-track-component="article body">
        
            
        
        <article lang="en">
            
            <div class="c-article-header">
                <header>
                    <ul class="c-article-identifiers" data-test="article-identifier">
                        
        <li class="c-article-identifiers__item" data-test="article-category">Review Article</li>
    
    

                        <li class="c-article-identifiers__item">Published: <time datetime="2022-07-04">04 July 2022</time></li>
                    </ul>

                    <h1 class="c-article-title" data-test="article-title" data-article-title="">Shifting machine learning for healthcare from development to deployment and from models to data</h1>
                    <ul class="c-article-author-list c-article-author-list--short" data-test="authors-list" data-component-authors-activator="authors-list"><li class="c-article-author-list__item"><a data-test="author-name" data-track="click" data-track-action="open author" data-track-label="link" data-track-index="1_4" data-track-context="researcher popup with no profile" href="#auth-Angela-Zhang-Aff1-Aff2-Aff3-Aff4" data-author-popup="auth-Angela-Zhang-Aff1-Aff2-Aff3-Aff4" data-author-search="Zhang, Angela" data-corresp-id="c1">Angela Zhang<svg width="16" height="16" focusable="false" role="img" aria-hidden="true" class="u-icon"><use xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="#icon-eds-i-mail-medium"></use></svg></a><span class="u-js-hide">
            <a class="js-orcid" href="https://orcid.org/0000-0003-0906-6770"><span class="u-visually-hidden">ORCID: </span>orcid.org/0000-0003-0906-6770</a></span><sup class="u-js-hide"><a href="#Aff1">1</a>,<a href="#Aff2">2</a>,<a href="#Aff3">3</a>,<a href="#Aff4">4</a></sup>, </li><li class="c-article-author-list__item"><a data-test="author-name" data-track="click" data-track-action="open author" data-track-label="link" data-track-index="2_4" data-track-context="researcher popup with no profile" href="#auth-Lei-Xing-Aff5" data-author-popup="auth-Lei-Xing-Aff5" data-author-search="Xing, Lei">Lei Xing</a><span class="u-js-hide">
            <a class="js-orcid" href="https://orcid.org/0000-0003-2536-5359"><span class="u-visually-hidden">ORCID: </span>orcid.org/0000-0003-2536-5359</a></span><sup class="u-js-hide"><a href="#Aff5">5</a></sup>, </li><li class="c-article-author-list__item c-article-author-list__item--hide-small-screen"><a data-test="author-name" data-track="click" data-track-action="open author" data-track-label="link" data-track-index="3_4" data-track-context="researcher popup with no profile" href="#auth-James-Zou-Aff4-Aff6" data-author-popup="auth-James-Zou-Aff4-Aff6" data-author-search="Zou, James">James Zou</a><span class="u-js-hide">
            <a class="js-orcid" href="https://orcid.org/0000-0001-8880-4764"><span class="u-visually-hidden">ORCID: </span>orcid.org/0000-0001-8880-4764</a></span><sup class="u-js-hide"><a href="#Aff4">4</a>,<a href="#Aff6">6</a></sup> &amp; </li><li class="c-article-author-list__show-more" aria-label="Show all 4 authors for this article" title="Show all 4 authors for this article"></li><li class="c-article-author-list__item"><a data-test="author-name" data-track="click" data-track-action="open author" data-track-label="link" data-track-index="4_4" data-track-context="researcher popup with no profile" href="#auth-Joseph_C_-Wu-Aff1-Aff3-Aff7-Aff8" data-author-popup="auth-Joseph_C_-Wu-Aff1-Aff3-Aff7-Aff8" data-author-search="Wu, Joseph C." data-corresp-id="c2">Joseph C. Wu<svg width="16" height="16" focusable="false" role="img" aria-hidden="true" class="u-icon"><use xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="#icon-eds-i-mail-medium"></use></svg></a><span class="u-js-hide">
            <a class="js-orcid" href="https://orcid.org/0000-0002-6068-8041"><span class="u-visually-hidden">ORCID: </span>orcid.org/0000-0002-6068-8041</a></span><sup class="u-js-hide"><a href="#Aff1">1</a>,<a href="#Aff3">3</a>,<a href="#Aff7">7</a>,<a href="#Aff8">8</a></sup></li></ul><button aria-expanded="false" class="c-article-author-list__button"><svg width="16" height="16" focusable="false" role="img" aria-hidden="true" class="u-icon"><use xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="#icon-eds-i-chevron-down-medium"></use></svg><span>Show authors</span></button>

                    

                    <p class="c-article-info-details" data-container-section="info">
                        
    <a data-test="journal-link" href="/natbiomedeng" data-track="click" data-track-action="journal homepage" data-track-category="article body" data-track-label="link"><i data-test="journal-title">Nature Biomedical Engineering</i></a>

                        <b data-test="journal-volume"><span class="u-visually-hidden">volume</span>6</b>,<span class="u-visually-hidden">pages </span>13301345 (<span data-test="article-publication-year">2022</span>)<a href="#citeas" class="c-article-info-details__cite-as u-hide-print" data-track="click" data-track-action="cite this article" data-track-label="link">Cite this article</a>
                    </p>
                    
        
        <div class="c-article-metrics-bar__wrapper u-clear-both">
            <ul class="c-article-metrics-bar u-list-reset">
                
                    <li class=" c-article-metrics-bar__item" data-test="access-count">
                        <p class="c-article-metrics-bar__count">50k <span class="c-article-metrics-bar__label">Accesses</span></p>
                    </li>
                
                
                    <li class="c-article-metrics-bar__item" data-test="citation-count">
                        <p class="c-article-metrics-bar__count">348 <span class="c-article-metrics-bar__label">Citations</span></p>
                    </li>
                
                
                    
                        <li class="c-article-metrics-bar__item" data-test="altmetric-score">
                            <p class="c-article-metrics-bar__count">200 <span class="c-article-metrics-bar__label">Altmetric</span></p>
                        </li>
                    
                
                
                    <li class="c-article-metrics-bar__item">
                        <p class="c-article-metrics-bar__details"><a href="/articles/s41551-022-00898-y/metrics" data-track="click" data-track-action="view metrics" data-track-label="link" rel="nofollow">Metrics <span class="u-visually-hidden">details</span></a></p>
                    </li>
                
            </ul>
        </div>
    
                    
                </header>

                
    <div class="u-js-hide" data-component="article-subject-links">
        <h3 class="c-article__sub-heading">Subjects</h3>
        <ul class="c-article-subject-list">
            <li class="c-article-subject-list__subject"><a href="/subjects/biomedical-engineering" data-track="click" data-track-action="view subject" data-track-label="link">Biomedical engineering</a></li><li class="c-article-subject-list__subject"><a href="/subjects/computational-science" data-track="click" data-track-action="view subject" data-track-label="link">Computational science</a></li><li class="c-article-subject-list__subject"><a href="/subjects/machine-learning" data-track="click" data-track-action="view subject" data-track-label="link">Machine learning</a></li><li class="c-article-subject-list__subject"><a href="/subjects/medical-imaging" data-track="click" data-track-action="view subject" data-track-label="link">Medical imaging</a></li><li class="c-article-subject-list__subject"><a href="/subjects/translational-research" data-track="click" data-track-action="view subject" data-track-label="link">Translational research</a></li>
        </ul>
    </div>

                
    
    

    
    

                
            </div>

        <div class="c-article-body">
            <section aria-labelledby="Abs1" data-title="Abstract" lang="en"><div class="c-article-section" id="Abs1-section"><h2 class="c-article-section__title js-section-title js-c-reading-companion-sections-item" id="Abs1">Abstract</h2><div class="c-article-section__content" id="Abs1-content"><p>In the past decade, the application of machine learning (ML) to healthcare has helped drive the automation of physician tasks as well as enhancements in clinical capabilities and access to care. This progress has emphasized that, from model development to model deployment, data play central roles. In this Review, we provide a data-centric view of the innovations and challenges that are defining ML for healthcare. We discuss deep generative models and federated learning as strategies to augment datasets for improved model performance, as well as the use of the more recent transformer models for handling larger datasets and enhancing the modelling of clinical text. We also discuss data-focused problems in the deployment of ML, emphasizing the need to efficiently deliver data to ML models for timely clinical predictions and to account for natural data shifts that can deteriorate model performance.</p></div></div></section>

            
                
                    <div class="js-context-bar-sticky-point-mobile" data-track-context="article body">
                            
        <div class="c-nature-box c-nature-box--side c-nature-box--access-to-pdf" data-test="entitlement-box">
        
            <div>
                <a href="https://wayf.springernature.com?redirect_uri&#x3D;https%3A%2F%2Fwww.nature.com%2Farticles%2Fs41551-022-00898-y" class="c-article__button" data-test="ra21">
                    <svg class="u-icon" width="18" height="18" aria-hidden="true" focusable="false"><use href="#icon-institution"></use></svg>
                    <span class="c-article__button-text">Access through your institution</span>
                </a>
            </div>
        
        
            
                <div data-test="entitlement-box-buy-button">
                    <a href="#access-options" class="c-article__button c-article__button--inverted" data-test="ra21">
                        <span>Buy or subscribe</span>
                    </a>
                </div>
            
        
        </div>
    

                    </div>
                
            

            
                
                
                
                
                    <div class="c-article-access-provider u-mb-32 u-mt-0">
                        <p class="c-article-access-provider__text u-sans-serif">This is a preview of subscription content, <a href="https://wayf.springernature.com?redirect_uri&#x3D;https%3A%2F%2Fwww.nature.com%2Farticles%2Fs41551-022-00898-y" data-track="click_institution_login" data-track-context="article body link"
                         data-track-action="institution access preview subscription" data-track-label="link">access via your institution</a></p>
                    </div>
                    
                

                

                <h2 class="c-article-section__title u-h2 u-mb-24" id="access-options">Access options</h2>
                


                    
                            
        <div class="c-nature-box c-nature-box--side " data-test="entitlement-box">
        
            <div>
                <a href="https://wayf.springernature.com?redirect_uri&#x3D;https%3A%2F%2Fwww.nature.com%2Farticles%2Fs41551-022-00898-y" class="c-article__button" data-test="ra21">
                    <svg class="u-icon" width="18" height="18" aria-hidden="true" focusable="false"><use href="#icon-institution"></use></svg>
                    <span class="c-article__button-text">Access through your institution</span>
                </a>
            </div>
        
        
        </div>
    

                    

                
    
    <div class="LiveAreaSection"><style type="text/css">/* style specs start */

/* style specs end */</style><section class="BuyBoxSection"><div class="subscribe-buybox-nature-plus">
    <div class="box-inner">
      <p class="title-buybox">
        Access Nature and 54 other Nature Portfolio journals
      </p>
      <p class="access-buybox">
        Get Nature+, our best-value online-access subscription
      </p>
      <div>
        <p class="price-buybox" id="nature-plus-subscription-price">
          <span class="price-value">27,99<span class="price-per-period" style="font-size: 0.9rem"> /30days</span></span>
        </p>
        <p class="issue-buybox">cancel any time</p>
      </div>
      <div class="button-container">
        <a
          href="https://shop.nature.com/products/plus/?region=ROW"
          class="Button-505204839"
          data-track="click"
          data-track-action="nature+"
          data-track-label="link"
          data-track-category="article body"
          ><span class="ButtonLabel-3869432492">Learn more</span></a
        >
      </div>
    </div>
    </div><div class="subscribe-buybox">
    <div class="box-inner">
      <p class="title-buybox">Subscribe to this journal</p>
      <p class="access-buybox">
        Receive 12 digital issues and online access to articles
      </p>
      
    <div>
      <p class="price-buybox" id="subscription-price">111,21 per year</p>
      <p class="issue-buybox">only 9,27  per issue</p>
    </div>
  
      
    <div class="button-container">
      <a
        href="/natbiomedeng/subscribe"
        class="Button-1078489254"
        data-track="click"
        data-track-action="subscribe"
        data-track-label="link"
        data-track-category="article body"
        ><span class="ButtonLabel-3296148077">Learn more</span></a
      >
    </div>
  
    </div>
  </div><div class="readcube-buybox"><div class="box-inner"><p class="title-readcube">Buy this article</p><ul><li class="link-usp"><span>Purchase on SpringerLink</span></li><li class="link-usp"><span>Instant access to the full article PDF.</span></li></ul><div><p class="price-buybox"><span class="price-value">39,95 </span></p></div><div><form action="https://order.springer.com/public/cart?utm_source=nature&amp;utm_medium=buyArticle" method="post"><input type="hidden" name="type" value="article" /><input type="hidden" name="doi" value="10.1038/s41551-022-00898-y" /><input type="hidden" name="isxn" value="2157-846X" /><input type="hidden" name="contenttitle" value="Shifting machine learning for healthcare from development to deployment and from models to data" /><input type="hidden" name="copyrightyear" value="2022" /><input type="hidden" name="year" value="2022" /><input type="hidden" name="authors" value="Angela Zhang, et al." /><input type="hidden" name="title" value="Nature Biomedical Engineering" /><input type="hidden" name="mac" value="59e62b32d8a6ee3f56cd2225e0012126aaabf3f2f76b2f7fe9c282f5293e8ae841c1281b50f8d35233cbc684d5085389cd5c29634f022f7d9fa2fee8f9293e42" /><div class="button-container"><input type="submit" class="btn-secondary Button-2737859108 article-buy-button" id="btn-nature-article-buy-now" onclick="dataLayer.push({&quot;event&quot;:&quot;addToCart&quot;,&quot;ecommerce&quot;:{&quot;currencyCode&quot;:&quot;EUR&quot;,&quot;add&quot;:{&quot;products&quot;:[{&quot;name&quot;:&quot;Shifting machine learning for healthcare from development to deployment and from models to data&quot;,&quot;id&quot;:&quot;2157-846X&quot;,&quot;price&quot;:39.95,&quot;brand&quot;:&quot;Nature Publishing Group UK&quot;,&quot;category&quot;:&quot;Biomedical Engineering and Bioengineering&quot;,&quot;variant&quot;:&quot;ppv-article&quot;,&quot;quantity&quot;:1}]}}});" value="Buy Now" /></div></form></div></div></div><p class="tax-buybox">Prices may be subject to local taxes which are calculated during checkout</p></section><style type="text/css">
          /* style specs start */
          style {
            display: none !important;
          }
          .LiveAreaSection * {
            align-content: stretch;
            align-items: stretch;
            align-self: auto;
            animation-delay: 0s;
            animation-direction: normal;
            animation-duration: 0s;
            animation-fill-mode: none;
            animation-iteration-count: 1;
            animation-name: none;
            animation-play-state: running;
            animation-timing-function: ease;
            azimuth: center;
            backface-visibility: visible;
            background-attachment: scroll;
            background-blend-mode: normal;
            background-clip: borderBox;
            background-color: transparent;
            background-image: none;
            background-origin: paddingBox;
            background-position: 0 0;
            background-repeat: repeat;
            background-size: auto auto;
            block-size: auto;
            border-block-end-color: currentcolor;
            border-block-end-style: none;
            border-block-end-width: medium;
            border-block-start-color: currentcolor;
            border-block-start-style: none;
            border-block-start-width: medium;
            border-bottom-color: currentcolor;
            border-bottom-left-radius: 0;
            border-bottom-right-radius: 0;
            border-bottom-style: none;
            border-bottom-width: medium;
            border-collapse: separate;
            border-image-outset: 0s;
            border-image-repeat: stretch;
            border-image-slice: 100%;
            border-image-source: none;
            border-image-width: 1;
            border-inline-end-color: currentcolor;
            border-inline-end-style: none;
            border-inline-end-width: medium;
            border-inline-start-color: currentcolor;
            border-inline-start-style: none;
            border-inline-start-width: medium;
            border-left-color: currentcolor;
            border-left-style: none;
            border-left-width: medium;
            border-right-color: currentcolor;
            border-right-style: none;
            border-right-width: medium;
            border-spacing: 0;
            border-top-color: currentcolor;
            border-top-left-radius: 0;
            border-top-right-radius: 0;
            border-top-style: none;
            border-top-width: medium;
            bottom: auto;
            box-decoration-break: slice;
            box-shadow: none;
            box-sizing: border-box;
            break-after: auto;
            break-before: auto;
            break-inside: auto;
            caption-side: top;
            caret-color: auto;
            clear: none;
            clip: auto;
            clip-path: none;
            color: initial;
            column-count: auto;
            column-fill: balance;
            column-gap: normal;
            column-rule-color: currentcolor;
            column-rule-style: none;
            column-rule-width: medium;
            column-span: none;
            column-width: auto;
            content: normal;
            counter-increment: none;
            counter-reset: none;
            cursor: auto;
            display: inline;
            empty-cells: show;
            filter: none;
            flex-basis: auto;
            flex-direction: row;
            flex-grow: 0;
            flex-shrink: 1;
            flex-wrap: nowrap;
            float: none;
            font-family: initial;
            font-feature-settings: normal;
            font-kerning: auto;
            font-language-override: normal;
            font-size: medium;
            font-size-adjust: none;
            font-stretch: normal;
            font-style: normal;
            font-synthesis: weight style;
            font-variant: normal;
            font-variant-alternates: normal;
            font-variant-caps: normal;
            font-variant-east-asian: normal;
            font-variant-ligatures: normal;
            font-variant-numeric: normal;
            font-variant-position: normal;
            font-weight: 400;
            grid-auto-columns: auto;
            grid-auto-flow: row;
            grid-auto-rows: auto;
            grid-column-end: auto;
            grid-column-gap: 0;
            grid-column-start: auto;
            grid-row-end: auto;
            grid-row-gap: 0;
            grid-row-start: auto;
            grid-template-areas: none;
            grid-template-columns: none;
            grid-template-rows: none;
            height: auto;
            hyphens: manual;
            image-orientation: 0deg;
            image-rendering: auto;
            image-resolution: 1dppx;
            ime-mode: auto;
            inline-size: auto;
            isolation: auto;
            justify-content: flexStart;
            left: auto;
            letter-spacing: normal;
            line-break: auto;
            line-height: normal;
            list-style-image: none;
            list-style-position: outside;
            list-style-type: disc;
            margin-block-end: 0;
            margin-block-start: 0;
            margin-bottom: 0;
            margin-inline-end: 0;
            margin-inline-start: 0;
            margin-left: 0;
            margin-right: 0;
            margin-top: 0;
            mask-clip: borderBox;
            mask-composite: add;
            mask-image: none;
            mask-mode: matchSource;
            mask-origin: borderBox;
            mask-position: 0 0;
            mask-repeat: repeat;
            mask-size: auto;
            mask-type: luminance;
            max-height: none;
            max-width: none;
            min-block-size: 0;
            min-height: 0;
            min-inline-size: 0;
            min-width: 0;
            mix-blend-mode: normal;
            object-fit: fill;
            object-position: 50% 50%;
            offset-block-end: auto;
            offset-block-start: auto;
            offset-inline-end: auto;
            offset-inline-start: auto;
            opacity: 1;
            order: 0;
            orphans: 2;
            outline-color: initial;
            outline-offset: 0;
            outline-style: none;
            outline-width: medium;
            overflow: visible;
            overflow-wrap: normal;
            overflow-x: visible;
            overflow-y: visible;
            padding-block-end: 0;
            padding-block-start: 0;
            padding-bottom: 0;
            padding-inline-end: 0;
            padding-inline-start: 0;
            padding-left: 0;
            padding-right: 0;
            padding-top: 0;
            page-break-after: auto;
            page-break-before: auto;
            page-break-inside: auto;
            perspective: none;
            perspective-origin: 50% 50%;
            pointer-events: auto;
            position: static;
            quotes: initial;
            resize: none;
            right: auto;
            ruby-align: spaceAround;
            ruby-merge: separate;
            ruby-position: over;
            scroll-behavior: auto;
            scroll-snap-coordinate: none;
            scroll-snap-destination: 0 0;
            scroll-snap-points-x: none;
            scroll-snap-points-y: none;
            scroll-snap-type: none;
            shape-image-threshold: 0;
            shape-margin: 0;
            shape-outside: none;
            tab-size: 8;
            table-layout: auto;
            text-align: initial;
            text-align-last: auto;
            text-combine-upright: none;
            text-decoration-color: currentcolor;
            text-decoration-line: none;
            text-decoration-style: solid;
            text-emphasis-color: currentcolor;
            text-emphasis-position: over right;
            text-emphasis-style: none;
            text-indent: 0;
            text-justify: auto;
            text-orientation: mixed;
            text-overflow: clip;
            text-rendering: auto;
            text-shadow: none;
            text-transform: none;
            text-underline-position: auto;
            top: auto;
            touch-action: auto;
            transform: none;
            transform-box: borderBox;
            transform-origin: 50% 50%0;
            transform-style: flat;
            transition-delay: 0s;
            transition-duration: 0s;
            transition-property: all;
            transition-timing-function: ease;
            vertical-align: baseline;
            visibility: visible;
            white-space: normal;
            widows: 2;
            width: auto;
            will-change: auto;
            word-break: normal;
            word-spacing: normal;
            word-wrap: normal;
            writing-mode: horizontalTb;
            z-index: auto;
            -webkit-appearance: none;
            -moz-appearance: none;
            -ms-appearance: none;
            appearance: none;
            margin: 0;
          }
          .LiveAreaSection {
            width: 100%;
          }
          .LiveAreaSection .login-option-buybox {
            display: block;
            width: 100%;
            font-size: 17px;
            line-height: 30px;
            color: #222;
            padding-top: 30px;
            font-family: Harding, Palatino, serif;
          }
          .LiveAreaSection .additional-access-options {
            display: block;
            font-weight: 700;
            font-size: 17px;
            line-height: 30px;
            color: #222;
            font-family: Harding, Palatino, serif;
          }
          .LiveAreaSection .additional-login > li:not(:first-child)::before {
            transform: translateY(-50%);
            content: "";
            height: 1rem;
            position: absolute;
            top: 50%;
            left: 0;
            border-left: 2px solid #999;
          }
          .LiveAreaSection .additional-login > li:not(:first-child) {
            padding-left: 10px;
          }
          .LiveAreaSection .additional-login > li {
            display: inline-block;
            position: relative;
            vertical-align: middle;
            padding-right: 10px;
          }
          .BuyBoxSection {
            display: flex;
            flex-wrap: wrap;
            flex: 1;
            flex-direction: row-reverse;
            margin: -30px -15px 0;
          }
          .BuyBoxSection .box-inner {
            width: 100%;
            height: 100%;
            padding: 30px 5px;
            display: flex;
            flex-direction: column;
            justify-content: space-between;
          }
          .BuyBoxSection p {
            margin: 0;
          }
          .BuyBoxSection .readcube-buybox {
            background-color: #f3f3f3;
            flex-shrink: 1;
            flex-grow: 1;
            flex-basis: 255px;
            background-clip: content-box;
            padding: 0 15px;
            margin-top: 30px;
          }
          .BuyBoxSection .subscribe-buybox {
            background-color: #f3f3f3;
            flex-shrink: 1;
            flex-grow: 4;
            flex-basis: 300px;
            background-clip: content-box;
            padding: 0 15px;
            margin-top: 30px;
          }
          .BuyBoxSection .subscribe-buybox-nature-plus {
            background-color: #f3f3f3;
            flex-shrink: 1;
            flex-grow: 4;
            flex-basis: 100%;
            background-clip: content-box;
            padding: 0 15px;
            margin-top: 30px;
          }
          .BuyBoxSection .title-readcube,
          .BuyBoxSection .title-buybox {
            display: block;
            margin: 0;
            margin-right: 10%;
            margin-left: 10%;
            font-size: 24px;
            line-height: 32px;
            color: #222;
            text-align: center;
            font-family: Harding, Palatino, serif;
          }
          .BuyBoxSection .title-asia-buybox {
            display: block;
            margin: 0;
            margin-right: 5%;
            margin-left: 5%;
            font-size: 24px;
            line-height: 32px;
            color: #222;
            text-align: center;
            font-family: Harding, Palatino, serif;
          }
          .BuyBoxSection .asia-link,
          .Link-328123652,
          .Link-2926870917,
          .Link-2291679238,
          .Link-595459207 {
            color: #069;
            cursor: pointer;
            text-decoration: none;
            font-size: 1.05em;
            font-family: -apple-system, BlinkMacSystemFont, "Segoe UI", Roboto,
              Oxygen-Sans, Ubuntu, Cantarell, "Helvetica Neue", sans-serif;
            line-height: 1.05em6;
          }
          .BuyBoxSection .access-readcube {
            display: block;
            margin: 0;
            margin-right: 10%;
            margin-left: 10%;
            font-size: 14px;
            color: #222;
            padding-top: 10px;
            text-align: center;
            font-family: -apple-system, BlinkMacSystemFont, "Segoe UI", Roboto,
              Oxygen-Sans, Ubuntu, Cantarell, "Helvetica Neue", sans-serif;
            line-height: 20px;
          }
          .BuyBoxSection ul {
            margin: 0;
          }
          .BuyBoxSection .link-usp {
            display: list-item;
            margin: 0;
            margin-left: 20px;
            padding-top: 6px;
            list-style-position: inside;
          }
          .BuyBoxSection .link-usp span {
            font-size: 14px;
            color: #222;
            font-family: -apple-system, BlinkMacSystemFont, "Segoe UI", Roboto,
              Oxygen-Sans, Ubuntu, Cantarell, "Helvetica Neue", sans-serif;
            line-height: 20px;
          }
          .BuyBoxSection .access-asia-buybox {
            display: block;
            margin: 0;
            margin-right: 5%;
            margin-left: 5%;
            font-size: 14px;
            color: #222;
            padding-top: 10px;
            text-align: center;
            font-family: -apple-system, BlinkMacSystemFont, "Segoe UI", Roboto,
              Oxygen-Sans, Ubuntu, Cantarell, "Helvetica Neue", sans-serif;
            line-height: 20px;
          }
          .BuyBoxSection .access-buybox {
            display: block;
            margin: 0;
            margin-right: 10%;
            margin-left: 10%;
            font-size: 14px;
            color: #222;
            opacity: 0.8px;
            padding-top: 10px;
            text-align: center;
            font-family: -apple-system, BlinkMacSystemFont, "Segoe UI", Roboto,
              Oxygen-Sans, Ubuntu, Cantarell, "Helvetica Neue", sans-serif;
            line-height: 20px;
          }
          .BuyBoxSection .price-buybox {
            display: block;
            font-size: 30px;
            color: #222;
            font-family: -apple-system, BlinkMacSystemFont, "Segoe UI", Roboto,
              Oxygen-Sans, Ubuntu, Cantarell, "Helvetica Neue", sans-serif;
            padding-top: 30px;
            text-align: center;
          }
          .BuyBoxSection .price-buybox-to {
            display: block;
            font-size: 30px;
            color: #222;
            font-family: -apple-system, BlinkMacSystemFont, "Segoe UI", Roboto,
              Oxygen-Sans, Ubuntu, Cantarell, "Helvetica Neue", sans-serif;
            text-align: center;
          }
          .BuyBoxSection .price-info-text {
            font-size: 16px;
            padding-right: 10px;
            color: #222;
            font-family: -apple-system, BlinkMacSystemFont, "Segoe UI", Roboto,
              Oxygen-Sans, Ubuntu, Cantarell, "Helvetica Neue", sans-serif;
          }
          .BuyBoxSection .price-value {
            font-size: 30px;
            font-family: -apple-system, BlinkMacSystemFont, "Segoe UI", Roboto,
              Oxygen-Sans, Ubuntu, Cantarell, "Helvetica Neue", sans-serif;
          }
          .BuyBoxSection .price-per-period {
            font-family: -apple-system, BlinkMacSystemFont, "Segoe UI", Roboto,
              Oxygen-Sans, Ubuntu, Cantarell, "Helvetica Neue", sans-serif;
          }
          .BuyBoxSection .price-from {
            font-size: 14px;
            padding-right: 10px;
            color: #222;
            font-family: -apple-system, BlinkMacSystemFont, "Segoe UI", Roboto,
              Oxygen-Sans, Ubuntu, Cantarell, "Helvetica Neue", sans-serif;
            line-height: 20px;
          }
          .BuyBoxSection .issue-buybox {
            display: block;
            font-size: 13px;
            text-align: center;
            color: #222;
            font-family: -apple-system, BlinkMacSystemFont, "Segoe UI", Roboto,
              Oxygen-Sans, Ubuntu, Cantarell, "Helvetica Neue", sans-serif;
            line-height: 19px;
          }
          .BuyBoxSection .no-price-buybox {
            display: block;
            font-size: 13px;
            line-height: 18px;
            text-align: center;
            padding-right: 10%;
            padding-left: 10%;
            padding-bottom: 20px;
            padding-top: 30px;
            color: #222;
            font-family: -apple-system, BlinkMacSystemFont, "Segoe UI", Roboto,
              Oxygen-Sans, Ubuntu, Cantarell, "Helvetica Neue", sans-serif;
          }
          .BuyBoxSection .vat-buybox {
            display: block;
            margin-top: 5px;
            margin-right: 20%;
            margin-left: 20%;
            font-size: 11px;
            color: #222;
            padding-top: 10px;
            padding-bottom: 15px;
            text-align: center;
            font-family: -apple-system, BlinkMacSystemFont, "Segoe UI", Roboto,
              Oxygen-Sans, Ubuntu, Cantarell, "Helvetica Neue", sans-serif;
            line-height: 17px;
          }
          .BuyBoxSection .tax-buybox {
            display: block;
            width: 100%;
            color: #222;
            padding: 20px 16px;
            text-align: center;
            font-family: -apple-system, BlinkMacSystemFont, "Segoe UI", Roboto,
              Oxygen-Sans, Ubuntu, Cantarell, "Helvetica Neue", sans-serif;
            line-height: NaNpx;
          }
          .BuyBoxSection .button-container {
            display: flex;
            padding-right: 20px;
            padding-left: 20px;
            justify-content: center;
          }
          .BuyBoxSection .button-container > * {
            flex: 1px;
          }
          .BuyBoxSection .button-container > a:hover,
          .Button-505204839:hover,
          .Button-1078489254:hover,
          .Button-2737859108:hover {
            text-decoration: none;
          }
          .BuyBoxSection .btn-secondary {
            background: #fff;
          }
          .BuyBoxSection .button-asia {
            background: #069;
            border: 1px solid #069;
            border-radius: 0;
            cursor: pointer;
            display: block;
            padding: 9px;
            outline: 0;
            text-align: center;
            text-decoration: none;
            min-width: 80px;
            margin-top: 75px;
          }
          .BuyBoxSection .button-label-asia,
          .ButtonLabel-3869432492,
          .ButtonLabel-3296148077,
          .ButtonLabel-1636778223 {
            display: block;
            color: #fff;
            font-size: 17px;
            line-height: 20px;
            font-family: -apple-system, BlinkMacSystemFont, "Segoe UI", Roboto,
              Oxygen-Sans, Ubuntu, Cantarell, "Helvetica Neue", sans-serif;
            text-align: center;
            text-decoration: none;
            cursor: pointer;
          }
          .Button-505204839,
          .Button-1078489254,
          .Button-2737859108 {
            background: #069;
            border: 1px solid #069;
            border-radius: 0;
            cursor: pointer;
            display: block;
            padding: 9px;
            outline: 0;
            text-align: center;
            text-decoration: none;
            min-width: 80px;
            max-width: 320px;
            margin-top: 20px;
          }
          .Button-505204839 .btn-secondary-label,
          .Button-1078489254 .btn-secondary-label,
          .Button-2737859108 .btn-secondary-label {
            color: #069;
          }
          .uList-2102244549 {
            list-style: none;
            padding: 0;
            margin: 0;
          }
          .article-buy-button {
            font-family: -apple-system, BlinkMacSystemFont, "Segoe UI", Roboto, Oxygen-Sans, Ubuntu, Cantarell, "Helvetica Neue", sans-serif;
            color: #069;
           }
          /* style specs end */</style><div></div></div>
  

    
    
        <nav class="c-access-options">
    <h3 class="c-access-options__heading">Additional access options:</h3>
    <ul class="c-access-options__list">
        <li>
            <a href="https://idp.nature.com/authorize/natureuser?client_id&#x3D;grover&amp;redirect_uri&#x3D;https%3A%2F%2Fwww.nature.com%2Farticles%2Fs41551-022-00898-y"
                data-track="click"
                data-track-action="login"
                data-track-category="article body"
                data-track-label="link">Log in</a>
        </li>
        
        <li>
            <a href="https://www.springernature.com/gp/librarians/licensing/license-options"
                data-track="click"
                data-track-action="learn-subscription"
                data-track-category="article body"
                data-track-label="link">Learn about institutional subscriptions</a>
        </li>
        <li>
            <a href="https://support.nature.com/en/support/home"
               data-track="click"
               data-track-action="read our faqs"
               data-track-category="article body"
               data-track-label="link">Read our FAQs</a>
        </li>
        <li>
            <a href="https://www.springernature.com/gp/contact"
               data-track="click"
               data-track-action="contact customer support"
               data-track-category="article body"
               data-track-label="link">Contact customer support</a>
        </li>
    </ul>
</nav>
    

                <div class="u-display-none">
                    <div class="c-article-section__figure js-c-reading-companion-figures-item" data-test="figure" data-container-section="figure" id="figure-1"><figure><figcaption><b id="Fig1" class="c-article-section__figure-caption" data-test="figure-caption-text">Fig. 1: Roles of GANs in healthcare.</b></figcaption><div class="c-article-section__figure-content"><div class="c-article-section__figure-item"><picture><source type="image/webp" srcset="//media.springernature.com/m312/springer-static/image/art%3A10.1038%2Fs41551-022-00898-y/MediaObjects/41551_2022_898_Fig1_HTML.png?as=webp"><img src="//media.springernature.com/m312/springer-static/image/art%3A10.1038%2Fs41551-022-00898-y/MediaObjects/41551_2022_898_Fig1_HTML.png" alt="" loading="lazy" width="312" height="197"></picture></div></div></figure></div><div class="c-article-section__figure js-c-reading-companion-figures-item" data-test="figure" data-container-section="figure" id="figure-2"><figure><figcaption><b id="Fig2" class="c-article-section__figure-caption" data-test="figure-caption-text">Fig. 2: Cross-silo federated learning for healthcare.</b></figcaption><div class="c-article-section__figure-content"><div class="c-article-section__figure-item"><picture><source type="image/webp" srcset="//media.springernature.com/m312/springer-static/image/art%3A10.1038%2Fs41551-022-00898-y/MediaObjects/41551_2022_898_Fig2_HTML.png?as=webp"><img src="//media.springernature.com/m312/springer-static/image/art%3A10.1038%2Fs41551-022-00898-y/MediaObjects/41551_2022_898_Fig2_HTML.png" alt="" loading="lazy" width="312" height="225"></picture></div></div></figure></div><div class="c-article-section__figure js-c-reading-companion-figures-item" data-test="figure" data-container-section="figure" id="figure-3"><figure><figcaption><b id="Fig3" class="c-article-section__figure-caption" data-test="figure-caption-text">Fig. 3: Transformers.</b></figcaption><div class="c-article-section__figure-content"><div class="c-article-section__figure-item"><picture><source type="image/webp" srcset="//media.springernature.com/m312/springer-static/image/art%3A10.1038%2Fs41551-022-00898-y/MediaObjects/41551_2022_898_Fig3_HTML.png?as=webp"><img src="//media.springernature.com/m312/springer-static/image/art%3A10.1038%2Fs41551-022-00898-y/MediaObjects/41551_2022_898_Fig3_HTML.png" alt="" loading="lazy" width="312" height="232"></picture></div></div></figure></div><div class="c-article-section__figure js-c-reading-companion-figures-item" data-test="figure" data-container-section="figure" id="figure-4"><figure><figcaption><b id="Fig4" class="c-article-section__figure-caption" data-test="figure-caption-text">Fig. 4: Data pipeline.</b></figcaption><div class="c-article-section__figure-content"><div class="c-article-section__figure-item"><picture><source type="image/webp" srcset="//media.springernature.com/m312/springer-static/image/art%3A10.1038%2Fs41551-022-00898-y/MediaObjects/41551_2022_898_Fig4_HTML.png?as=webp"><img src="//media.springernature.com/m312/springer-static/image/art%3A10.1038%2Fs41551-022-00898-y/MediaObjects/41551_2022_898_Fig4_HTML.png" alt="" loading="lazy" width="312" height="189"></picture></div></div></figure></div>
                </div>

                
                    
        
            <section aria-labelledby="inline-recommendations" data-title="Inline Recommendations" class="c-article-recommendations" data-track-component="inline-recommendations">
                <h3 class="c-article-recommendations-title" id="inline-recommendations">Similar content being viewed by others</h3>
                <div class="c-article-recommendations-list">
                    
                        <div class="c-article-recommendations-list__item">
                            <article class="c-article-recommendations-card" itemscope itemtype="http://schema.org/ScholarlyArticle">
                                
                                    <div class="c-article-recommendations-card__img"><img src="https://media.springernature.com/w215h120/springer-static/image/art%3Aplaceholder%2Fimages/placeholder-figure-nature.png" loading="lazy" alt=""></div>
                                
                                <div class="c-article-recommendations-card__main">
                                    <h3 class="c-article-recommendations-card__heading" itemprop="name headline">
                                        <a class="c-article-recommendations-card__link"
                                           itemprop="url"
                                           href="https://www.nature.com/articles/s42256-022-00559-4?fromPaywallRec=true"
                                           data-track="select_recommendations_1"
                                           data-track-context="inline recommendations"
                                           data-track-action="click recommendations inline - 1"
                                           data-track-label="10.1038/s42256-022-00559-4">Developing robust benchmarks for driving forward AI innovation in healthcare
                                        </a>
                                    </h3>
                                    <div class="c-article-meta-recommendations" data-test="recommendation-info">
                                        <span class="c-article-meta-recommendations__item-type">Article</span>
                                        
                                         <span class="c-article-meta-recommendations__date">15 November 2022</span>
                                    </div>
                                </div>
                            </article>
                        </div>
                    
                        <div class="c-article-recommendations-list__item">
                            <article class="c-article-recommendations-card" itemscope itemtype="http://schema.org/ScholarlyArticle">
                                
                                    <div class="c-article-recommendations-card__img"><img src="https://media.springernature.com/w215h120/springer-static/image/art%3A10.1038%2Fs41598-022-09954-8/MediaObjects/41598_2022_9954_Fig1_HTML.png" loading="lazy" alt=""></div>
                                
                                <div class="c-article-recommendations-card__main">
                                    <h3 class="c-article-recommendations-card__heading" itemprop="name headline">
                                        <a class="c-article-recommendations-card__link"
                                           itemprop="url"
                                           href="https://www.nature.com/articles/s41598-022-09954-8?fromPaywallRec=true"
                                           data-track="select_recommendations_2"
                                           data-track-context="inline recommendations"
                                           data-track-action="click recommendations inline - 2"
                                           data-track-label="10.1038/s41598-022-09954-8">On evaluation metrics for medical applications of artificial intelligence
                                        </a>
                                    </h3>
                                    <div class="c-article-meta-recommendations" data-test="recommendation-info">
                                        <span class="c-article-meta-recommendations__item-type">Article</span>
                                         <span class="c-article-meta-recommendations__access-type">Open access</span>
                                         <span class="c-article-meta-recommendations__date">08 April 2022</span>
                                    </div>
                                </div>
                            </article>
                        </div>
                    
                        <div class="c-article-recommendations-list__item">
                            <article class="c-article-recommendations-card" itemscope itemtype="http://schema.org/ScholarlyArticle">
                                
                                    <div class="c-article-recommendations-card__img"><img src="https://media.springernature.com/w215h120/springer-static/image/art%3A10.1038%2Fs41746-023-00753-7/MediaObjects/41746_2023_753_Fig1_HTML.png" loading="lazy" alt=""></div>
                                
                                <div class="c-article-recommendations-card__main">
                                    <h3 class="c-article-recommendations-card__heading" itemprop="name headline">
                                        <a class="c-article-recommendations-card__link"
                                           itemprop="url"
                                           href="https://www.nature.com/articles/s41746-023-00753-7?fromPaywallRec=true"
                                           data-track="select_recommendations_3"
                                           data-track-context="inline recommendations"
                                           data-track-action="click recommendations inline - 3"
                                           data-track-label="10.1038/s41746-023-00753-7">Making machine learning matter to clinicians: model actionability in medical decision-making
                                        </a>
                                    </h3>
                                    <div class="c-article-meta-recommendations" data-test="recommendation-info">
                                        <span class="c-article-meta-recommendations__item-type">Article</span>
                                         <span class="c-article-meta-recommendations__access-type">Open access</span>
                                         <span class="c-article-meta-recommendations__date">24 January 2023</span>
                                    </div>
                                </div>
                            </article>
                        </div>
                    
                </div>
            </section>
        
            <script>
                window.dataLayer = window.dataLayer || [];
                window.dataLayer.push({
                    recommendations: {
                        recommender: 'semantic',
                        model: 'specter',
                        policy_id: 'NA',
                        timestamp: 1768224211,
                        embedded_user: 'null'
                    }
                });
            </script>
        
    
                
            

            <div class="u-mt-32">
                <div id="MagazineFulltextArticleBodySuffix"><section aria-labelledby="Bib1" data-title="References"><div class="c-article-section" id="Bib1-section"><h2 class="c-article-section__title js-section-title js-c-reading-companion-sections-item" id="Bib1">References</h2><div class="c-article-section__content" id="Bib1-content"><div data-container-section="references"><ol class="c-article-references" data-track-component="outbound reference" data-track-context="references section"><li class="c-article-references__item js-c-reading-companion-references-item" data-counter="1."><p class="c-article-references__text" id="ref-CR1">Topol, E. J. High-performance medicine: the convergence of human and artificial intelligence. <i>Nat. Med.</i> <b>25</b>, 4456 (2019).</p><p class="c-article-references__links u-hide-print"><a data-track="click_references" rel="nofollow noopener" data-track-label="10.1038/s41591-018-0300-7" data-track-item_id="10.1038/s41591-018-0300-7" data-track-value="article reference" data-track-action="article reference" href="https://doi.org/10.1038%2Fs41591-018-0300-7" aria-label="Article reference 1" data-doi="10.1038/s41591-018-0300-7">Article</a>
    <a data-track="click_references" rel="nofollow noopener" data-track-label="link" data-track-item_id="link" data-track-value="cas reference" data-track-action="cas reference" href="/articles/cas-redirect/1:CAS:528:DC%2BC1MXmvVOgsbs%3D" aria-label="CAS reference 1">CAS</a>
    <a data-track="click_references" rel="nofollow noopener" data-track-label="link" data-track-item_id="link" data-track-value="pubmed reference" data-track-action="pubmed reference" href="http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?cmd=Retrieve&amp;db=PubMed&amp;dopt=Abstract&amp;list_uids=30617339" aria-label="PubMed reference 1">PubMed</a>
    <a data-track="click_references" data-track-action="google scholar reference" data-track-value="google scholar reference" data-track-label="link" data-track-item_id="link" rel="nofollow noopener" aria-label="Google Scholar reference 1" href="http://scholar.google.com/scholar_lookup?&amp;title=High-performance%20medicine%3A%20the%20convergence%20of%20human%20and%20artificial%20intelligence&amp;journal=Nat.%20Med.&amp;doi=10.1038%2Fs41591-018-0300-7&amp;volume=25&amp;pages=44-56&amp;publication_year=2019&amp;author=Topol%2CEJ">
                    Google Scholar</a>
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" data-counter="2."><p class="c-article-references__text" id="ref-CR2">Gulshan, V. et al. Development and validation of a deep learning algorithm for detection of diabetic retinopathy in retinal fundus photographs. <i>JAMA</i> <b>316</b>, 24022410 (2016).</p><p class="c-article-references__links u-hide-print"><a data-track="click_references" rel="nofollow noopener" data-track-label="10.1001/jama.2016.17216" data-track-item_id="10.1001/jama.2016.17216" data-track-value="article reference" data-track-action="article reference" href="https://doi.org/10.1001%2Fjama.2016.17216" aria-label="Article reference 2" data-doi="10.1001/jama.2016.17216">Article</a>
    <a data-track="click_references" rel="nofollow noopener" data-track-label="link" data-track-item_id="link" data-track-value="pubmed reference" data-track-action="pubmed reference" href="http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?cmd=Retrieve&amp;db=PubMed&amp;dopt=Abstract&amp;list_uids=27898976" aria-label="PubMed reference 2">PubMed</a>
    <a data-track="click_references" data-track-action="google scholar reference" data-track-value="google scholar reference" data-track-label="link" data-track-item_id="link" rel="nofollow noopener" aria-label="Google Scholar reference 2" href="http://scholar.google.com/scholar_lookup?&amp;title=Development%20and%20validation%20of%20a%20deep%20learning%20algorithm%20for%20detection%20of%20diabetic%20retinopathy%20in%20retinal%20fundus%20photographs&amp;journal=JAMA&amp;doi=10.1001%2Fjama.2016.17216&amp;volume=316&amp;pages=2402-2410&amp;publication_year=2016&amp;author=Gulshan%2CV">
                    Google Scholar</a>
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" data-counter="3."><p class="c-article-references__text" id="ref-CR3">Esteva, A. et al. Dermatologist-level classification of skin cancer with deep neural networks. <i>Nature</i> <b>542</b>, 115118 (2017).</p><p class="c-article-references__links u-hide-print"><a data-track="click_references" rel="nofollow noopener" data-track-label="10.1038/nature21056" data-track-item_id="10.1038/nature21056" data-track-value="article reference" data-track-action="article reference" href="https://doi.org/10.1038%2Fnature21056" aria-label="Article reference 3" data-doi="10.1038/nature21056">Article</a>
    <a data-track="click_references" rel="nofollow noopener" data-track-label="link" data-track-item_id="link" data-track-value="cas reference" data-track-action="cas reference" href="/articles/cas-redirect/1:CAS:528:DC%2BC2sXhsFGltrY%3D" aria-label="CAS reference 3">CAS</a>
    <a data-track="click_references" rel="nofollow noopener" data-track-label="link" data-track-item_id="link" data-track-value="pubmed reference" data-track-action="pubmed reference" href="http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?cmd=Retrieve&amp;db=PubMed&amp;dopt=Abstract&amp;list_uids=28117445" aria-label="PubMed reference 3">PubMed</a>
    <a data-track="click_references" rel="nofollow noopener" data-track-label="link" data-track-item_id="link" data-track-value="pubmed central reference" data-track-action="pubmed central reference" href="http://www.ncbi.nlm.nih.gov/pmc/articles/PMC8382232" aria-label="PubMed Central reference 3">PubMed Central</a>
    <a data-track="click_references" data-track-action="google scholar reference" data-track-value="google scholar reference" data-track-label="link" data-track-item_id="link" rel="nofollow noopener" aria-label="Google Scholar reference 3" href="http://scholar.google.com/scholar_lookup?&amp;title=Dermatologist-level%20classification%20of%20skin%20cancer%20with%20deep%20neural%20networks&amp;journal=Nature&amp;doi=10.1038%2Fnature21056&amp;volume=542&amp;pages=115-118&amp;publication_year=2017&amp;author=Esteva%2CA">
                    Google Scholar</a>
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" data-counter="4."><p class="c-article-references__text" id="ref-CR4">Rajkomar, A. et al. Scalable and accurate deep learning with electronic health records. <i>npj Digit. Med.</i> <b>1</b>, 18 (2018).</p><p class="c-article-references__links u-hide-print"><a data-track="click_references" rel="nofollow noopener" data-track-label="10.1038/s41746-018-0029-1" data-track-item_id="10.1038/s41746-018-0029-1" data-track-value="article reference" data-track-action="article reference" href="https://doi.org/10.1038%2Fs41746-018-0029-1" aria-label="Article reference 4" data-doi="10.1038/s41746-018-0029-1">Article</a>
    <a data-track="click_references" rel="nofollow noopener" data-track-label="link" data-track-item_id="link" data-track-value="pubmed reference" data-track-action="pubmed reference" href="http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?cmd=Retrieve&amp;db=PubMed&amp;dopt=Abstract&amp;list_uids=31304302" aria-label="PubMed reference 4">PubMed</a>
    <a data-track="click_references" rel="nofollow noopener" data-track-label="link" data-track-item_id="link" data-track-value="pubmed central reference" data-track-action="pubmed central reference" href="http://www.ncbi.nlm.nih.gov/pmc/articles/PMC6550175" aria-label="PubMed Central reference 4">PubMed Central</a>
    <a data-track="click_references" data-track-action="google scholar reference" data-track-value="google scholar reference" data-track-label="link" data-track-item_id="link" rel="nofollow noopener" aria-label="Google Scholar reference 4" href="http://scholar.google.com/scholar_lookup?&amp;title=Scalable%20and%20accurate%20deep%20learning%20with%20electronic%20health%20records&amp;journal=npj%20Digit.%20Med.&amp;doi=10.1038%2Fs41746-018-0029-1&amp;volume=1&amp;publication_year=2018&amp;author=Rajkomar%2CA">
                    Google Scholar</a>
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" data-counter="5."><p class="c-article-references__text" id="ref-CR5">Rajkomar, A. et al. Automatically charting symptoms from patient-physician conversations using machine learning. <i>JAMA Intern. Med.</i> <b>179</b>, 836838 (2019).</p><p class="c-article-references__links u-hide-print"><a data-track="click_references" rel="nofollow noopener" data-track-label="10.1001/jamainternmed.2018.8558" data-track-item_id="10.1001/jamainternmed.2018.8558" data-track-value="article reference" data-track-action="article reference" href="https://doi.org/10.1001%2Fjamainternmed.2018.8558" aria-label="Article reference 5" data-doi="10.1001/jamainternmed.2018.8558">Article</a>
    <a data-track="click_references" rel="nofollow noopener" data-track-label="link" data-track-item_id="link" data-track-value="pubmed reference" data-track-action="pubmed reference" href="http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?cmd=Retrieve&amp;db=PubMed&amp;dopt=Abstract&amp;list_uids=30907920" aria-label="PubMed reference 5">PubMed</a>
    <a data-track="click_references" rel="nofollow noopener" data-track-label="link" data-track-item_id="link" data-track-value="pubmed central reference" data-track-action="pubmed central reference" href="http://www.ncbi.nlm.nih.gov/pmc/articles/PMC6547250" aria-label="PubMed Central reference 5">PubMed Central</a>
    <a data-track="click_references" data-track-action="google scholar reference" data-track-value="google scholar reference" data-track-label="link" data-track-item_id="link" rel="nofollow noopener" aria-label="Google Scholar reference 5" href="http://scholar.google.com/scholar_lookup?&amp;title=Automatically%20charting%20symptoms%20from%20patient-physician%20conversations%20using%20machine%20learning&amp;journal=JAMA%20Intern.%20Med.&amp;doi=10.1001%2Fjamainternmed.2018.8558&amp;volume=179&amp;pages=836-838&amp;publication_year=2019&amp;author=Rajkomar%2CA">
                    Google Scholar</a>
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" data-counter="6."><p class="c-article-references__text" id="ref-CR6">Henry, K. E., Hager, D. N., Pronovost, P. J. &amp; Saria, S. A targeted real-time early warning score (TREWScore) for septic shock. <i>Sci. Transl. Med.</i> <b>7</b>, 299ra122 (2015).</p><p class="c-article-references__links u-hide-print"><a data-track="click_references" rel="nofollow noopener" data-track-label="10.1126/scitranslmed.aab3719" data-track-item_id="10.1126/scitranslmed.aab3719" data-track-value="article reference" data-track-action="article reference" href="https://doi.org/10.1126%2Fscitranslmed.aab3719" aria-label="Article reference 6" data-doi="10.1126/scitranslmed.aab3719">Article</a>
    <a data-track="click_references" rel="nofollow noopener" data-track-label="link" data-track-item_id="link" data-track-value="pubmed reference" data-track-action="pubmed reference" href="http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?cmd=Retrieve&amp;db=PubMed&amp;dopt=Abstract&amp;list_uids=26246167" aria-label="PubMed reference 6">PubMed</a>
    <a data-track="click_references" data-track-action="google scholar reference" data-track-value="google scholar reference" data-track-label="link" data-track-item_id="link" rel="nofollow noopener" aria-label="Google Scholar reference 6" href="http://scholar.google.com/scholar_lookup?&amp;title=A%20targeted%20real-time%20early%20warning%20score%20%28TREWScore%29%20for%20septic%20shock&amp;journal=Sci.%20Transl.%20Med.&amp;doi=10.1126%2Fscitranslmed.aab3719&amp;volume=7&amp;publication_year=2015&amp;author=Henry%2CKE&amp;author=Hager%2CDN&amp;author=Pronovost%2CPJ&amp;author=Saria%2CS">
                    Google Scholar</a>
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" data-counter="7."><p class="c-article-references__text" id="ref-CR7">Komorowski, M., Celi, L. A., Badawi, O., Gordon, A. C. &amp; Faisal, A. A. The Artificial Intelligence Clinician learns optimal treatment strategies for sepsis in intensive care. <i>Nat. Med.</i> <b>24</b>, 17161720 (2018).</p><p class="c-article-references__links u-hide-print"><a data-track="click_references" rel="nofollow noopener" data-track-label="10.1038/s41591-018-0213-5" data-track-item_id="10.1038/s41591-018-0213-5" data-track-value="article reference" data-track-action="article reference" href="https://doi.org/10.1038%2Fs41591-018-0213-5" aria-label="Article reference 7" data-doi="10.1038/s41591-018-0213-5">Article</a>
    <a data-track="click_references" rel="nofollow noopener" data-track-label="link" data-track-item_id="link" data-track-value="cas reference" data-track-action="cas reference" href="/articles/cas-redirect/1:CAS:528:DC%2BC1cXhvF2lsbrF" aria-label="CAS reference 7">CAS</a>
    <a data-track="click_references" rel="nofollow noopener" data-track-label="link" data-track-item_id="link" data-track-value="pubmed reference" data-track-action="pubmed reference" href="http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?cmd=Retrieve&amp;db=PubMed&amp;dopt=Abstract&amp;list_uids=30349085" aria-label="PubMed reference 7">PubMed</a>
    <a data-track="click_references" data-track-action="google scholar reference" data-track-value="google scholar reference" data-track-label="link" data-track-item_id="link" rel="nofollow noopener" aria-label="Google Scholar reference 7" href="http://scholar.google.com/scholar_lookup?&amp;title=The%20Artificial%20Intelligence%20Clinician%20learns%20optimal%20treatment%20strategies%20for%20sepsis%20in%20intensive%20care&amp;journal=Nat.%20Med.&amp;doi=10.1038%2Fs41591-018-0213-5&amp;volume=24&amp;pages=1716-1720&amp;publication_year=2018&amp;author=Komorowski%2CM&amp;author=Celi%2CLA&amp;author=Badawi%2CO&amp;author=Gordon%2CAC&amp;author=Faisal%2CAA">
                    Google Scholar</a>
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" data-counter="8."><p class="c-article-references__text" id="ref-CR8">Abrmoff, M. D., Lavin, P. T., Birch, M., Shah, N. &amp; Folk, J. C. Pivotal trial of an autonomous AI-based diagnostic system for detection of diabetic retinopathy in primary care offices. <i>npj Digit. Med.</i> <b>1</b>, 39 (2018).</p><p class="c-article-references__links u-hide-print"><a data-track="click_references" rel="nofollow noopener" data-track-label="10.1038/s41746-018-0040-6" data-track-item_id="10.1038/s41746-018-0040-6" data-track-value="article reference" data-track-action="article reference" href="https://doi.org/10.1038%2Fs41746-018-0040-6" aria-label="Article reference 8" data-doi="10.1038/s41746-018-0040-6">Article</a>
    <a data-track="click_references" rel="nofollow noopener" data-track-label="link" data-track-item_id="link" data-track-value="pubmed reference" data-track-action="pubmed reference" href="http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?cmd=Retrieve&amp;db=PubMed&amp;dopt=Abstract&amp;list_uids=31304320" aria-label="PubMed reference 8">PubMed</a>
    <a data-track="click_references" rel="nofollow noopener" data-track-label="link" data-track-item_id="link" data-track-value="pubmed central reference" data-track-action="pubmed central reference" href="http://www.ncbi.nlm.nih.gov/pmc/articles/PMC6550188" aria-label="PubMed Central reference 8">PubMed Central</a>
    <a data-track="click_references" data-track-action="google scholar reference" data-track-value="google scholar reference" data-track-label="link" data-track-item_id="link" rel="nofollow noopener" aria-label="Google Scholar reference 8" href="http://scholar.google.com/scholar_lookup?&amp;title=Pivotal%20trial%20of%20an%20autonomous%20AI-based%20diagnostic%20system%20for%20detection%20of%20diabetic%20retinopathy%20in%20primary%20care%20offices&amp;journal=npj%20Digit.%20Med.&amp;doi=10.1038%2Fs41746-018-0040-6&amp;volume=1&amp;publication_year=2018&amp;author=Abr%C3%A0moff%2CMD&amp;author=Lavin%2CPT&amp;author=Birch%2CM&amp;author=Shah%2CN&amp;author=Folk%2CJC">
                    Google Scholar</a>
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" data-counter="9."><p class="c-article-references__text" id="ref-CR9">Iacobucci, G. Babylon Health holds talks with significant number of NHS trusts. <i>Brit. Med. J.</i> <b>368</b>, m266 (2020).</p><p class="c-article-references__links u-hide-print"><a data-track="click_references" rel="nofollow noopener" data-track-label="10.1136/bmj.m266" data-track-item_id="10.1136/bmj.m266" data-track-value="article reference" data-track-action="article reference" href="https://doi.org/10.1136%2Fbmj.m266" aria-label="Article reference 9" data-doi="10.1136/bmj.m266">Article</a>
    <a data-track="click_references" rel="nofollow noopener" data-track-label="link" data-track-item_id="link" data-track-value="pubmed reference" data-track-action="pubmed reference" href="http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?cmd=Retrieve&amp;db=PubMed&amp;dopt=Abstract&amp;list_uids=31974118" aria-label="PubMed reference 9">PubMed</a>
    <a data-track="click_references" data-track-action="google scholar reference" data-track-value="google scholar reference" data-track-label="link" data-track-item_id="link" rel="nofollow noopener" aria-label="Google Scholar reference 9" href="http://scholar.google.com/scholar_lookup?&amp;title=Babylon%20Health%20holds%20talks%20with%20%E2%80%98significant%E2%80%99%20number%20of%20NHS%20trusts&amp;journal=Brit.%20Med.%20J.&amp;doi=10.1136%2Fbmj.m266&amp;volume=368&amp;publication_year=2020&amp;author=Iacobucci%2CG">
                    Google Scholar</a>
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" data-counter="10."><p class="c-article-references__text" id="ref-CR10">Hale, C. Medtronic to distribute Viz.ais stroke-spotting AI imaging software. <i>Fierce Biotech</i> (23 July 2019); <a href="https://www.fiercebiotech.com/medtech/medtronic-to-distribute-viz-ai-s-stroke-spotting-ai-imaging-software" data-track="click_references" data-track-action="external reference" data-track-value="external reference" data-track-label="https://www.fiercebiotech.com/medtech/medtronic-to-distribute-viz-ai-s-stroke-spotting-ai-imaging-software">https://www.fiercebiotech.com/medtech/medtronic-to-distribute-viz-ai-s-stroke-spotting-ai-imaging-software</a></p></li><li class="c-article-references__item js-c-reading-companion-references-item" data-counter="11."><p class="c-article-references__text" id="ref-CR11">Hassan, A. E. et al. Early experience utilizing artificial intelligence shows significant reduction in transfer times and length of stay in a hub and spoke model. <i>Interv. Neuroradiol.</i> <b>26</b>, 615622 (2020).</p><p class="c-article-references__links u-hide-print"><a data-track="click_references" rel="nofollow noopener" data-track-label="10.1177/1591019920953055" data-track-item_id="10.1177/1591019920953055" data-track-value="article reference" data-track-action="article reference" href="https://doi.org/10.1177%2F1591019920953055" aria-label="Article reference 11" data-doi="10.1177/1591019920953055">Article</a>
    <a data-track="click_references" rel="nofollow noopener" data-track-label="link" data-track-item_id="link" data-track-value="pubmed reference" data-track-action="pubmed reference" href="http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?cmd=Retrieve&amp;db=PubMed&amp;dopt=Abstract&amp;list_uids=32847449" aria-label="PubMed reference 11">PubMed</a>
    <a data-track="click_references" rel="nofollow noopener" data-track-label="link" data-track-item_id="link" data-track-value="pubmed central reference" data-track-action="pubmed central reference" href="http://www.ncbi.nlm.nih.gov/pmc/articles/PMC7645178" aria-label="PubMed Central reference 11">PubMed Central</a>
    <a data-track="click_references" data-track-action="google scholar reference" data-track-value="google scholar reference" data-track-label="link" data-track-item_id="link" rel="nofollow noopener" aria-label="Google Scholar reference 11" href="http://scholar.google.com/scholar_lookup?&amp;title=Early%20experience%20utilizing%20artificial%20intelligence%20shows%20significant%20reduction%20in%20transfer%20times%20and%20length%20of%20stay%20in%20a%20hub%20and%20spoke%20model&amp;journal=Interv.%20Neuroradiol.&amp;doi=10.1177%2F1591019920953055&amp;volume=26&amp;pages=615-622&amp;publication_year=2020&amp;author=Hassan%2CAE">
                    Google Scholar</a>
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" data-counter="12."><p class="c-article-references__text" id="ref-CR12">Ting, D. S. W. et al. Development and validation of a deep learning system for diabetic retinopathy and related eye diseases using retinal images from multiethnic populations with diabetes. <i>JAMA</i> <b>318</b>, 22112223 (2017).</p><p class="c-article-references__links u-hide-print"><a data-track="click_references" rel="nofollow noopener" data-track-label="10.1001/jama.2017.18152" data-track-item_id="10.1001/jama.2017.18152" data-track-value="article reference" data-track-action="article reference" href="https://doi.org/10.1001%2Fjama.2017.18152" aria-label="Article reference 12" data-doi="10.1001/jama.2017.18152">Article</a>
    <a data-track="click_references" rel="nofollow noopener" data-track-label="link" data-track-item_id="link" data-track-value="pubmed reference" data-track-action="pubmed reference" href="http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?cmd=Retrieve&amp;db=PubMed&amp;dopt=Abstract&amp;list_uids=29234807" aria-label="PubMed reference 12">PubMed</a>
    <a data-track="click_references" rel="nofollow noopener" data-track-label="link" data-track-item_id="link" data-track-value="pubmed central reference" data-track-action="pubmed central reference" href="http://www.ncbi.nlm.nih.gov/pmc/articles/PMC5820739" aria-label="PubMed Central reference 12">PubMed Central</a>
    <a data-track="click_references" data-track-action="google scholar reference" data-track-value="google scholar reference" data-track-label="link" data-track-item_id="link" rel="nofollow noopener" aria-label="Google Scholar reference 12" href="http://scholar.google.com/scholar_lookup?&amp;title=Development%20and%20validation%20of%20a%20deep%20learning%20system%20for%20diabetic%20retinopathy%20and%20related%20eye%20diseases%20using%20retinal%20images%20from%20multiethnic%20populations%20with%20diabetes&amp;journal=JAMA&amp;doi=10.1001%2Fjama.2017.18152&amp;volume=318&amp;pages=2211-2223&amp;publication_year=2017&amp;author=Ting%2CDSW">
                    Google Scholar</a>
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" data-counter="13."><p class="c-article-references__text" id="ref-CR13">McKinney, S. M. et al. International evaluation of an AI system for breast cancer screening. <i>Nature</i> <b>577</b>, 8994 (2020).</p><p class="c-article-references__links u-hide-print"><a data-track="click_references" rel="nofollow noopener" data-track-label="10.1038/s41586-019-1799-6" data-track-item_id="10.1038/s41586-019-1799-6" data-track-value="article reference" data-track-action="article reference" href="https://doi.org/10.1038%2Fs41586-019-1799-6" aria-label="Article reference 13" data-doi="10.1038/s41586-019-1799-6">Article</a>
    <a data-track="click_references" rel="nofollow noopener" data-track-label="link" data-track-item_id="link" data-track-value="cas reference" data-track-action="cas reference" href="/articles/cas-redirect/1:CAS:528:DC%2BB3cXjsFKlsA%3D%3D" aria-label="CAS reference 13">CAS</a>
    <a data-track="click_references" rel="nofollow noopener" data-track-label="link" data-track-item_id="link" data-track-value="pubmed reference" data-track-action="pubmed reference" href="http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?cmd=Retrieve&amp;db=PubMed&amp;dopt=Abstract&amp;list_uids=31894144" aria-label="PubMed reference 13">PubMed</a>
    <a data-track="click_references" data-track-action="google scholar reference" data-track-value="google scholar reference" data-track-label="link" data-track-item_id="link" rel="nofollow noopener" aria-label="Google Scholar reference 13" href="http://scholar.google.com/scholar_lookup?&amp;title=International%20evaluation%20of%20an%20AI%20system%20for%20breast%20cancer%20screening&amp;journal=Nature&amp;doi=10.1038%2Fs41586-019-1799-6&amp;volume=577&amp;pages=89-94&amp;publication_year=2020&amp;author=McKinney%2CSM">
                    Google Scholar</a>
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" data-counter="14."><p class="c-article-references__text" id="ref-CR14">Liu, Y. et al. A deep learning system for differential diagnosis of skin diseases. <i>Nat. Med.</i> <b>26</b>, 900908 (2020).</p><p class="c-article-references__links u-hide-print"><a data-track="click_references" rel="nofollow noopener" data-track-label="10.1038/s41591-020-0842-3" data-track-item_id="10.1038/s41591-020-0842-3" data-track-value="article reference" data-track-action="article reference" href="https://doi.org/10.1038%2Fs41591-020-0842-3" aria-label="Article reference 14" data-doi="10.1038/s41591-020-0842-3">Article</a>
    <a data-track="click_references" rel="nofollow noopener" data-track-label="link" data-track-item_id="link" data-track-value="cas reference" data-track-action="cas reference" href="/articles/cas-redirect/1:CAS:528:DC%2BB3cXpsFyjs7s%3D" aria-label="CAS reference 14">CAS</a>
    <a data-track="click_references" rel="nofollow noopener" data-track-label="link" data-track-item_id="link" data-track-value="pubmed reference" data-track-action="pubmed reference" href="http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?cmd=Retrieve&amp;db=PubMed&amp;dopt=Abstract&amp;list_uids=32424212" aria-label="PubMed reference 14">PubMed</a>
    <a data-track="click_references" data-track-action="google scholar reference" data-track-value="google scholar reference" data-track-label="link" data-track-item_id="link" rel="nofollow noopener" aria-label="Google Scholar reference 14" href="http://scholar.google.com/scholar_lookup?&amp;title=A%20deep%20learning%20system%20for%20differential%20diagnosis%20of%20skin%20diseases&amp;journal=Nat.%20Med.&amp;doi=10.1038%2Fs41591-020-0842-3&amp;volume=26&amp;pages=900-908&amp;publication_year=2020&amp;author=Liu%2CY">
                    Google Scholar</a>
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" data-counter="15."><p class="c-article-references__text" id="ref-CR15">Seyyed-Kalantari, L., Liu, G., McDermott, M., Chen, I. Y. &amp; Ghassemi, M. CheXclusion: fairness gaps in deep chest X-ray classifiers. <i>Pac. Symp. Biocomput.</i> <b>26</b>, 232243 (2021).</p><p class="c-article-references__links u-hide-print"><a data-track="click_references" rel="nofollow noopener" data-track-label="link" data-track-item_id="link" data-track-value="pubmed reference" data-track-action="pubmed reference" href="http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?cmd=Retrieve&amp;db=PubMed&amp;dopt=Abstract&amp;list_uids=33691020" aria-label="PubMed reference 15">PubMed</a>
    <a data-track="click_references" data-track-action="google scholar reference" data-track-value="google scholar reference" data-track-label="link" data-track-item_id="link" rel="nofollow noopener" aria-label="Google Scholar reference 15" href="http://scholar.google.com/scholar_lookup?&amp;title=CheXclusion%3A%20fairness%20gaps%20in%20deep%20chest%20X-ray%20classifiers&amp;journal=Pac.%20Symp.%20Biocomput.&amp;volume=26&amp;pages=232-243&amp;publication_year=2021&amp;author=Seyyed-Kalantari%2CL&amp;author=Liu%2CG&amp;author=McDermott%2CM&amp;author=Chen%2CIY&amp;author=Ghassemi%2CM">
                    Google Scholar</a>
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" data-counter="16."><p class="c-article-references__text" id="ref-CR16">Yu, K.-H., Beam, A. L. &amp; Kohane, I. S. Artificial intelligence in healthcare. <i>Nat. Biomed. Eng.</i> <b>2</b>, 719731 (2018).</p><p class="c-article-references__links u-hide-print"><a data-track="click_references" rel="nofollow noopener" data-track-label="10.1038/s41551-018-0305-z" data-track-item_id="10.1038/s41551-018-0305-z" data-track-value="article reference" data-track-action="article reference" href="https://doi.org/10.1038%2Fs41551-018-0305-z" aria-label="Article reference 16" data-doi="10.1038/s41551-018-0305-z">Article</a>
    <a data-track="click_references" rel="nofollow noopener" data-track-label="link" data-track-item_id="link" data-track-value="pubmed reference" data-track-action="pubmed reference" href="http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?cmd=Retrieve&amp;db=PubMed&amp;dopt=Abstract&amp;list_uids=31015651" aria-label="PubMed reference 16">PubMed</a>
    <a data-track="click_references" data-track-action="google scholar reference" data-track-value="google scholar reference" data-track-label="link" data-track-item_id="link" rel="nofollow noopener" aria-label="Google Scholar reference 16" href="http://scholar.google.com/scholar_lookup?&amp;title=Artificial%20intelligence%20in%20healthcare&amp;journal=Nat.%20Biomed.%20Eng.&amp;doi=10.1038%2Fs41551-018-0305-z&amp;volume=2&amp;pages=719-731&amp;publication_year=2018&amp;author=Yu%2CK-H&amp;author=Beam%2CAL&amp;author=Kohane%2CIS">
                    Google Scholar</a>
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" data-counter="17."><p class="c-article-references__text" id="ref-CR17">Esteva, A. et al. A guide to deep learning in healthcare. <i>Nat. Med.</i> <b>25</b>, 2429 (2019).</p><p class="c-article-references__links u-hide-print"><a data-track="click_references" rel="nofollow noopener" data-track-label="10.1038/s41591-018-0316-z" data-track-item_id="10.1038/s41591-018-0316-z" data-track-value="article reference" data-track-action="article reference" href="https://doi.org/10.1038%2Fs41591-018-0316-z" aria-label="Article reference 17" data-doi="10.1038/s41591-018-0316-z">Article</a>
    <a data-track="click_references" rel="nofollow noopener" data-track-label="link" data-track-item_id="link" data-track-value="cas reference" data-track-action="cas reference" href="/articles/cas-redirect/1:CAS:528:DC%2BC1MXmvVOgsb0%3D" aria-label="CAS reference 17">CAS</a>
    <a data-track="click_references" rel="nofollow noopener" data-track-label="link" data-track-item_id="link" data-track-value="pubmed reference" data-track-action="pubmed reference" href="http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?cmd=Retrieve&amp;db=PubMed&amp;dopt=Abstract&amp;list_uids=30617335" aria-label="PubMed reference 17">PubMed</a>
    <a data-track="click_references" data-track-action="google scholar reference" data-track-value="google scholar reference" data-track-label="link" data-track-item_id="link" rel="nofollow noopener" aria-label="Google Scholar reference 17" href="http://scholar.google.com/scholar_lookup?&amp;title=A%20guide%20to%20deep%20learning%20in%20healthcare&amp;journal=Nat.%20Med.&amp;doi=10.1038%2Fs41591-018-0316-z&amp;volume=25&amp;pages=24-29&amp;publication_year=2019&amp;author=Esteva%2CA">
                    Google Scholar</a>
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" data-counter="18."><p class="c-article-references__text" id="ref-CR18">Frid-Adar, M. et al. GAN-based synthetic medical image augmentation for increased CNN performance in liver lesion classification. <i>Neurocomputing</i> <b>321</b>, 321331 (2018).</p><p class="c-article-references__links u-hide-print"><a data-track="click_references" rel="nofollow noopener" data-track-label="10.1016/j.neucom.2018.09.013" data-track-item_id="10.1016/j.neucom.2018.09.013" data-track-value="article reference" data-track-action="article reference" href="https://doi.org/10.1016%2Fj.neucom.2018.09.013" aria-label="Article reference 18" data-doi="10.1016/j.neucom.2018.09.013">Article</a>
    <a data-track="click_references" data-track-action="google scholar reference" data-track-value="google scholar reference" data-track-label="link" data-track-item_id="link" rel="nofollow noopener" aria-label="Google Scholar reference 18" href="http://scholar.google.com/scholar_lookup?&amp;title=GAN-based%20synthetic%20medical%20image%20augmentation%20for%20increased%20CNN%20performance%20in%20liver%20lesion%20classification&amp;journal=Neurocomputing&amp;doi=10.1016%2Fj.neucom.2018.09.013&amp;volume=321&amp;pages=321-331&amp;publication_year=2018&amp;author=Frid-Adar%2CM">
                    Google Scholar</a>
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" data-counter="19."><p class="c-article-references__text" id="ref-CR19">Shin, H.-C. et al. Medical image synthesis for data augmentation and anonymization using generative adversarial networks. In <i>Simulation and Synthesis in Medical Imaging</i> SASHIMI 2018 (eds Gooya, A., Goksel, O., Oguz, I. &amp; Burgos, N.) 111 (Springer Cham, 2018).</p></li><li class="c-article-references__item js-c-reading-companion-references-item" data-counter="20."><p class="c-article-references__text" id="ref-CR20">Salehinejad, H., Valaee, S., Dowdell, T., Colak, E. &amp; Barfett, J. Generalization of deep neural networks for chest pathology classification in X-rays using generative adversarial networks. In <i>IEEE International Conference on Acoustics, Speech and Signal Processing</i> (ICASSP) 990994 (ieeexplore.ieee.org, 2018).</p></li><li class="c-article-references__item js-c-reading-companion-references-item" data-counter="21."><p class="c-article-references__text" id="ref-CR21">Zhang, Z., Yang, L. &amp; Zheng, Y. Translating and segmenting multimodal medical volumes with cycle-and shape-consistency generative adversarial network. In <i>Proceedings of IEEE/CVF Conference on Computer Vision and Pattern Recognition</i> 92429251 (IEEE, 2018).</p></li><li class="c-article-references__item js-c-reading-companion-references-item" data-counter="22."><p class="c-article-references__text" id="ref-CR22">Xu, F., Zhang, J., Shi, Y., Kang, K. &amp; Yang, S. A fast low-rank matrix factorization method for dynamic magnetic resonance imaging restoration. In <i>5th International Conference on Big Data Computing and Communications</i> (BIGCOM) 3842 (2019).</p></li><li class="c-article-references__item js-c-reading-companion-references-item" data-counter="23."><p class="c-article-references__text" id="ref-CR23">Goodfellow, I. J. et al. Generative adversarial networks. In <i>Advances in Neural Information Processing Systems</i> 27 (eds .Ghahramani, Z., Welling, M., Cortes, C., Lawrence, N. &amp; Weinbergerm, K.Q.) Paper 1384 (Curran, 2014).</p></li><li class="c-article-references__item js-c-reading-companion-references-item" data-counter="24."><p class="c-article-references__text" id="ref-CR24">Wang, Z., She, Q. &amp; Ward, T. E. Generative adversarial networks in computer vision: a survey and taxonomy. <i>ACM Comput. Surv.</i> <b>54</b>, 138 (2021).</p><p class="c-article-references__links u-hide-print"><a data-track="click_references" data-track-action="google scholar reference" data-track-value="google scholar reference" data-track-label="link" data-track-item_id="link" rel="nofollow noopener" aria-label="Google Scholar reference 24" href="http://scholar.google.com/scholar_lookup?&amp;title=Generative%20adversarial%20networks%20in%20computer%20vision%3A%20a%20survey%20and%20taxonomy&amp;journal=ACM%20Comput.%20Surv.&amp;volume=54&amp;pages=1-38&amp;publication_year=2021&amp;author=Wang%2CZ&amp;author=She%2CQ&amp;author=Ward%2CTE">
                    Google Scholar</a>
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" data-counter="25."><p class="c-article-references__text" id="ref-CR25">Radford, A., Metz, L. &amp; Chintala, S. Unsupervised representation learning with deep convolutional generative adversarial networks. Preprint at <a href="https://arxiv.org/abs/1511.06434v2" data-track="click_references" data-track-action="external reference" data-track-value="external reference" data-track-label="https://arxiv.org/abs/1511.06434v2">https://arxiv.org/abs/1511.06434v2</a> (2016).</p></li><li class="c-article-references__item js-c-reading-companion-references-item" data-counter="26."><p class="c-article-references__text" id="ref-CR26">Denton, E. L., Chintala, S. &amp; Fergus, R. Deep generative image models using a Laplacian pyramid of adversarial networks. In <i>Advances in Neural Information Processing Systems</i> 28 (eds Cortes, C., Lawrence, N., Lee, D., Sugiyama, M. &amp; Garnett, R.) Paper 903 (Curran, 2015).</p></li><li class="c-article-references__item js-c-reading-companion-references-item" data-counter="27."><p class="c-article-references__text" id="ref-CR27">Karras, T., Aila, T., Laine, S. &amp; Lehtinen, J. Progressive growing of GANs for improved quality, stability, and variation. In <i>International Conference on Learning Representations 2018</i> Paper 447 (ICLR, 2018).</p></li><li class="c-article-references__item js-c-reading-companion-references-item" data-counter="28."><p class="c-article-references__text" id="ref-CR28">Mirza, M. &amp; Osindero, S. Conditional generative adversarial nets. Preprint at <a href="https://arxiv.org/abs/1411.1784v1" data-track="click_references" data-track-action="external reference" data-track-value="external reference" data-track-label="https://arxiv.org/abs/1411.1784v1">https://arxiv.org/abs/1411.1784v1</a> (2014).</p></li><li class="c-article-references__item js-c-reading-companion-references-item" data-counter="29."><p class="c-article-references__text" id="ref-CR29">Odena, A., Olah, C. &amp; Shlens, J. Conditional image synthesis with auxiliary classifier GANs. In <i>Proceedings of the 34th International Conference on Machine Learning</i> (eds. Precup, D. &amp; Teh, Y. W.) 26422651 (PMLR, 2017).</p></li><li class="c-article-references__item js-c-reading-companion-references-item" data-counter="30."><p class="c-article-references__text" id="ref-CR30">Isola, P., Zhu, J.-Y., Zhou, T. &amp; Efros, A. A. Image-to-image translation with conditional adversarial networks. In <i>Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition</i> 59675976 (2018).</p></li><li class="c-article-references__item js-c-reading-companion-references-item" data-counter="31."><p class="c-article-references__text" id="ref-CR31">Zhang, H., Goodfellow, I., Metaxas, D. &amp; Odena, A. Self-attention generative adversarial networks. In <i>Proceedings of the 36th International Conference on Machine Learning</i> (eds. Chaudhuri, K. &amp; Salakhutdinov, R.) 73547363 (PMLR, 2019).</p></li><li class="c-article-references__item js-c-reading-companion-references-item" data-counter="32."><p class="c-article-references__text" id="ref-CR32">Wu, Y., Ma, Y., Liu, J., Du, J. &amp; Xing, L. Self-attention convolutional neural network for improved MR image reconstruction. <i>Inf. Sci.</i> <b>490</b>, 317328 (2019).</p><p class="c-article-references__links u-hide-print"><a data-track="click_references" rel="nofollow noopener" data-track-label="10.1016/j.ins.2019.03.080" data-track-item_id="10.1016/j.ins.2019.03.080" data-track-value="article reference" data-track-action="article reference" href="https://doi.org/10.1016%2Fj.ins.2019.03.080" aria-label="Article reference 32" data-doi="10.1016/j.ins.2019.03.080">Article</a>
    <a data-track="click_references" data-track-action="google scholar reference" data-track-value="google scholar reference" data-track-label="link" data-track-item_id="link" rel="nofollow noopener" aria-label="Google Scholar reference 32" href="http://scholar.google.com/scholar_lookup?&amp;title=Self-attention%20convolutional%20neural%20network%20for%20improved%20MR%20image%20reconstruction&amp;journal=Inf.%20Sci.&amp;doi=10.1016%2Fj.ins.2019.03.080&amp;volume=490&amp;pages=317-328&amp;publication_year=2019&amp;author=Wu%2CY&amp;author=Ma%2CY&amp;author=Liu%2CJ&amp;author=Du%2CJ&amp;author=Xing%2CL">
                    Google Scholar</a>
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" data-counter="33."><p class="c-article-references__text" id="ref-CR33">Brock, A., Donahue, J. &amp; Simonyan, K. Large scale GAN training for high fidelity natural image synthesis. In <i>International Conference on Learning Representations</i> Paper 564 (ICLR, 2019).</p></li><li class="c-article-references__item js-c-reading-companion-references-item" data-counter="34."><p class="c-article-references__text" id="ref-CR34">Arjovsky, M., Chintala, S. &amp; Bottou, L. Wasserstein generative adversarial networks. In <i>Proceedings of the 34th International Conference on Machine Learning</i> (eds. Precup, D. &amp; Teh, Y. W.) 214223 (PMLR, 2017).</p></li><li class="c-article-references__item js-c-reading-companion-references-item" data-counter="35."><p class="c-article-references__text" id="ref-CR35">Gulrajani, I., Ahmed, F., Arjovsky, M., Dumoulin, V. &amp; Courville, A. C. Improved training of Wasserstein GANs. In <i>Advances in Neural Information Processing Systems</i> 30 (eds. Guyon, I. et al.) Paper 2945 (Curran, 2017).</p></li><li class="c-article-references__item js-c-reading-companion-references-item" data-counter="36."><p class="c-article-references__text" id="ref-CR36">Hindupur, A. The-gan-zoo. <a href="https://github.com/hindupuravinash/the-gan-zoo" data-track="click_references" data-track-action="external reference" data-track-value="external reference" data-track-label="https://github.com/hindupuravinash/the-gan-zoo">https://github.com/hindupuravinash/the-gan-zoo</a> (2018).</p></li><li class="c-article-references__item js-c-reading-companion-references-item" data-counter="37."><p class="c-article-references__text" id="ref-CR37">Rajpurkar, P. et al. Deep learning for chest radiograph diagnosis: a retrospective comparison of the CheXNeXt algorithm to practicing radiologists. <i>PLoS Med.</i> <b>15</b>, e1002686 (2018).</p><p class="c-article-references__links u-hide-print"><a data-track="click_references" rel="nofollow noopener" data-track-label="10.1371/journal.pmed.1002686" data-track-item_id="10.1371/journal.pmed.1002686" data-track-value="article reference" data-track-action="article reference" href="https://doi.org/10.1371%2Fjournal.pmed.1002686" aria-label="Article reference 37" data-doi="10.1371/journal.pmed.1002686">Article</a>
    <a data-track="click_references" rel="nofollow noopener" data-track-label="link" data-track-item_id="link" data-track-value="pubmed reference" data-track-action="pubmed reference" href="http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?cmd=Retrieve&amp;db=PubMed&amp;dopt=Abstract&amp;list_uids=30457988" aria-label="PubMed reference 37">PubMed</a>
    <a data-track="click_references" rel="nofollow noopener" data-track-label="link" data-track-item_id="link" data-track-value="pubmed central reference" data-track-action="pubmed central reference" href="http://www.ncbi.nlm.nih.gov/pmc/articles/PMC6245676" aria-label="PubMed Central reference 37">PubMed Central</a>
    <a data-track="click_references" data-track-action="google scholar reference" data-track-value="google scholar reference" data-track-label="link" data-track-item_id="link" rel="nofollow noopener" aria-label="Google Scholar reference 37" href="http://scholar.google.com/scholar_lookup?&amp;title=Deep%20learning%20for%20chest%20radiograph%20diagnosis%3A%20a%20retrospective%20comparison%20of%20the%20CheXNeXt%20algorithm%20to%20practicing%20radiologists&amp;journal=PLoS%20Med.&amp;doi=10.1371%2Fjournal.pmed.1002686&amp;volume=15&amp;publication_year=2018&amp;author=Rajpurkar%2CP">
                    Google Scholar</a>
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" data-counter="38."><p class="c-article-references__text" id="ref-CR38">Ouyang, D. et al. Video-based AI for beat-to-beat assessment of cardiac function. <i>Nature</i> <b>580</b>, 252256 (2020).</p><p class="c-article-references__links u-hide-print"><a data-track="click_references" rel="nofollow noopener" data-track-label="10.1038/s41586-020-2145-8" data-track-item_id="10.1038/s41586-020-2145-8" data-track-value="article reference" data-track-action="article reference" href="https://doi.org/10.1038%2Fs41586-020-2145-8" aria-label="Article reference 38" data-doi="10.1038/s41586-020-2145-8">Article</a>
    <a data-track="click_references" rel="nofollow noopener" data-track-label="link" data-track-item_id="link" data-track-value="cas reference" data-track-action="cas reference" href="/articles/cas-redirect/1:CAS:528:DC%2BB3cXls1yrsbw%3D" aria-label="CAS reference 38">CAS</a>
    <a data-track="click_references" rel="nofollow noopener" data-track-label="link" data-track-item_id="link" data-track-value="pubmed reference" data-track-action="pubmed reference" href="http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?cmd=Retrieve&amp;db=PubMed&amp;dopt=Abstract&amp;list_uids=32269341" aria-label="PubMed reference 38">PubMed</a>
    <a data-track="click_references" rel="nofollow noopener" data-track-label="link" data-track-item_id="link" data-track-value="pubmed central reference" data-track-action="pubmed central reference" href="http://www.ncbi.nlm.nih.gov/pmc/articles/PMC8979576" aria-label="PubMed Central reference 38">PubMed Central</a>
    <a data-track="click_references" data-track-action="google scholar reference" data-track-value="google scholar reference" data-track-label="link" data-track-item_id="link" rel="nofollow noopener" aria-label="Google Scholar reference 38" href="http://scholar.google.com/scholar_lookup?&amp;title=Video-based%20AI%20for%20beat-to-beat%20assessment%20of%20cardiac%20function&amp;journal=Nature&amp;doi=10.1038%2Fs41586-020-2145-8&amp;volume=580&amp;pages=252-256&amp;publication_year=2020&amp;author=Ouyang%2CD">
                    Google Scholar</a>
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" data-counter="39."><p class="c-article-references__text" id="ref-CR39">Xue, Y., Xu, T., Zhang, H., Long, L. R. &amp; Huang, X. SegAN: adversarial network with multi-scale L1 loss for medical image segmentation. <i>Neuroinformatics</i> <b>16</b>, 383392 (2018).</p><p class="c-article-references__links u-hide-print"><a data-track="click_references" rel="noopener" data-track-label="10.1007/s12021-018-9377-x" data-track-item_id="10.1007/s12021-018-9377-x" data-track-value="article reference" data-track-action="article reference" href="https://link.springer.com/doi/10.1007/s12021-018-9377-x" aria-label="Article reference 39" data-doi="10.1007/s12021-018-9377-x">Article</a>
    <a data-track="click_references" rel="nofollow noopener" data-track-label="link" data-track-item_id="link" data-track-value="pubmed reference" data-track-action="pubmed reference" href="http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?cmd=Retrieve&amp;db=PubMed&amp;dopt=Abstract&amp;list_uids=29725916" aria-label="PubMed reference 39">PubMed</a>
    <a data-track="click_references" data-track-action="google scholar reference" data-track-value="google scholar reference" data-track-label="link" data-track-item_id="link" rel="nofollow noopener" aria-label="Google Scholar reference 39" href="http://scholar.google.com/scholar_lookup?&amp;title=SegAN%3A%20adversarial%20network%20with%20multi-scale%20L1%20loss%20for%20medical%20image%20segmentation&amp;journal=Neuroinformatics&amp;doi=10.1007%2Fs12021-018-9377-x&amp;volume=16&amp;pages=383-392&amp;publication_year=2018&amp;author=Xue%2CY&amp;author=Xu%2CT&amp;author=Zhang%2CH&amp;author=Long%2CLR&amp;author=Huang%2CX">
                    Google Scholar</a>
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" data-counter="40."><p class="c-article-references__text" id="ref-CR40">Haque, A., Milstein, A. &amp; Fei-Fei, L. Illuminating the dark spaces of healthcare with ambient intelligence. <i>Nature</i> <b>585</b>, 193202 (2020).</p><p class="c-article-references__links u-hide-print"><a data-track="click_references" rel="nofollow noopener" data-track-label="10.1038/s41586-020-2669-y" data-track-item_id="10.1038/s41586-020-2669-y" data-track-value="article reference" data-track-action="article reference" href="https://doi.org/10.1038%2Fs41586-020-2669-y" aria-label="Article reference 40" data-doi="10.1038/s41586-020-2669-y">Article</a>
    <a data-track="click_references" rel="nofollow noopener" data-track-label="link" data-track-item_id="link" data-track-value="cas reference" data-track-action="cas reference" href="/articles/cas-redirect/1:CAS:528:DC%2BB3cXhvFSlt7bE" aria-label="CAS reference 40">CAS</a>
    <a data-track="click_references" rel="nofollow noopener" data-track-label="link" data-track-item_id="link" data-track-value="pubmed reference" data-track-action="pubmed reference" href="http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?cmd=Retrieve&amp;db=PubMed&amp;dopt=Abstract&amp;list_uids=32908264" aria-label="PubMed reference 40">PubMed</a>
    <a data-track="click_references" data-track-action="google scholar reference" data-track-value="google scholar reference" data-track-label="link" data-track-item_id="link" rel="nofollow noopener" aria-label="Google Scholar reference 40" href="http://scholar.google.com/scholar_lookup?&amp;title=Illuminating%20the%20dark%20spaces%20of%20healthcare%20with%20ambient%20intelligence&amp;journal=Nature&amp;doi=10.1038%2Fs41586-020-2669-y&amp;volume=585&amp;pages=193-202&amp;publication_year=2020&amp;author=Haque%2CA&amp;author=Milstein%2CA&amp;author=Fei-Fei%2CL">
                    Google Scholar</a>
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" data-counter="41."><p class="c-article-references__text" id="ref-CR41">Zech, J. R. et al. Variable generalization performance of a deep learning model to detect pneumonia in chest radiographs: a cross-sectional study. <i>PLoS Med.</i> <b>15</b>, e1002683 (2018).</p><p class="c-article-references__links u-hide-print"><a data-track="click_references" rel="nofollow noopener" data-track-label="10.1371/journal.pmed.1002683" data-track-item_id="10.1371/journal.pmed.1002683" data-track-value="article reference" data-track-action="article reference" href="https://doi.org/10.1371%2Fjournal.pmed.1002683" aria-label="Article reference 41" data-doi="10.1371/journal.pmed.1002683">Article</a>
    <a data-track="click_references" rel="nofollow noopener" data-track-label="link" data-track-item_id="link" data-track-value="pubmed reference" data-track-action="pubmed reference" href="http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?cmd=Retrieve&amp;db=PubMed&amp;dopt=Abstract&amp;list_uids=30399157" aria-label="PubMed reference 41">PubMed</a>
    <a data-track="click_references" rel="nofollow noopener" data-track-label="link" data-track-item_id="link" data-track-value="pubmed central reference" data-track-action="pubmed central reference" href="http://www.ncbi.nlm.nih.gov/pmc/articles/PMC6219764" aria-label="PubMed Central reference 41">PubMed Central</a>
    <a data-track="click_references" data-track-action="google scholar reference" data-track-value="google scholar reference" data-track-label="link" data-track-item_id="link" rel="nofollow noopener" aria-label="Google Scholar reference 41" href="http://scholar.google.com/scholar_lookup?&amp;title=Variable%20generalization%20performance%20of%20a%20deep%20learning%20model%20to%20detect%20pneumonia%20in%20chest%20radiographs%3A%20a%20cross-sectional%20study&amp;journal=PLoS%20Med.&amp;doi=10.1371%2Fjournal.pmed.1002683&amp;volume=15&amp;publication_year=2018&amp;author=Zech%2CJR">
                    Google Scholar</a>
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" data-counter="42."><p class="c-article-references__text" id="ref-CR42">Zou, J. &amp; Schiebinger, L. AI can be sexist and racist  its time to make it fair. <i>Nature</i> <b>559</b>, 324326 (2018).</p><p class="c-article-references__links u-hide-print"><a data-track="click_references" rel="nofollow noopener" data-track-label="10.1038/d41586-018-05707-8" data-track-item_id="10.1038/d41586-018-05707-8" data-track-value="article reference" data-track-action="article reference" href="https://doi.org/10.1038%2Fd41586-018-05707-8" aria-label="Article reference 42" data-doi="10.1038/d41586-018-05707-8">Article</a>
    <a data-track="click_references" rel="nofollow noopener" data-track-label="link" data-track-item_id="link" data-track-value="cas reference" data-track-action="cas reference" href="/articles/cas-redirect/1:CAS:528:DC%2BC1cXhtlClsbbJ" aria-label="CAS reference 42">CAS</a>
    <a data-track="click_references" rel="nofollow noopener" data-track-label="link" data-track-item_id="link" data-track-value="pubmed reference" data-track-action="pubmed reference" href="http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?cmd=Retrieve&amp;db=PubMed&amp;dopt=Abstract&amp;list_uids=30018439" aria-label="PubMed reference 42">PubMed</a>
    <a data-track="click_references" data-track-action="google scholar reference" data-track-value="google scholar reference" data-track-label="link" data-track-item_id="link" rel="nofollow noopener" aria-label="Google Scholar reference 42" href="http://scholar.google.com/scholar_lookup?&amp;title=AI%20can%20be%20sexist%20and%20racist%20%E2%80%94%20it%E2%80%99s%20time%20to%20make%20it%20fair&amp;journal=Nature&amp;doi=10.1038%2Fd41586-018-05707-8&amp;volume=559&amp;pages=324-326&amp;publication_year=2018&amp;author=Zou%2CJ&amp;author=Schiebinger%2CL">
                    Google Scholar</a>
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" data-counter="43."><p class="c-article-references__text" id="ref-CR43">Perez, L. &amp; Wang, J. The effectiveness of data augmentation in image classification using deep learning. Preprint at <a href="https://arxiv.org/abs/1712.04621v1" data-track="click_references" data-track-action="external reference" data-track-value="external reference" data-track-label="https://arxiv.org/abs/1712.04621v1">https://arxiv.org/abs/1712.04621v1</a> (2017).</p></li><li class="c-article-references__item js-c-reading-companion-references-item" data-counter="44."><p class="c-article-references__text" id="ref-CR44">Madani, A., Moradi, M., Karargyris, A. &amp; Syeda-Mahmood, T. Semi-supervised learning with generative adversarial networks for chest X-ray classification with ability of data domain adaptation. In <i>IEEE 15th International Symposium on Biomedical Imaging</i> (ISBI) 10381042 (IEEE, 2018).</p></li><li class="c-article-references__item js-c-reading-companion-references-item" data-counter="45."><p class="c-article-references__text" id="ref-CR45">He, J. et al. The practical implementation of artificial intelligence technologies in medicine. <i>Nat. Med.</i> <b>25</b>, 3036 (2019).</p><p class="c-article-references__links u-hide-print"><a data-track="click_references" rel="nofollow noopener" data-track-label="10.1038/s41591-018-0307-0" data-track-item_id="10.1038/s41591-018-0307-0" data-track-value="article reference" data-track-action="article reference" href="https://doi.org/10.1038%2Fs41591-018-0307-0" aria-label="Article reference 45" data-doi="10.1038/s41591-018-0307-0">Article</a>
    <a data-track="click_references" rel="nofollow noopener" data-track-label="link" data-track-item_id="link" data-track-value="cas reference" data-track-action="cas reference" href="/articles/cas-redirect/1:CAS:528:DC%2BC1MXmvVOgtr0%3D" aria-label="CAS reference 45">CAS</a>
    <a data-track="click_references" rel="nofollow noopener" data-track-label="link" data-track-item_id="link" data-track-value="pubmed reference" data-track-action="pubmed reference" href="http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?cmd=Retrieve&amp;db=PubMed&amp;dopt=Abstract&amp;list_uids=30617336" aria-label="PubMed reference 45">PubMed</a>
    <a data-track="click_references" rel="nofollow noopener" data-track-label="link" data-track-item_id="link" data-track-value="pubmed central reference" data-track-action="pubmed central reference" href="http://www.ncbi.nlm.nih.gov/pmc/articles/PMC6995276" aria-label="PubMed Central reference 45">PubMed Central</a>
    <a data-track="click_references" data-track-action="google scholar reference" data-track-value="google scholar reference" data-track-label="link" data-track-item_id="link" rel="nofollow noopener" aria-label="Google Scholar reference 45" href="http://scholar.google.com/scholar_lookup?&amp;title=The%20practical%20implementation%20of%20artificial%20intelligence%20technologies%20in%20medicine&amp;journal=Nat.%20Med.&amp;doi=10.1038%2Fs41591-018-0307-0&amp;volume=25&amp;pages=30-36&amp;publication_year=2019&amp;author=He%2CJ">
                    Google Scholar</a>
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" data-counter="46."><p class="c-article-references__text" id="ref-CR46">Kelly, C. J., Karthikesalingam, A., Suleyman, M., Corrado, G. &amp; King, D. Key challenges for delivering clinical impact with artificial intelligence. <i>BMC Med.</i> <b>17</b>, 195 (2019).</p><p class="c-article-references__links u-hide-print"><a data-track="click_references" rel="noopener" data-track-label="10.1186/s12916-019-1426-2" data-track-item_id="10.1186/s12916-019-1426-2" data-track-value="article reference" data-track-action="article reference" href="https://link.springer.com/doi/10.1186/s12916-019-1426-2" aria-label="Article reference 46" data-doi="10.1186/s12916-019-1426-2">Article</a>
    <a data-track="click_references" rel="nofollow noopener" data-track-label="link" data-track-item_id="link" data-track-value="pubmed reference" data-track-action="pubmed reference" href="http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?cmd=Retrieve&amp;db=PubMed&amp;dopt=Abstract&amp;list_uids=31665002" aria-label="PubMed reference 46">PubMed</a>
    <a data-track="click_references" rel="nofollow noopener" data-track-label="link" data-track-item_id="link" data-track-value="pubmed central reference" data-track-action="pubmed central reference" href="http://www.ncbi.nlm.nih.gov/pmc/articles/PMC6821018" aria-label="PubMed Central reference 46">PubMed Central</a>
    <a data-track="click_references" data-track-action="google scholar reference" data-track-value="google scholar reference" data-track-label="link" data-track-item_id="link" rel="nofollow noopener" aria-label="Google Scholar reference 46" href="http://scholar.google.com/scholar_lookup?&amp;title=Key%20challenges%20for%20delivering%20clinical%20impact%20with%20artificial%20intelligence&amp;journal=BMC%20Med.&amp;doi=10.1186%2Fs12916-019-1426-2&amp;volume=17&amp;publication_year=2019&amp;author=Kelly%2CCJ&amp;author=Karthikesalingam%2CA&amp;author=Suleyman%2CM&amp;author=Corrado%2CG&amp;author=King%2CD">
                    Google Scholar</a>
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" data-counter="47."><p class="c-article-references__text" id="ref-CR47">Rocher, L., Hendrickx, J. M. &amp; de Montjoye, Y.-A. Estimating the success of re-identifications in incomplete datasets using generative models. <i>Nat. Commun.</i> <b>10</b>, 3069 (2019).</p><p class="c-article-references__links u-hide-print"><a data-track="click_references" rel="nofollow noopener" data-track-label="10.1038/s41467-019-10933-3" data-track-item_id="10.1038/s41467-019-10933-3" data-track-value="article reference" data-track-action="article reference" href="https://doi.org/10.1038%2Fs41467-019-10933-3" aria-label="Article reference 47" data-doi="10.1038/s41467-019-10933-3">Article</a>
    <a data-track="click_references" rel="nofollow noopener" data-track-label="link" data-track-item_id="link" data-track-value="pubmed reference" data-track-action="pubmed reference" href="http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?cmd=Retrieve&amp;db=PubMed&amp;dopt=Abstract&amp;list_uids=31337762" aria-label="PubMed reference 47">PubMed</a>
    <a data-track="click_references" rel="nofollow noopener" data-track-label="link" data-track-item_id="link" data-track-value="pubmed central reference" data-track-action="pubmed central reference" href="http://www.ncbi.nlm.nih.gov/pmc/articles/PMC6650473" aria-label="PubMed Central reference 47">PubMed Central</a>
    <a data-track="click_references" data-track-action="google scholar reference" data-track-value="google scholar reference" data-track-label="link" data-track-item_id="link" rel="nofollow noopener" aria-label="Google Scholar reference 47" href="http://scholar.google.com/scholar_lookup?&amp;title=Estimating%20the%20success%20of%20re-identifications%20in%20incomplete%20datasets%20using%20generative%20models&amp;journal=Nat.%20Commun.&amp;doi=10.1038%2Fs41467-019-10933-3&amp;volume=10&amp;publication_year=2019&amp;author=Rocher%2CL&amp;author=Hendrickx%2CJM&amp;author=Montjoye%2CY-A">
                    Google Scholar</a>
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" data-counter="48."><p class="c-article-references__text" id="ref-CR48">Schwarz, C. G. et al. Identification of anonymous MRI research participants with face-recognition software. <i>N. Engl. J. Med.</i> <b>381</b>, 16841686 (2019).</p><p class="c-article-references__links u-hide-print"><a data-track="click_references" rel="nofollow noopener" data-track-label="10.1056/NEJMc1908881" data-track-item_id="10.1056/NEJMc1908881" data-track-value="article reference" data-track-action="article reference" href="https://doi.org/10.1056%2FNEJMc1908881" aria-label="Article reference 48" data-doi="10.1056/NEJMc1908881">Article</a>
    <a data-track="click_references" rel="nofollow noopener" data-track-label="link" data-track-item_id="link" data-track-value="pubmed reference" data-track-action="pubmed reference" href="http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?cmd=Retrieve&amp;db=PubMed&amp;dopt=Abstract&amp;list_uids=31644852" aria-label="PubMed reference 48">PubMed</a>
    <a data-track="click_references" rel="nofollow noopener" data-track-label="link" data-track-item_id="link" data-track-value="pubmed central reference" data-track-action="pubmed central reference" href="http://www.ncbi.nlm.nih.gov/pmc/articles/PMC7091256" aria-label="PubMed Central reference 48">PubMed Central</a>
    <a data-track="click_references" data-track-action="google scholar reference" data-track-value="google scholar reference" data-track-label="link" data-track-item_id="link" rel="nofollow noopener" aria-label="Google Scholar reference 48" href="http://scholar.google.com/scholar_lookup?&amp;title=Identification%20of%20anonymous%20MRI%20research%20participants%20with%20face-recognition%20software&amp;journal=N.%20Engl.%20J.%20Med.&amp;doi=10.1056%2FNEJMc1908881&amp;volume=381&amp;pages=1684-1686&amp;publication_year=2019&amp;author=Schwarz%2CCG">
                    Google Scholar</a>
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" data-counter="49."><p class="c-article-references__text" id="ref-CR49">Chartsias, A., Joyce, T., Dharmakumar, R. &amp; Tsaftaris, S. A. Adversarial image synthesis for unpaired multi-modal cardiac data. in <i>Simulation and Synthesis in Medical Imaging</i> (eds. Tsaftaris, S. A., Gooya, A., Frangi, A. F. &amp; Prince, J. L.) 313 (Springer International Publishing, 2017).</p></li><li class="c-article-references__item js-c-reading-companion-references-item" data-counter="50."><p class="c-article-references__text" id="ref-CR50">Emami, H., Dong, M., Nejad-Davarani, S. P. &amp; Glide-Hurst, C. K. Generating synthetic CTs from magnetic resonance images using generative adversarial networks. <i>Med. Phys</i>. <a href="https://doi.org/10.1002/mp.13047" data-track="click_references" data-track-action="external reference" data-track-value="external reference" data-track-label="10.1002/mp.13047">https://doi.org/10.1002/mp.13047</a> (2018).</p></li><li class="c-article-references__item js-c-reading-companion-references-item" data-counter="51."><p class="c-article-references__text" id="ref-CR51">Jin, C.-B. et al. Deep CT to MR synthesis using paired and unpaired data. <i>Sensors</i> <b>19</b>, 2361 (2019).</p><p class="c-article-references__links u-hide-print"><a data-track="click_references" rel="nofollow noopener" data-track-label="10.3390/s19102361" data-track-item_id="10.3390/s19102361" data-track-value="article reference" data-track-action="article reference" href="https://doi.org/10.3390%2Fs19102361" aria-label="Article reference 51" data-doi="10.3390/s19102361">Article</a>
    <a data-track="click_references" rel="nofollow noopener" data-track-label="link" data-track-item_id="link" data-track-value="pubmed reference" data-track-action="pubmed reference" href="http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?cmd=Retrieve&amp;db=PubMed&amp;dopt=Abstract&amp;list_uids=31121961" aria-label="PubMed reference 51">PubMed</a>
    <a data-track="click_references" rel="nofollow noopener" data-track-label="link" data-track-item_id="link" data-track-value="pubmed central reference" data-track-action="pubmed central reference" href="http://www.ncbi.nlm.nih.gov/pmc/articles/PMC6566351" aria-label="PubMed Central reference 51">PubMed Central</a>
    <a data-track="click_references" data-track-action="google scholar reference" data-track-value="google scholar reference" data-track-label="link" data-track-item_id="link" rel="nofollow noopener" aria-label="Google Scholar reference 51" href="http://scholar.google.com/scholar_lookup?&amp;title=Deep%20CT%20to%20MR%20synthesis%20using%20paired%20and%20unpaired%20data&amp;journal=Sensors&amp;doi=10.3390%2Fs19102361&amp;volume=19&amp;publication_year=2019&amp;author=Jin%2CC-B">
                    Google Scholar</a>
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" data-counter="52."><p class="c-article-references__text" id="ref-CR52">Bi, L., Kim, J., Kumar, A., Feng, D. &amp; Fulham, M. In <i>Molecular Imaging, Reconstruction and Analysis of Moving Body Organs, and Stroke Imaging and Treatment</i> (eds. Cardoso, M. J. et al.) 4351 (Springer International Publishing, 2017).</p></li><li class="c-article-references__item js-c-reading-companion-references-item" data-counter="53."><p class="c-article-references__text" id="ref-CR53">Ben-Cohen, A. et al. Cross-modality synthesis from CT to PET using FCN and GAN networks for improved automated lesion detection. <i>Eng. Appl. Artif. Intell.</i> <b>78</b>, 186194 (2019).</p></li><li class="c-article-references__item js-c-reading-companion-references-item" data-counter="54."><p class="c-article-references__text" id="ref-CR54">Armanious, K. et al. MedGAN: medical image translation using GANs. <i>Comput. Med. Imaging Graph.</i> <b>79</b>, 101684 (2020).</p><p class="c-article-references__links u-hide-print"><a data-track="click_references" rel="nofollow noopener" data-track-label="10.1016/j.compmedimag.2019.101684" data-track-item_id="10.1016/j.compmedimag.2019.101684" data-track-value="article reference" data-track-action="article reference" href="https://doi.org/10.1016%2Fj.compmedimag.2019.101684" aria-label="Article reference 54" data-doi="10.1016/j.compmedimag.2019.101684">Article</a>
    <a data-track="click_references" rel="nofollow noopener" data-track-label="link" data-track-item_id="link" data-track-value="pubmed reference" data-track-action="pubmed reference" href="http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?cmd=Retrieve&amp;db=PubMed&amp;dopt=Abstract&amp;list_uids=31812132" aria-label="PubMed reference 54">PubMed</a>
    <a data-track="click_references" data-track-action="google scholar reference" data-track-value="google scholar reference" data-track-label="link" data-track-item_id="link" rel="nofollow noopener" aria-label="Google Scholar reference 54" href="http://scholar.google.com/scholar_lookup?&amp;title=MedGAN%3A%20medical%20image%20translation%20using%20GANs&amp;journal=Comput.%20Med.%20Imaging%20Graph.&amp;doi=10.1016%2Fj.compmedimag.2019.101684&amp;volume=79&amp;publication_year=2020&amp;author=Armanious%2CK">
                    Google Scholar</a>
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" data-counter="55."><p class="c-article-references__text" id="ref-CR55">Choi, H. &amp; Lee, D. S. Alzheimers Disease Neuroimaging Initiative. Generation of structural MR images from amyloid PET: application to MR-less quantification. <i>J. Nucl. Med.</i> <b>59</b>, 11111117 (2018).</p><p class="c-article-references__links u-hide-print"><a data-track="click_references" rel="nofollow noopener" data-track-label="10.2967/jnumed.117.199414" data-track-item_id="10.2967/jnumed.117.199414" data-track-value="article reference" data-track-action="article reference" href="https://doi.org/10.2967%2Fjnumed.117.199414" aria-label="Article reference 55" data-doi="10.2967/jnumed.117.199414">Article</a>
    <a data-track="click_references" rel="nofollow noopener" data-track-label="link" data-track-item_id="link" data-track-value="cas reference" data-track-action="cas reference" href="/articles/cas-redirect/1:CAS:528:DC%2BC1MXis1Cnsrk%3D" aria-label="CAS reference 55">CAS</a>
    <a data-track="click_references" rel="nofollow noopener" data-track-label="link" data-track-item_id="link" data-track-value="pubmed reference" data-track-action="pubmed reference" href="http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?cmd=Retrieve&amp;db=PubMed&amp;dopt=Abstract&amp;list_uids=29217736" aria-label="PubMed reference 55">PubMed</a>
    <a data-track="click_references" rel="nofollow noopener" data-track-label="link" data-track-item_id="link" data-track-value="pubmed central reference" data-track-action="pubmed central reference" href="http://www.ncbi.nlm.nih.gov/pmc/articles/PMC6910644" aria-label="PubMed Central reference 55">PubMed Central</a>
    <a data-track="click_references" data-track-action="google scholar reference" data-track-value="google scholar reference" data-track-label="link" data-track-item_id="link" rel="nofollow noopener" aria-label="Google Scholar reference 55" href="http://scholar.google.com/scholar_lookup?&amp;title=Alzheimer%E2%80%99s%20Disease%20Neuroimaging%20Initiative.%20Generation%20of%20structural%20MR%20images%20from%20amyloid%20PET%3A%20application%20to%20MR-less%20quantification&amp;journal=J.%20Nucl.%20Med.&amp;doi=10.2967%2Fjnumed.117.199414&amp;volume=59&amp;pages=1111-1117&amp;publication_year=2018&amp;author=Choi%2CH&amp;author=Lee%2CDS">
                    Google Scholar</a>
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" data-counter="56."><p class="c-article-references__text" id="ref-CR56">Wei, W. et al. Learning myelin content in multiple sclerosis from multimodal MRI through adversarial training. In <i>Medical Image Computing and Computer Assisted Intervention</i>  MICCAI 2018 (eds. Frangi, A. F., Schnabel, J. A., Davatzikos, C., Alberola-Lpez, C. &amp; Fichtinger, G.) 514522 (Springer Cham, 2018).</p></li><li class="c-article-references__item js-c-reading-companion-references-item" data-counter="57."><p class="c-article-references__text" id="ref-CR57">Pan, Y. et al. Synthesizing missing PET from MRI with cycle-consistent generative adversarial networks for Alzheimers disease diagnosis. In <i>Medical Image Computing and Computer Assisted Intervention</i> <i></i> MICCAI 2018 (eds. Frangi, A. F., Schnabel, J. A., Davatzikos, C., Alberola-Lpez, C. &amp; Fichtinger, G.) 455463 (Springer Cham, 2018).</p></li><li class="c-article-references__item js-c-reading-companion-references-item" data-counter="58."><p class="c-article-references__text" id="ref-CR58">Welander, P., Karlsson, S. &amp; Eklund, A. Generative adversarial networks for image-to-image translation on multi-contrast MR images - a comparison of CycleGAN and UNIT. Preprint at <a href="https://arxiv.org/abs/1806.07777v1" data-track="click_references" data-track-action="external reference" data-track-value="external reference" data-track-label="https://arxiv.org/abs/1806.07777v1">https://arxiv.org/abs/1806.07777v1</a> (2018).</p></li><li class="c-article-references__item js-c-reading-companion-references-item" data-counter="59."><p class="c-article-references__text" id="ref-CR59">Dar, S. U. H. et al. Image synthesis in multi-contrast MRI with conditional generative adversarial networks. <i>IEEE Trans. Med. Imaging</i> <b>38</b>, 23752388 (2019).</p></li><li class="c-article-references__item js-c-reading-companion-references-item" data-counter="60."><p class="c-article-references__text" id="ref-CR60">Zhu, J.-Y., Park, T., Isola, P. &amp; Efros, A. A. Unpaired image-to-image translation using cycle-consistent adversarial networks. In 2017 <i>IEEE International Conference on Computer Vision</i> (ICCV) (IEEE, 2017); <a href="https://doi.org/10.1109/iccv.2017.244" data-track="click_references" data-track-action="external reference" data-track-value="external reference" data-track-label="10.1109/iccv.2017.244">https://doi.org/10.1109/iccv.2017.244</a></p></li><li class="c-article-references__item js-c-reading-companion-references-item" data-counter="61."><p class="c-article-references__text" id="ref-CR61">Maspero, M. et al. Dose evaluation of fast synthetic-CT generation using a generative adversarial network for general pelvis MR-only radiotherapy. <i>Phys. Med. Biol.</i> <b>63</b>, 185001 (2018).</p><p class="c-article-references__links u-hide-print"><a data-track="click_references" rel="nofollow noopener" data-track-label="10.1088/1361-6560/aada6d" data-track-item_id="10.1088/1361-6560/aada6d" data-track-value="article reference" data-track-action="article reference" href="https://doi.org/10.1088%2F1361-6560%2Faada6d" aria-label="Article reference 61" data-doi="10.1088/1361-6560/aada6d">Article</a>
    <a data-track="click_references" rel="nofollow noopener" data-track-label="link" data-track-item_id="link" data-track-value="pubmed reference" data-track-action="pubmed reference" href="http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?cmd=Retrieve&amp;db=PubMed&amp;dopt=Abstract&amp;list_uids=30109989" aria-label="PubMed reference 61">PubMed</a>
    <a data-track="click_references" data-track-action="google scholar reference" data-track-value="google scholar reference" data-track-label="link" data-track-item_id="link" rel="nofollow noopener" aria-label="Google Scholar reference 61" href="http://scholar.google.com/scholar_lookup?&amp;title=Dose%20evaluation%20of%20fast%20synthetic-CT%20generation%20using%20a%20generative%20adversarial%20network%20for%20general%20pelvis%20MR-only%20radiotherapy&amp;journal=Phys.%20Med.%20Biol.&amp;doi=10.1088%2F1361-6560%2Faada6d&amp;volume=63&amp;publication_year=2018&amp;author=Maspero%2CM">
                    Google Scholar</a>
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" data-counter="62."><p class="c-article-references__text" id="ref-CR62">Olut, S., Sahin, Y.H., Demir, U., Unal, G. Generative adversarial training for MRA image synthesis using multi-contrast MRI. In <i>PRedictive Intelligence in MEdicine.</i> PRIME 2018. Lecture Notes in Computer Science (eds Rekik, I., Unal, G., Adeli, E. &amp; Park, S.) (Springer Cham, 2018); <a href="https://doi.org/10.1007/978-3-030-00320-3_18" data-track="click_references" data-track-action="external reference" data-track-value="external reference" data-track-label="10.1007/978-3-030-00320-3_18">https://doi.org/10.1007/978-3-030-00320-3_18</a></p></li><li class="c-article-references__item js-c-reading-companion-references-item" data-counter="63."><p class="c-article-references__text" id="ref-CR63">Chen, R. J., Lu, M. Y., Chen, T. Y., Williamson, D. F. K. &amp; Mahmood, F. Synthetic data in machine learning for medicine and healthcare. <i>Nat. Biomed. Eng.</i> <b>5</b>, 493497 (2021).</p><p class="c-article-references__links u-hide-print"><a data-track="click_references" rel="nofollow noopener" data-track-label="10.1038/s41551-021-00751-8" data-track-item_id="10.1038/s41551-021-00751-8" data-track-value="article reference" data-track-action="article reference" href="https://doi.org/10.1038%2Fs41551-021-00751-8" aria-label="Article reference 63" data-doi="10.1038/s41551-021-00751-8">Article</a>
    <a data-track="click_references" rel="nofollow noopener" data-track-label="link" data-track-item_id="link" data-track-value="pubmed reference" data-track-action="pubmed reference" href="http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?cmd=Retrieve&amp;db=PubMed&amp;dopt=Abstract&amp;list_uids=34131324" aria-label="PubMed reference 63">PubMed</a>
    <a data-track="click_references" rel="nofollow noopener" data-track-label="link" data-track-item_id="link" data-track-value="pubmed central reference" data-track-action="pubmed central reference" href="http://www.ncbi.nlm.nih.gov/pmc/articles/PMC9353344" aria-label="PubMed Central reference 63">PubMed Central</a>
    <a data-track="click_references" data-track-action="google scholar reference" data-track-value="google scholar reference" data-track-label="link" data-track-item_id="link" rel="nofollow noopener" aria-label="Google Scholar reference 63" href="http://scholar.google.com/scholar_lookup?&amp;title=Synthetic%20data%20in%20machine%20learning%20for%20medicine%20and%20healthcare&amp;journal=Nat.%20Biomed.%20Eng.&amp;doi=10.1038%2Fs41551-021-00751-8&amp;volume=5&amp;pages=493-497&amp;publication_year=2021&amp;author=Chen%2CRJ&amp;author=Lu%2CMY&amp;author=Chen%2CTY&amp;author=Williamson%2CDFK&amp;author=Mahmood%2CF">
                    Google Scholar</a>
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" data-counter="64."><p class="c-article-references__text" id="ref-CR64">Kanakasabapathy, M. K. et al. Adaptive adversarial neural networks for the analysis of lossy and domain-shifted datasets of medical images. <i>Nat. Biomed. Eng.</i> <b>5</b>, 571585 (2021).</p><p class="c-article-references__links u-hide-print"><a data-track="click_references" rel="nofollow noopener" data-track-label="10.1038/s41551-021-00733-w" data-track-item_id="10.1038/s41551-021-00733-w" data-track-value="article reference" data-track-action="article reference" href="https://doi.org/10.1038%2Fs41551-021-00733-w" aria-label="Article reference 64" data-doi="10.1038/s41551-021-00733-w">Article</a>
    <a data-track="click_references" rel="nofollow noopener" data-track-label="link" data-track-item_id="link" data-track-value="pubmed reference" data-track-action="pubmed reference" href="http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?cmd=Retrieve&amp;db=PubMed&amp;dopt=Abstract&amp;list_uids=34112997" aria-label="PubMed reference 64">PubMed</a>
    <a data-track="click_references" rel="nofollow noopener" data-track-label="link" data-track-item_id="link" data-track-value="pubmed central reference" data-track-action="pubmed central reference" href="http://www.ncbi.nlm.nih.gov/pmc/articles/PMC8943917" aria-label="PubMed Central reference 64">PubMed Central</a>
    <a data-track="click_references" data-track-action="google scholar reference" data-track-value="google scholar reference" data-track-label="link" data-track-item_id="link" rel="nofollow noopener" aria-label="Google Scholar reference 64" href="http://scholar.google.com/scholar_lookup?&amp;title=Adaptive%20adversarial%20neural%20networks%20for%20the%20analysis%20of%20lossy%20and%20domain-shifted%20datasets%20of%20medical%20images&amp;journal=Nat.%20Biomed.%20Eng.&amp;doi=10.1038%2Fs41551-021-00733-w&amp;volume=5&amp;pages=571-585&amp;publication_year=2021&amp;author=Kanakasabapathy%2CMK">
                    Google Scholar</a>
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" data-counter="65."><p class="c-article-references__text" id="ref-CR65">Bowles, C., Gunn, R., Hammers, A. &amp; Rueckert, D. Modelling the progression of Alzheimers disease in MRI using generative adversarial networks. In <i>Medical Imaging 2018: Image Processing</i> (eds. Angelini, E. D. &amp; Landman, B. A.) 397 407 (International Society for Optics and Photonics, 2018).</p></li><li class="c-article-references__item js-c-reading-companion-references-item" data-counter="66."><p class="c-article-references__text" id="ref-CR66">Ravi, D., Alexander, D.C., Oxtoby, N.P. &amp; Alzheimers Disease Neuroimaging Initiative. Degenerative adversarial neuroImage nets: generating images that mimic disease progression. In <i>Medical Image Computing and Computer Assisted Intervention</i>  MICCAI 2019. Lecture Notes in Computer Science. (eds Shen, D. et al) 164172 (Springer, 2019).</p></li><li class="c-article-references__item js-c-reading-companion-references-item" data-counter="67."><p class="c-article-references__text" id="ref-CR67">Borji, A. Pros and cons of GAN evaluation measures. <i>Comput. Vis. Image Underst.</i> <b>179</b>, 4165 (2019).</p><p class="c-article-references__links u-hide-print"><a data-track="click_references" rel="nofollow noopener" data-track-label="10.1016/j.cviu.2018.10.009" data-track-item_id="10.1016/j.cviu.2018.10.009" data-track-value="article reference" data-track-action="article reference" href="https://doi.org/10.1016%2Fj.cviu.2018.10.009" aria-label="Article reference 67" data-doi="10.1016/j.cviu.2018.10.009">Article</a>
    <a data-track="click_references" data-track-action="google scholar reference" data-track-value="google scholar reference" data-track-label="link" data-track-item_id="link" rel="nofollow noopener" aria-label="Google Scholar reference 67" href="http://scholar.google.com/scholar_lookup?&amp;title=Pros%20and%20cons%20of%20GAN%20evaluation%20measures&amp;journal=Comput.%20Vis.%20Image%20Underst.&amp;doi=10.1016%2Fj.cviu.2018.10.009&amp;volume=179&amp;pages=41-65&amp;publication_year=2019&amp;author=Borji%2CA">
                    Google Scholar</a>
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" data-counter="68."><p class="c-article-references__text" id="ref-CR68">Vincent, J. Nvidia uses AI to make it snow on streets that are always sunny. <i>The Verge</i> <a href="https://www.theverge.com/2017/12/5/16737260/ai-image-translation-nvidia-data-self-driving-cars" data-track="click_references" data-track-action="external reference" data-track-value="external reference" data-track-label="https://www.theverge.com/2017/12/5/16737260/ai-image-translation-nvidia-data-self-driving-cars">https://www.theverge.com/2017/12/5/16737260/ai-image-translation-nvidia-data-self-driving-cars</a> (2017).</p></li><li class="c-article-references__item js-c-reading-companion-references-item" data-counter="69."><p class="c-article-references__text" id="ref-CR69">Kairouz, P. et al. Advances and open problems in federated learning. <i>Found. Trends Mach. Learn.</i> <a href="https://doi.org/10.1561/2200000083" data-track="click_references" data-track-action="external reference" data-track-value="external reference" data-track-label="10.1561/2200000083">https://doi.org/10.1561/2200000083</a> (2021)</p></li><li class="c-article-references__item js-c-reading-companion-references-item" data-counter="70."><p class="c-article-references__text" id="ref-CR70">McMahan, B., Moore, E., Ramage, D., Hampson, S. &amp; Aguera y Arcas, B. Communication-efficient learning of deep networks from decentralized data. In <i>Proceedings of the 20th International Conference on Artificial Intelligence and Statistics</i> (eds. Singh, A. &amp; Zhu, J.) 12731282 (ML Research Press, 2017).</p></li><li class="c-article-references__item js-c-reading-companion-references-item" data-counter="71."><p class="c-article-references__text" id="ref-CR71">Li, X. et al. Multi-site fMRI analysis using privacy-preserving federated learning and domain adaptation: ABIDE results. <i>Med. Image Anal.</i> <b>65</b>, 101765 (2020).</p><p class="c-article-references__links u-hide-print"><a data-track="click_references" rel="nofollow noopener" data-track-label="10.1016/j.media.2020.101765" data-track-item_id="10.1016/j.media.2020.101765" data-track-value="article reference" data-track-action="article reference" href="https://doi.org/10.1016%2Fj.media.2020.101765" aria-label="Article reference 71" data-doi="10.1016/j.media.2020.101765">Article</a>
    <a data-track="click_references" rel="nofollow noopener" data-track-label="link" data-track-item_id="link" data-track-value="pubmed reference" data-track-action="pubmed reference" href="http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?cmd=Retrieve&amp;db=PubMed&amp;dopt=Abstract&amp;list_uids=32679533" aria-label="PubMed reference 71">PubMed</a>
    <a data-track="click_references" rel="nofollow noopener" data-track-label="link" data-track-item_id="link" data-track-value="pubmed central reference" data-track-action="pubmed central reference" href="http://www.ncbi.nlm.nih.gov/pmc/articles/PMC7569477" aria-label="PubMed Central reference 71">PubMed Central</a>
    <a data-track="click_references" data-track-action="google scholar reference" data-track-value="google scholar reference" data-track-label="link" data-track-item_id="link" rel="nofollow noopener" aria-label="Google Scholar reference 71" href="http://scholar.google.com/scholar_lookup?&amp;title=Multi-site%20fMRI%20analysis%20using%20privacy-preserving%20federated%20learning%20and%20domain%20adaptation%3A%20ABIDE%20results&amp;journal=Med.%20Image%20Anal.&amp;doi=10.1016%2Fj.media.2020.101765&amp;volume=65&amp;publication_year=2020&amp;author=Li%2CX">
                    Google Scholar</a>
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" data-counter="72."><p class="c-article-references__text" id="ref-CR72">Brisimi, T. S. et al. Federated learning of predictive models from federated Electronic Health Records. <i>Int. J. Med. Inform.</i> <b>112</b>, 5967 (2018).</p><p class="c-article-references__links u-hide-print"><a data-track="click_references" rel="nofollow noopener" data-track-label="10.1016/j.ijmedinf.2018.01.007" data-track-item_id="10.1016/j.ijmedinf.2018.01.007" data-track-value="article reference" data-track-action="article reference" href="https://doi.org/10.1016%2Fj.ijmedinf.2018.01.007" aria-label="Article reference 72" data-doi="10.1016/j.ijmedinf.2018.01.007">Article</a>
    <a data-track="click_references" rel="nofollow noopener" data-track-label="link" data-track-item_id="link" data-track-value="pubmed reference" data-track-action="pubmed reference" href="http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?cmd=Retrieve&amp;db=PubMed&amp;dopt=Abstract&amp;list_uids=29500022" aria-label="PubMed reference 72">PubMed</a>
    <a data-track="click_references" rel="nofollow noopener" data-track-label="link" data-track-item_id="link" data-track-value="pubmed central reference" data-track-action="pubmed central reference" href="http://www.ncbi.nlm.nih.gov/pmc/articles/PMC5836813" aria-label="PubMed Central reference 72">PubMed Central</a>
    <a data-track="click_references" data-track-action="google scholar reference" data-track-value="google scholar reference" data-track-label="link" data-track-item_id="link" rel="nofollow noopener" aria-label="Google Scholar reference 72" href="http://scholar.google.com/scholar_lookup?&amp;title=Federated%20learning%20of%20predictive%20models%20from%20federated%20Electronic%20Health%20Records&amp;journal=Int.%20J.%20Med.%20Inform.&amp;doi=10.1016%2Fj.ijmedinf.2018.01.007&amp;volume=112&amp;pages=59-67&amp;publication_year=2018&amp;author=Brisimi%2CTS">
                    Google Scholar</a>
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" data-counter="73."><p class="c-article-references__text" id="ref-CR73">Lee, J. et al. Privacy-preserving patient similarity learning in a federated environment: development and analysis. <i>JMIR Med. Inform.</i> <b>6</b>, e20 (2018).</p><p class="c-article-references__links u-hide-print"><a data-track="click_references" rel="nofollow noopener" data-track-label="10.2196/medinform.7744" data-track-item_id="10.2196/medinform.7744" data-track-value="article reference" data-track-action="article reference" href="https://doi.org/10.2196%2Fmedinform.7744" aria-label="Article reference 73" data-doi="10.2196/medinform.7744">Article</a>
    <a data-track="click_references" rel="nofollow noopener" data-track-label="link" data-track-item_id="link" data-track-value="pubmed reference" data-track-action="pubmed reference" href="http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?cmd=Retrieve&amp;db=PubMed&amp;dopt=Abstract&amp;list_uids=29653917" aria-label="PubMed reference 73">PubMed</a>
    <a data-track="click_references" rel="nofollow noopener" data-track-label="link" data-track-item_id="link" data-track-value="pubmed central reference" data-track-action="pubmed central reference" href="http://www.ncbi.nlm.nih.gov/pmc/articles/PMC5924379" aria-label="PubMed Central reference 73">PubMed Central</a>
    <a data-track="click_references" data-track-action="google scholar reference" data-track-value="google scholar reference" data-track-label="link" data-track-item_id="link" rel="nofollow noopener" aria-label="Google Scholar reference 73" href="http://scholar.google.com/scholar_lookup?&amp;title=Privacy-preserving%20patient%20similarity%20learning%20in%20a%20federated%20environment%3A%20development%20and%20analysis&amp;journal=JMIR%20Med.%20Inform.&amp;doi=10.2196%2Fmedinform.7744&amp;volume=6&amp;publication_year=2018&amp;author=Lee%2CJ">
                    Google Scholar</a>
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" data-counter="74."><p class="c-article-references__text" id="ref-CR74">Dou, Q. et al. Federated deep learning for detecting COVID-19 lung abnormalities in CT: a privacy-preserving multinational validation study. <i>npj Digit. Med.</i> <b>4</b>, 60 (2021).</p><p class="c-article-references__links u-hide-print"><a data-track="click_references" rel="nofollow noopener" data-track-label="10.1038/s41746-021-00431-6" data-track-item_id="10.1038/s41746-021-00431-6" data-track-value="article reference" data-track-action="article reference" href="https://doi.org/10.1038%2Fs41746-021-00431-6" aria-label="Article reference 74" data-doi="10.1038/s41746-021-00431-6">Article</a>
    <a data-track="click_references" rel="nofollow noopener" data-track-label="link" data-track-item_id="link" data-track-value="pubmed reference" data-track-action="pubmed reference" href="http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?cmd=Retrieve&amp;db=PubMed&amp;dopt=Abstract&amp;list_uids=33782526" aria-label="PubMed reference 74">PubMed</a>
    <a data-track="click_references" rel="nofollow noopener" data-track-label="link" data-track-item_id="link" data-track-value="pubmed central reference" data-track-action="pubmed central reference" href="http://www.ncbi.nlm.nih.gov/pmc/articles/PMC8007806" aria-label="PubMed Central reference 74">PubMed Central</a>
    <a data-track="click_references" data-track-action="google scholar reference" data-track-value="google scholar reference" data-track-label="link" data-track-item_id="link" rel="nofollow noopener" aria-label="Google Scholar reference 74" href="http://scholar.google.com/scholar_lookup?&amp;title=Federated%20deep%20learning%20for%20detecting%20COVID-19%20lung%20abnormalities%20in%20CT%3A%20a%20privacy-preserving%20multinational%20validation%20study&amp;journal=npj%20Digit.%20Med.&amp;doi=10.1038%2Fs41746-021-00431-6&amp;volume=4&amp;publication_year=2021&amp;author=Dou%2CQ">
                    Google Scholar</a>
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" data-counter="75."><p class="c-article-references__text" id="ref-CR75">Silva, S. et al. Federated learning in distributed medical databases: meta-analysis of large-scale subcortical brain data. In <i>2019 IEEE 16th International Symposium on Biomedical Imaging ISBI 2019</i> 18822077 (IEEE, 2019).</p></li><li class="c-article-references__item js-c-reading-companion-references-item" data-counter="76."><p class="c-article-references__text" id="ref-CR76">Sheller, M. J., Reina, G. A., Edwards, B., Martin, J. &amp; Bakas, S. Multi-institutional deep learning modeling without sharing patient data: a feasibility study on brain tumor segmentation. <i>Brainlesion</i> <b>11383</b>, 92104 (2019).</p><p class="c-article-references__links u-hide-print"><a data-track="click_references" rel="nofollow noopener" data-track-label="link" data-track-item_id="link" data-track-value="pubmed reference" data-track-action="pubmed reference" href="http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?cmd=Retrieve&amp;db=PubMed&amp;dopt=Abstract&amp;list_uids=31231720" aria-label="PubMed reference 76">PubMed</a>
    <a data-track="click_references" rel="nofollow noopener" data-track-label="link" data-track-item_id="link" data-track-value="pubmed central reference" data-track-action="pubmed central reference" href="http://www.ncbi.nlm.nih.gov/pmc/articles/PMC6589345" aria-label="PubMed Central reference 76">PubMed Central</a>
    <a data-track="click_references" data-track-action="google scholar reference" data-track-value="google scholar reference" data-track-label="link" data-track-item_id="link" rel="nofollow noopener" aria-label="Google Scholar reference 76" href="http://scholar.google.com/scholar_lookup?&amp;title=Multi-institutional%20deep%20learning%20modeling%20without%20sharing%20patient%20data%3A%20a%20feasibility%20study%20on%20brain%20tumor%20segmentation&amp;journal=Brainlesion&amp;volume=11383&amp;pages=92-104&amp;publication_year=2019&amp;author=Sheller%2CMJ&amp;author=Reina%2CGA&amp;author=Edwards%2CB&amp;author=Martin%2CJ&amp;author=Bakas%2CS">
                    Google Scholar</a>
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" data-counter="77."><p class="c-article-references__text" id="ref-CR77">Sheller, M. J. et al. Federated learning in medicine: facilitating multi-institutional collaborations without sharing patient data. <i>Sci. Rep.</i> <b>10</b>, 12598 (2020).</p><p class="c-article-references__links u-hide-print"><a data-track="click_references" rel="nofollow noopener" data-track-label="10.1038/s41598-020-69250-1" data-track-item_id="10.1038/s41598-020-69250-1" data-track-value="article reference" data-track-action="article reference" href="https://doi.org/10.1038%2Fs41598-020-69250-1" aria-label="Article reference 77" data-doi="10.1038/s41598-020-69250-1">Article</a>
    <a data-track="click_references" rel="nofollow noopener" data-track-label="link" data-track-item_id="link" data-track-value="pubmed reference" data-track-action="pubmed reference" href="http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?cmd=Retrieve&amp;db=PubMed&amp;dopt=Abstract&amp;list_uids=32724046" aria-label="PubMed reference 77">PubMed</a>
    <a data-track="click_references" rel="nofollow noopener" data-track-label="link" data-track-item_id="link" data-track-value="pubmed central reference" data-track-action="pubmed central reference" href="http://www.ncbi.nlm.nih.gov/pmc/articles/PMC7387485" aria-label="PubMed Central reference 77">PubMed Central</a>
    <a data-track="click_references" data-track-action="google scholar reference" data-track-value="google scholar reference" data-track-label="link" data-track-item_id="link" rel="nofollow noopener" aria-label="Google Scholar reference 77" href="http://scholar.google.com/scholar_lookup?&amp;title=Federated%20learning%20in%20medicine%3A%20facilitating%20multi-institutional%20collaborations%20without%20sharing%20patient%20data&amp;journal=Sci.%20Rep.&amp;doi=10.1038%2Fs41598-020-69250-1&amp;volume=10&amp;publication_year=2020&amp;author=Sheller%2CMJ">
                    Google Scholar</a>
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" data-counter="78."><p class="c-article-references__text" id="ref-CR78">Sarma, K. V. et al. Federated learning improves site performance in multicenter deep learning without data sharing. <i>J. Am. Med. Inform. Assoc.</i> <b>28</b>, 12591264 (2021).</p><p class="c-article-references__links u-hide-print"><a data-track="click_references" rel="nofollow noopener" data-track-label="10.1093/jamia/ocaa341" data-track-item_id="10.1093/jamia/ocaa341" data-track-value="article reference" data-track-action="article reference" href="https://doi.org/10.1093%2Fjamia%2Focaa341" aria-label="Article reference 78" data-doi="10.1093/jamia/ocaa341">Article</a>
    <a data-track="click_references" rel="nofollow noopener" data-track-label="link" data-track-item_id="link" data-track-value="pubmed reference" data-track-action="pubmed reference" href="http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?cmd=Retrieve&amp;db=PubMed&amp;dopt=Abstract&amp;list_uids=33537772" aria-label="PubMed reference 78">PubMed</a>
    <a data-track="click_references" rel="nofollow noopener" data-track-label="link" data-track-item_id="link" data-track-value="pubmed central reference" data-track-action="pubmed central reference" href="http://www.ncbi.nlm.nih.gov/pmc/articles/PMC8200268" aria-label="PubMed Central reference 78">PubMed Central</a>
    <a data-track="click_references" data-track-action="google scholar reference" data-track-value="google scholar reference" data-track-label="link" data-track-item_id="link" rel="nofollow noopener" aria-label="Google Scholar reference 78" href="http://scholar.google.com/scholar_lookup?&amp;title=Federated%20learning%20improves%20site%20performance%20in%20multicenter%20deep%20learning%20without%20data%20sharing&amp;journal=J.%20Am.%20Med.%20Inform.%20Assoc.&amp;doi=10.1093%2Fjamia%2Focaa341&amp;volume=28&amp;pages=1259-1264&amp;publication_year=2021&amp;author=Sarma%2CKV">
                    Google Scholar</a>
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" data-counter="79."><p class="c-article-references__text" id="ref-CR79">Li, W. et al. Privacy-preserving federated brain tumour segmentation. In <i>Machine Learning in Medical Imaging</i> (eds. Suk, H.-I., Liu, M., Yan, P. &amp; Lian, C.) 133141 (Springer International Publishing, 2019).</p></li><li class="c-article-references__item js-c-reading-companion-references-item" data-counter="80."><p class="c-article-references__text" id="ref-CR80">Shokri, R., Stronati, M., Song, C. &amp; Shmatikov, V. Membership inference attacks against machine learning models. In <i>IEEE Symposium on Security and Privacy</i> SP 2017 318 (IEEE, 2017).</p></li><li class="c-article-references__item js-c-reading-companion-references-item" data-counter="81."><p class="c-article-references__text" id="ref-CR81">Fredrikson, M., Jha, S. &amp; Ristenpart, T. Model inversion attacks that exploit confidence information and basic countermeasures. In <i>Proceedings of the 22nd ACM SIGSAC Conference on Computer and Communications Security</i> 13221333 (Association for Computing Machinery, 2015).</p></li><li class="c-article-references__item js-c-reading-companion-references-item" data-counter="82."><p class="c-article-references__text" id="ref-CR82">Zhang, C., Bengio, S., Hardt, M., Recht, B. &amp; Vinyals, O. Understanding deep learning (still) requires rethinking generalization. <i>Commun. ACM</i> <b>64</b>, 107115 (2021).</p><p class="c-article-references__links u-hide-print"><a data-track="click_references" rel="nofollow noopener" data-track-label="10.1145/3446776" data-track-item_id="10.1145/3446776" data-track-value="article reference" data-track-action="article reference" href="https://doi.org/10.1145%2F3446776" aria-label="Article reference 82" data-doi="10.1145/3446776">Article</a>
    <a data-track="click_references" data-track-action="google scholar reference" data-track-value="google scholar reference" data-track-label="link" data-track-item_id="link" rel="nofollow noopener" aria-label="Google Scholar reference 82" href="http://scholar.google.com/scholar_lookup?&amp;title=Understanding%20deep%20learning%20%28still%29%20requires%20rethinking%20generalization&amp;journal=Commun.%20ACM&amp;doi=10.1145%2F3446776&amp;volume=64&amp;pages=107-115&amp;publication_year=2021&amp;author=Zhang%2CC&amp;author=Bengio%2CS&amp;author=Hardt%2CM&amp;author=Recht%2CB&amp;author=Vinyals%2CO">
                    Google Scholar</a>
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" data-counter="83."><p class="c-article-references__text" id="ref-CR83">Zhu, L., Liu, Z. &amp; Han, S. Deep leakage from gradients. In <i>Advances in Neural Information Processing Systems</i> 32 (eds Wallach, H. et al.) Paper 8389 (Curran, 2019)</p></li><li class="c-article-references__item js-c-reading-companion-references-item" data-counter="84."><p class="c-article-references__text" id="ref-CR84">Abadi, M. et al. Deep learning with differential privacy. In <i>Proceedings of the 2016 ACM SIGSAC Conference on Computer and Communications Security</i> 308318 (Association for Computing Machinery, 2016).</p></li><li class="c-article-references__item js-c-reading-companion-references-item" data-counter="85."><p class="c-article-references__text" id="ref-CR85">Brendan McMahan, H. et al. A general approach to adding differential privacy to iterative training procedures. Preprint at <a href="https://arxiv.org/abs/1812.06210v2" data-track="click_references" data-track-action="external reference" data-track-value="external reference" data-track-label="https://arxiv.org/abs/1812.06210v2">https://arxiv.org/abs/1812.06210v2</a> (2018).</p></li><li class="c-article-references__item js-c-reading-companion-references-item" data-counter="86."><p class="c-article-references__text" id="ref-CR86">McMahan, H. B., Ramage, D., Talwar, K. &amp; Zhang, L. Learning differentially private recurrent language models. In <i>ICLR 2018 Sixth International Conference on Learning Representations</i> Paper 504 (ICLR, 2018).</p></li><li class="c-article-references__item js-c-reading-companion-references-item" data-counter="87."><p class="c-article-references__text" id="ref-CR87">Shokri, R. &amp; Shmatikov, V. Privacy-preserving deep learning. In <i>Proceedings of the 22nd ACM SIGSAC Conference on Computer and Communications Security</i> 13101321 (Association for Computing Machinery, 2015).</p></li><li class="c-article-references__item js-c-reading-companion-references-item" data-counter="88."><p class="c-article-references__text" id="ref-CR88">Lyu, M., Su, D. &amp; Li, N. Understanding the sparse vector technique for differential privacy. <i>Proc. VLDB Endow.</i> <b>10</b>, 637648 (2017).</p><p class="c-article-references__links u-hide-print"><a data-track="click_references" rel="nofollow noopener" data-track-label="10.14778/3055330.3055331" data-track-item_id="10.14778/3055330.3055331" data-track-value="article reference" data-track-action="article reference" href="https://doi.org/10.14778%2F3055330.3055331" aria-label="Article reference 88" data-doi="10.14778/3055330.3055331">Article</a>
    <a data-track="click_references" data-track-action="google scholar reference" data-track-value="google scholar reference" data-track-label="link" data-track-item_id="link" rel="nofollow noopener" aria-label="Google Scholar reference 88" href="http://scholar.google.com/scholar_lookup?&amp;title=Understanding%20the%20sparse%20vector%20technique%20for%20differential%20privacy&amp;journal=Proc.%20VLDB%20Endow.&amp;doi=10.14778%2F3055330.3055331&amp;volume=10&amp;pages=637-648&amp;publication_year=2017&amp;author=Lyu%2CM&amp;author=Su%2CD&amp;author=Li%2CN">
                    Google Scholar</a>
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" data-counter="89."><p class="c-article-references__text" id="ref-CR89">Hitaj, B., Ateniese, G. &amp; Perez-Cruz, F. Deep models under the GAN: information leakage from collaborative deep learning. In <i>Proceedings of the 2017 ACM SIGSAC Conference on Computer and Communications Security</i> 603618 (Association for Computing Machinery, 2017).</p></li><li class="c-article-references__item js-c-reading-companion-references-item" data-counter="90."><p class="c-article-references__text" id="ref-CR90">Li, X., Huang, K., Yang, W., Wang, S. &amp; Zhang, Z. On the convergence of FedAvg on Non-IID Data. In <i>ICLR 2020 Eighth International Conference on Learning Representations</i> Paper 261 (2020).</p></li><li class="c-article-references__item js-c-reading-companion-references-item" data-counter="91."><p class="c-article-references__text" id="ref-CR91">Smith, V., Chiang, C.-K., Sanjabi, M. &amp; Talwalkar, A. S. Federated multi-task learning. In <i>Advances in Neural Information Processing Systems</i> 30 (eds Guyon, I. et al.) Paper 2307 (NeuIPS, 2017).</p></li><li class="c-article-references__item js-c-reading-companion-references-item" data-counter="92."><p class="c-article-references__text" id="ref-CR92">Xu, J. et al. Federated learning for healthcare informatics. <i>J. Healthc. Inform. Res.</i> <b>5</b>, 119 (2021).</p><p class="c-article-references__links u-hide-print"><a data-track="click_references" rel="noopener" data-track-label="10.1007/s41666-020-00082-4" data-track-item_id="10.1007/s41666-020-00082-4" data-track-value="article reference" data-track-action="article reference" href="https://link.springer.com/doi/10.1007/s41666-020-00082-4" aria-label="Article reference 92" data-doi="10.1007/s41666-020-00082-4">Article</a>
    <a data-track="click_references" rel="nofollow noopener" data-track-label="link" data-track-item_id="link" data-track-value="pubmed reference" data-track-action="pubmed reference" href="http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?cmd=Retrieve&amp;db=PubMed&amp;dopt=Abstract&amp;list_uids=33204939" aria-label="PubMed reference 92">PubMed</a>
    <a data-track="click_references" data-track-action="google scholar reference" data-track-value="google scholar reference" data-track-label="link" data-track-item_id="link" rel="nofollow noopener" aria-label="Google Scholar reference 92" href="http://scholar.google.com/scholar_lookup?&amp;title=Federated%20learning%20for%20healthcare%20informatics&amp;journal=J.%20Healthc.%20Inform.%20Res.&amp;doi=10.1007%2Fs41666-020-00082-4&amp;volume=5&amp;pages=1-19&amp;publication_year=2021&amp;author=Xu%2CJ">
                    Google Scholar</a>
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" data-counter="93."><p class="c-article-references__text" id="ref-CR93">Huang, L. et al. LoAdaBoost: loss-based AdaBoost federated machine learning with reduced computational complexity on IID and non-IID intensive care data. <i>PLoS ONE</i> <b>15</b>, e0230706 (2020).</p><p class="c-article-references__links u-hide-print"><a data-track="click_references" rel="nofollow noopener" data-track-label="10.1371/journal.pone.0230706" data-track-item_id="10.1371/journal.pone.0230706" data-track-value="article reference" data-track-action="article reference" href="https://doi.org/10.1371%2Fjournal.pone.0230706" aria-label="Article reference 93" data-doi="10.1371/journal.pone.0230706">Article</a>
    <a data-track="click_references" rel="nofollow noopener" data-track-label="link" data-track-item_id="link" data-track-value="cas reference" data-track-action="cas reference" href="/articles/cas-redirect/1:CAS:528:DC%2BB3cXosVGjsbc%3D" aria-label="CAS reference 93">CAS</a>
    <a data-track="click_references" rel="nofollow noopener" data-track-label="link" data-track-item_id="link" data-track-value="pubmed reference" data-track-action="pubmed reference" href="http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?cmd=Retrieve&amp;db=PubMed&amp;dopt=Abstract&amp;list_uids=32302316" aria-label="PubMed reference 93">PubMed</a>
    <a data-track="click_references" rel="nofollow noopener" data-track-label="link" data-track-item_id="link" data-track-value="pubmed central reference" data-track-action="pubmed central reference" href="http://www.ncbi.nlm.nih.gov/pmc/articles/PMC7164603" aria-label="PubMed Central reference 93">PubMed Central</a>
    <a data-track="click_references" data-track-action="google scholar reference" data-track-value="google scholar reference" data-track-label="link" data-track-item_id="link" rel="nofollow noopener" aria-label="Google Scholar reference 93" href="http://scholar.google.com/scholar_lookup?&amp;title=LoAdaBoost%3A%20loss-based%20AdaBoost%20federated%20machine%20learning%20with%20reduced%20computational%20complexity%20on%20IID%20and%20non-IID%20intensive%20care%20data&amp;journal=PLoS%20ONE&amp;doi=10.1371%2Fjournal.pone.0230706&amp;volume=15&amp;publication_year=2020&amp;author=Huang%2CL">
                    Google Scholar</a>
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" data-counter="94."><p class="c-article-references__text" id="ref-CR94">Zhao, Y. et al. Federated learning with non-IID data. Preprint at <a href="https://arxiv.org/abs/1806.00582v1" data-track="click_references" data-track-action="external reference" data-track-value="external reference" data-track-label="https://arxiv.org/abs/1806.00582v1">https://arxiv.org/abs/1806.00582v1</a> (2018).</p></li><li class="c-article-references__item js-c-reading-companion-references-item" data-counter="95."><p class="c-article-references__text" id="ref-CR95">Torres-Soto, J. &amp; Ashley, E. A. Multi-task deep learning for cardiac rhythm detection in wearable devices. <i>npj Digit. Med.</i> <b>3</b>, 116 (2020).</p><p class="c-article-references__links u-hide-print"><a data-track="click_references" rel="nofollow noopener" data-track-label="10.1038/s41746-020-00320-4" data-track-item_id="10.1038/s41746-020-00320-4" data-track-value="article reference" data-track-action="article reference" href="https://doi.org/10.1038%2Fs41746-020-00320-4" aria-label="Article reference 95" data-doi="10.1038/s41746-020-00320-4">Article</a>
    <a data-track="click_references" rel="nofollow noopener" data-track-label="link" data-track-item_id="link" data-track-value="pubmed reference" data-track-action="pubmed reference" href="http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?cmd=Retrieve&amp;db=PubMed&amp;dopt=Abstract&amp;list_uids=32964139" aria-label="PubMed reference 95">PubMed</a>
    <a data-track="click_references" rel="nofollow noopener" data-track-label="link" data-track-item_id="link" data-track-value="pubmed central reference" data-track-action="pubmed central reference" href="http://www.ncbi.nlm.nih.gov/pmc/articles/PMC7481177" aria-label="PubMed Central reference 95">PubMed Central</a>
    <a data-track="click_references" data-track-action="google scholar reference" data-track-value="google scholar reference" data-track-label="link" data-track-item_id="link" rel="nofollow noopener" aria-label="Google Scholar reference 95" href="http://scholar.google.com/scholar_lookup?&amp;title=Multi-task%20deep%20learning%20for%20cardiac%20rhythm%20detection%20in%20wearable%20devices&amp;journal=npj%20Digit.%20Med.&amp;doi=10.1038%2Fs41746-020-00320-4&amp;volume=3&amp;publication_year=2020&amp;author=Torres-Soto%2CJ&amp;author=Ashley%2CEA">
                    Google Scholar</a>
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" data-counter="96."><p class="c-article-references__text" id="ref-CR96">Turakhia, M. P. et al. Rationale and design of a large-scale, app-based study to identify cardiac arrhythmias using a smartwatch: The Apple Heart Study. <i>Am. Heart J.</i> <b>207</b>, 6675 (2019).</p><p class="c-article-references__links u-hide-print"><a data-track="click_references" rel="nofollow noopener" data-track-label="10.1016/j.ahj.2018.09.002" data-track-item_id="10.1016/j.ahj.2018.09.002" data-track-value="article reference" data-track-action="article reference" href="https://doi.org/10.1016%2Fj.ahj.2018.09.002" aria-label="Article reference 96" data-doi="10.1016/j.ahj.2018.09.002">Article</a>
    <a data-track="click_references" rel="nofollow noopener" data-track-label="link" data-track-item_id="link" data-track-value="pubmed reference" data-track-action="pubmed reference" href="http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?cmd=Retrieve&amp;db=PubMed&amp;dopt=Abstract&amp;list_uids=30392584" aria-label="PubMed reference 96">PubMed</a>
    <a data-track="click_references" data-track-action="google scholar reference" data-track-value="google scholar reference" data-track-label="link" data-track-item_id="link" rel="nofollow noopener" aria-label="Google Scholar reference 96" href="http://scholar.google.com/scholar_lookup?&amp;title=Rationale%20and%20design%20of%20a%20large-scale%2C%20app-based%20study%20to%20identify%20cardiac%20arrhythmias%20using%20a%20smartwatch%3A%20The%20Apple%20Heart%20Study&amp;journal=Am.%20Heart%20J.&amp;doi=10.1016%2Fj.ahj.2018.09.002&amp;volume=207&amp;pages=66-75&amp;publication_year=2019&amp;author=Turakhia%2CMP">
                    Google Scholar</a>
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" data-counter="97."><p class="c-article-references__text" id="ref-CR97">Synced. Apple reveals design of its on-device ML system for federated evaluation and tuning <i>SyncedReview</i> <a href="https://syncedreview.com/2021/02/19/apple-reveals-design-of-its-on-device-ml-system-for-federated-evaluation-and-tuning" data-track="click_references" data-track-action="external reference" data-track-value="external reference" data-track-label="https://syncedreview.com/2021/02/19/apple-reveals-design-of-its-on-device-ml-system-for-federated-evaluation-and-tuning">https://syncedreview.com/2021/02/19/apple-reveals-design-of-its-on-device-ml-system-for-federated-evaluation-and-tuning</a> (2021).</p></li><li class="c-article-references__item js-c-reading-companion-references-item" data-counter="98."><p class="c-article-references__text" id="ref-CR98">McMahan, B. &amp; Ramage, D. Federated learning: collaborative machine learning without centralized training data <i>Google AI Blog</i> <a href="https://ai.googleblog.com/2017/04/federated-learning-collaborative.html" data-track="click_references" data-track-action="external reference" data-track-value="external reference" data-track-label="https://ai.googleblog.com/2017/04/federated-learning-collaborative.html">https://ai.googleblog.com/2017/04/federated-learning-collaborative.html</a> (2017).</p></li><li class="c-article-references__item js-c-reading-companion-references-item" data-counter="99."><p class="c-article-references__text" id="ref-CR99">Chen, Y., Qin, X., Wang, J., Yu, C. &amp; Gao, W. FedHealth: a federated transfer learning framework for wearable healthcare. <i>IEEE Intell. Syst.</i> <b>35</b>, 8393 (2020).</p><p class="c-article-references__links u-hide-print"><a data-track="click_references" rel="nofollow noopener" data-track-label="10.1109/MIS.2020.2988604" data-track-item_id="10.1109/MIS.2020.2988604" data-track-value="article reference" data-track-action="article reference" href="https://doi.org/10.1109%2FMIS.2020.2988604" aria-label="Article reference 99" data-doi="10.1109/MIS.2020.2988604">Article</a>
    <a data-track="click_references" data-track-action="google scholar reference" data-track-value="google scholar reference" data-track-label="link" data-track-item_id="link" rel="nofollow noopener" aria-label="Google Scholar reference 99" href="http://scholar.google.com/scholar_lookup?&amp;title=FedHealth%3A%20a%20federated%20transfer%20learning%20framework%20for%20wearable%20healthcare&amp;journal=IEEE%20Intell.%20Syst.&amp;doi=10.1109%2FMIS.2020.2988604&amp;volume=35&amp;pages=83-93&amp;publication_year=2020&amp;author=Chen%2CY&amp;author=Qin%2CX&amp;author=Wang%2CJ&amp;author=Yu%2CC&amp;author=Gao%2CW">
                    Google Scholar</a>
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" data-counter="100."><p class="c-article-references__text" id="ref-CR100">Ramage, D. &amp; Mazzocchi, S. Federated analytics: collaborative data science without data collection <i>Google AI Blog</i> <a href="https://ai.googleblog.com/2020/05/federated-analytics-collaborative-data.html" data-track="click_references" data-track-action="external reference" data-track-value="external reference" data-track-label="https://ai.googleblog.com/2020/05/federated-analytics-collaborative-data.html">https://ai.googleblog.com/2020/05/federated-analytics-collaborative-data.html</a> (2020).</p></li><li class="c-article-references__item js-c-reading-companion-references-item" data-counter="101."><p class="c-article-references__text" id="ref-CR101">Augenstein, S. et al. Generative models for effective ML on private, decentralized datasets. In <i>ICLR 2020 Eighth International Conference on Learning Representations</i> Paper 1448 (ICLR, 2020).</p></li><li class="c-article-references__item js-c-reading-companion-references-item" data-counter="102."><p class="c-article-references__text" id="ref-CR102">Pati, S. et al. The federated tumor segmentation (FeTS) challenge. Preprint at <a href="https://arxiv.org/abs/2105.05874v2" data-track="click_references" data-track-action="external reference" data-track-value="external reference" data-track-label="https://arxiv.org/abs/2105.05874v2">https://arxiv.org/abs/2105.05874v2</a> (2021).</p></li><li class="c-article-references__item js-c-reading-companion-references-item" data-counter="103."><p class="c-article-references__text" id="ref-CR103">Flores, M. Medical institutions collaborate to improve mammogram assessment AI with Nvidia Clara federated learning <i>The AI Podcast</i> <a href="https://blogs.nvidia.com/blog/2020/04/15/federated-learning" data-track="click_references" data-track-action="external reference" data-track-value="external reference" data-track-label="https://blogs.nvidia.com/blog/2020/04/15/federated-learning">https://blogs.nvidia.com/blog/2020/04/15/federated-learning-mammogram-assessment/</a> (2020).</p></li><li class="c-article-references__item js-c-reading-companion-references-item" data-counter="104."><p class="c-article-references__text" id="ref-CR104">Kannan, A., Chen, K., Jaunzeikare, D. &amp; Rajkomar, A. Semi-supervised learning for information extraction from dialogue. In <i>Proc. Interspeech 2018</i> 20772081 (ISCA, 2018); <a href="https://doi.org/10.21437/interspeech.2018-1318" data-track="click_references" data-track-action="external reference" data-track-value="external reference" data-track-label="10.21437/interspeech.2018-1318">https://doi.org/10.21437/interspeech.2018-1318</a></p></li><li class="c-article-references__item js-c-reading-companion-references-item" data-counter="105."><p class="c-article-references__text" id="ref-CR105">Chiu, C.-C. et al. Speech recognition for medical conversations. Preprint at <a href="https://arxiv.org/abs/1711.07274v2" data-track="click_references" data-track-action="external reference" data-track-value="external reference" data-track-label="https://arxiv.org/abs/1711.07274v2">https://arxiv.org/abs/1711.07274v2</a>; <a href="https://doi.org/10.1093/jamia/ocx073" data-track="click_references" data-track-action="external reference" data-track-value="external reference" data-track-label="10.1093/jamia/ocx073">https://doi.org/10.1093/jamia/ocx073</a> (2017).</p></li><li class="c-article-references__item js-c-reading-companion-references-item" data-counter="106."><p class="c-article-references__text" id="ref-CR106">Si, Y., Wang, J., Xu, H. &amp; Roberts, K. Enhancing clinical concept extraction with contextual embeddings. <i>J. Am. Med. Inform. Assoc.</i> <b>26</b>, 12971304 (2019).</p><p class="c-article-references__links u-hide-print"><a data-track="click_references" rel="nofollow noopener" data-track-label="10.1093/jamia/ocz096" data-track-item_id="10.1093/jamia/ocz096" data-track-value="article reference" data-track-action="article reference" href="https://doi.org/10.1093%2Fjamia%2Focz096" aria-label="Article reference 106" data-doi="10.1093/jamia/ocz096">Article</a>
    <a data-track="click_references" rel="nofollow noopener" data-track-label="link" data-track-item_id="link" data-track-value="pubmed reference" data-track-action="pubmed reference" href="http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?cmd=Retrieve&amp;db=PubMed&amp;dopt=Abstract&amp;list_uids=31265066" aria-label="PubMed reference 106">PubMed</a>
    <a data-track="click_references" rel="nofollow noopener" data-track-label="link" data-track-item_id="link" data-track-value="pubmed central reference" data-track-action="pubmed central reference" href="http://www.ncbi.nlm.nih.gov/pmc/articles/PMC6798561" aria-label="PubMed Central reference 106">PubMed Central</a>
    <a data-track="click_references" data-track-action="google scholar reference" data-track-value="google scholar reference" data-track-label="link" data-track-item_id="link" rel="nofollow noopener" aria-label="Google Scholar reference 106" href="http://scholar.google.com/scholar_lookup?&amp;title=Enhancing%20clinical%20concept%20extraction%20with%20contextual%20embeddings&amp;journal=J.%20Am.%20Med.%20Inform.%20Assoc.&amp;doi=10.1093%2Fjamia%2Focz096&amp;volume=26&amp;pages=1297-1304&amp;publication_year=2019&amp;author=Si%2CY&amp;author=Wang%2CJ&amp;author=Xu%2CH&amp;author=Roberts%2CK">
                    Google Scholar</a>
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" data-counter="107."><p class="c-article-references__text" id="ref-CR107">Shin, H.-C. et al. Learning to read chest X-rays: recurrent neural cascade model for automated image annotation. In <i>2016 IEEE Conference on Computer Vision and Pattern Recognition</i> (CVPR) (IEEE, 2016); <a href="https://doi.org/10.1109/cvpr.2016.274" data-track="click_references" data-track-action="external reference" data-track-value="external reference" data-track-label="10.1109/cvpr.2016.274">https://doi.org/10.1109/cvpr.2016.274</a></p></li><li class="c-article-references__item js-c-reading-companion-references-item" data-counter="108."><p class="c-article-references__text" id="ref-CR108">Wang, X., Peng, Y., Lu, L., Lu, Z. &amp; Summers, R. M. TieNet: text-image embedding network for common thorax disease classification and reporting in chest X-rays. In <i>IEEE/CVF Conference on Computer Vision and Pattern Recognition 2018</i> (IEEE, 2018); <a href="https://doi.org/10.1109/cvpr.2018.00943" data-track="click_references" data-track-action="external reference" data-track-value="external reference" data-track-label="10.1109/cvpr.2018.00943">https://doi.org/10.1109/cvpr.2018.00943</a></p></li><li class="c-article-references__item js-c-reading-companion-references-item" data-counter="109."><p class="c-article-references__text" id="ref-CR109">Hochreiter, S. &amp; Schmidhuber, J. Long short-term memory. <i>Neural Comput.</i> <b>9</b>, 17351780 (1997).</p><p class="c-article-references__links u-hide-print"><a data-track="click_references" rel="nofollow noopener" data-track-label="10.1162/neco.1997.9.8.1735" data-track-item_id="10.1162/neco.1997.9.8.1735" data-track-value="article reference" data-track-action="article reference" href="https://doi.org/10.1162%2Fneco.1997.9.8.1735" aria-label="Article reference 109" data-doi="10.1162/neco.1997.9.8.1735">Article</a>
    <a data-track="click_references" rel="nofollow noopener" data-track-label="link" data-track-item_id="link" data-track-value="cas reference" data-track-action="cas reference" href="/articles/cas-redirect/1:STN:280:DyaK1c%2FhvVahsQ%3D%3D" aria-label="CAS reference 109">CAS</a>
    <a data-track="click_references" rel="nofollow noopener" data-track-label="link" data-track-item_id="link" data-track-value="pubmed reference" data-track-action="pubmed reference" href="http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?cmd=Retrieve&amp;db=PubMed&amp;dopt=Abstract&amp;list_uids=9377276" aria-label="PubMed reference 109">PubMed</a>
    <a data-track="click_references" data-track-action="google scholar reference" data-track-value="google scholar reference" data-track-label="link" data-track-item_id="link" rel="nofollow noopener" aria-label="Google Scholar reference 109" href="http://scholar.google.com/scholar_lookup?&amp;title=Long%20short-term%20memory&amp;journal=Neural%20Comput.&amp;doi=10.1162%2Fneco.1997.9.8.1735&amp;volume=9&amp;pages=1735-1780&amp;publication_year=1997&amp;author=Hochreiter%2CS&amp;author=Schmidhuber%2CJ">
                    Google Scholar</a>
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" data-counter="110."><p class="c-article-references__text" id="ref-CR110">Cho, K. et al. Learning phrase representations using RNN encoder-decoder for statistical machine translation. In <i>Proceedings of the 2014 Conference on Empirical Methods in Natural Language Processing</i> (EMNLP) (eds Moschitti, A., Pang, B. &amp; Daelemans, W.) 17241734 (Association for Computational Linguistics, 2014).</p></li><li class="c-article-references__item js-c-reading-companion-references-item" data-counter="111."><p class="c-article-references__text" id="ref-CR111">Lipton, Z. C., Kale, D. C., Elkan, C. &amp; Wetzel, R. Learning to diagnose with LSTM recurrent neural networks. Preprint at <a href="https://arxiv.org/abs/1511.03677v7" data-track="click_references" data-track-action="external reference" data-track-value="external reference" data-track-label="https://arxiv.org/abs/1511.03677v7">https://arxiv.org/abs/1511.03677v7</a> (2015).</p></li><li class="c-article-references__item js-c-reading-companion-references-item" data-counter="112."><p class="c-article-references__text" id="ref-CR112">Choi, E., Bahadori, M. T., Schuetz, A., Stewart, W. F. &amp; Sun, J. Doctor AI: predicting clinical events via recurrent neural networks. <i>JMLR Workshop Conf. Proc.</i> <b>56</b>, 301318 (2016).</p><p class="c-article-references__links u-hide-print"><a data-track="click_references" rel="nofollow noopener" data-track-label="link" data-track-item_id="link" data-track-value="pubmed reference" data-track-action="pubmed reference" href="http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?cmd=Retrieve&amp;db=PubMed&amp;dopt=Abstract&amp;list_uids=28286600" aria-label="PubMed reference 112">PubMed</a>
    <a data-track="click_references" rel="nofollow noopener" data-track-label="link" data-track-item_id="link" data-track-value="pubmed central reference" data-track-action="pubmed central reference" href="http://www.ncbi.nlm.nih.gov/pmc/articles/PMC5341604" aria-label="PubMed Central reference 112">PubMed Central</a>
    <a data-track="click_references" data-track-action="google scholar reference" data-track-value="google scholar reference" data-track-label="link" data-track-item_id="link" rel="nofollow noopener" aria-label="Google Scholar reference 112" href="http://scholar.google.com/scholar_lookup?&amp;title=Doctor%20AI%3A%20predicting%20clinical%20events%20via%20recurrent%20neural%20networks&amp;journal=JMLR%20Workshop%20Conf.%20Proc.&amp;volume=56&amp;pages=301-318&amp;publication_year=2016&amp;author=Choi%2CE&amp;author=Bahadori%2CMT&amp;author=Schuetz%2CA&amp;author=Stewart%2CWF&amp;author=Sun%2CJ">
                    Google Scholar</a>
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" data-counter="113."><p class="c-article-references__text" id="ref-CR113">Zhu, Paschalidis &amp; Tahmasebi. Clinical concept extraction with contextual word embedding. Preprint at <a href="https://doi.org/10.48550/arXiv.1810.10566" data-track="click_references" data-track-action="external reference" data-track-value="external reference" data-track-label="10.48550/arXiv.1810.10566">https://doi.org/10.48550/arXiv.1810.10566</a> (2018).</p></li><li class="c-article-references__item js-c-reading-companion-references-item" data-counter="114."><p class="c-article-references__text" id="ref-CR114">Cho, K., van Merrinboer, B., Bahdanau, D. &amp; Bengio, Y. On the properties of neural machine translation: encoderdecoder approaches. In <i>Proceedings of SSST-8, Eighth Workshop on Syntax, Semantics and Structure in Statistical Translation</i> (eds Wu, D., Carpuat, M., Carreras, X. &amp; Vecchi, E. M.) 103111 (Association for Computational Linguistics, 2014).</p></li><li class="c-article-references__item js-c-reading-companion-references-item" data-counter="115."><p class="c-article-references__text" id="ref-CR115">Gehring, J., Auli, M., Grangier, D., Yarats, D. &amp; Dauphin, Y. N. Convolutional sequence to sequence learning. In <i>Proceedings of the 34th International Conference on Machine Learning</i> (eds Precup, D. &amp; Teh, Y. W.) 12431252 (PMLR, 2017).</p></li><li class="c-article-references__item js-c-reading-companion-references-item" data-counter="116."><p class="c-article-references__text" id="ref-CR116">Vaswani, A. et al. Attention is all you need. In <i>Advances in Neural Information Processing Systems</i> 30 (eds Guyon, I. et al.) Paper 3058 (Curran, 2017).</p></li><li class="c-article-references__item js-c-reading-companion-references-item" data-counter="117."><p class="c-article-references__text" id="ref-CR117">Bahdanau, D., Cho, K. H. &amp; Bengio, Y. Neural machine translation by jointly learning to align and translate. In <i>3rd International Conference on Learning Representations</i> ICLR 2015 (ICLR, 2015).</p></li><li class="c-article-references__item js-c-reading-companion-references-item" data-counter="118."><p class="c-article-references__text" id="ref-CR118">Luong, T., Pham, H. &amp; Manning, C. D. Effective approaches to attention-based neural machine translation. In <i>Proceedings of the 2015 Conference on Empirical Methods in Natural Language Processing</i> (eds Mrquez, L., Callison-Burch, C. &amp; Su, J.) 14121421 (Association for Computational Linguistics, 2015); <a href="https://doi.org/10.18653/v1/d15-1166" data-track="click_references" data-track-action="external reference" data-track-value="external reference" data-track-label="10.18653/v1/d15-1166">https://doi.org/10.18653/v1/d15-1166</a></p></li><li class="c-article-references__item js-c-reading-companion-references-item" data-counter="119."><p class="c-article-references__text" id="ref-CR119">Sutskever, I., Vinyals, O. &amp; Le, Q. V. Sequence to sequence learning with neural networks. In <i>Advances in Neural Information Processing Systems</i> 27 (eds Ghahramani, Z., Welling, M., Cortes, C., Lawrence, N. &amp; Weinberger, K. Q.) Paper 1610 (Curran, 2014).</p></li><li class="c-article-references__item js-c-reading-companion-references-item" data-counter="120."><p class="c-article-references__text" id="ref-CR120">Krizhevsky, A., Sutskever, I. &amp; Hinton, G. E. in <i>Advances in Neural Information Processing Systems</i> 25 (eds Bartlett, P. et al.) 10971105 (Curran, 2012).</p></li><li class="c-article-references__item js-c-reading-companion-references-item" data-counter="121."><p class="c-article-references__text" id="ref-CR121">Kiani, A. et al. Impact of a deep learning assistant on the histopathologic classification of liver cancer. <i>npj Digit. Med.</i> <b>3</b>, 23 (2020).</p><p class="c-article-references__links u-hide-print"><a data-track="click_references" rel="nofollow noopener" data-track-label="10.1038/s41746-020-0232-8" data-track-item_id="10.1038/s41746-020-0232-8" data-track-value="article reference" data-track-action="article reference" href="https://doi.org/10.1038%2Fs41746-020-0232-8" aria-label="Article reference 121" data-doi="10.1038/s41746-020-0232-8">Article</a>
    <a data-track="click_references" rel="nofollow noopener" data-track-label="link" data-track-item_id="link" data-track-value="pubmed reference" data-track-action="pubmed reference" href="http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?cmd=Retrieve&amp;db=PubMed&amp;dopt=Abstract&amp;list_uids=32140566" aria-label="PubMed reference 121">PubMed</a>
    <a data-track="click_references" rel="nofollow noopener" data-track-label="link" data-track-item_id="link" data-track-value="pubmed central reference" data-track-action="pubmed central reference" href="http://www.ncbi.nlm.nih.gov/pmc/articles/PMC7044422" aria-label="PubMed Central reference 121">PubMed Central</a>
    <a data-track="click_references" data-track-action="google scholar reference" data-track-value="google scholar reference" data-track-label="link" data-track-item_id="link" rel="nofollow noopener" aria-label="Google Scholar reference 121" href="http://scholar.google.com/scholar_lookup?&amp;title=Impact%20of%20a%20deep%20learning%20assistant%20on%20the%20histopathologic%20classification%20of%20liver%20cancer&amp;journal=npj%20Digit.%20Med.&amp;doi=10.1038%2Fs41746-020-0232-8&amp;volume=3&amp;publication_year=2020&amp;author=Kiani%2CA">
                    Google Scholar</a>
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" data-counter="122."><p class="c-article-references__text" id="ref-CR122">Park, S.-M. et al. A mountable toilet system for personalized health monitoring via the analysis of excreta. <i>Nat. Biomed. Eng.</i> <b>4</b>, 624635 (2020).</p><p class="c-article-references__links u-hide-print"><a data-track="click_references" rel="nofollow noopener" data-track-label="10.1038/s41551-020-0534-9" data-track-item_id="10.1038/s41551-020-0534-9" data-track-value="article reference" data-track-action="article reference" href="https://doi.org/10.1038%2Fs41551-020-0534-9" aria-label="Article reference 122" data-doi="10.1038/s41551-020-0534-9">Article</a>
    <a data-track="click_references" rel="nofollow noopener" data-track-label="link" data-track-item_id="link" data-track-value="pubmed reference" data-track-action="pubmed reference" href="http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?cmd=Retrieve&amp;db=PubMed&amp;dopt=Abstract&amp;list_uids=32251391" aria-label="PubMed reference 122">PubMed</a>
    <a data-track="click_references" rel="nofollow noopener" data-track-label="link" data-track-item_id="link" data-track-value="pubmed central reference" data-track-action="pubmed central reference" href="http://www.ncbi.nlm.nih.gov/pmc/articles/PMC7377213" aria-label="PubMed Central reference 122">PubMed Central</a>
    <a data-track="click_references" data-track-action="google scholar reference" data-track-value="google scholar reference" data-track-label="link" data-track-item_id="link" rel="nofollow noopener" aria-label="Google Scholar reference 122" href="http://scholar.google.com/scholar_lookup?&amp;title=A%20mountable%20toilet%20system%20for%20personalized%20health%20monitoring%20via%20the%20analysis%20of%20excreta&amp;journal=Nat.%20Biomed.%20Eng.&amp;doi=10.1038%2Fs41551-020-0534-9&amp;volume=4&amp;pages=624-635&amp;publication_year=2020&amp;author=Park%2CS-M">
                    Google Scholar</a>
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" data-counter="123."><p class="c-article-references__text" id="ref-CR123">Howard, J. &amp; Ruder, S. Universal language model fine-tuning for text classification. In <i>Proceedings of the 56th Annual Meeting of the Association for Computational Linguistics</i> (eds Gurevych, I. &amp; Miyao, Y.) 328339 (Association for Computational Linguistics, 2018).</p></li><li class="c-article-references__item js-c-reading-companion-references-item" data-counter="124."><p class="c-article-references__text" id="ref-CR124">Peters, M. E. et al. Deep contextualized word representations. In <i>Proceedings of the 2018 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies</i> (eds Walker, M., Ji, H. &amp; Stent, A.) 22272237 (Association for Computational Linguistics, 2018).</p></li><li class="c-article-references__item js-c-reading-companion-references-item" data-counter="125."><p class="c-article-references__text" id="ref-CR125">Brown, T. et al. Language models are few-shot learners. In <i>Advances in Neural Information Processing Systems</i> 33 (eds. Larochelle, H., Ranzato, M., Hadsell, R., Balcan, M. F. &amp; Lin, H.) 18771901 (Curran, 2020).</p></li><li class="c-article-references__item js-c-reading-companion-references-item" data-counter="126."><p class="c-article-references__text" id="ref-CR126">Kenton, J. D. M.-W. C. &amp; Toutanova, L. K. BERT: pre-training of deep bidirectional transformers for language understanding. in <i>Proceedings of the 2019 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies</i> (eds Burstein, J., Doran, C. &amp; Solorio, T.) 41714186 (Association for Computational Linguistics, 2019).</p></li><li class="c-article-references__item js-c-reading-companion-references-item" data-counter="127."><p class="c-article-references__text" id="ref-CR127">Mikolov, T., Chen, K., Corrado, G. &amp; Dean, J. Efficient estimation of word representations in vector space. Preprint at <a href="https://arxiv.org/abs/1301.3781v3" data-track="click_references" data-track-action="external reference" data-track-value="external reference" data-track-label="https://arxiv.org/abs/1301.3781v3">https://arxiv.org/abs/1301.3781v3</a> (2013).</p></li><li class="c-article-references__item js-c-reading-companion-references-item" data-counter="128."><p class="c-article-references__text" id="ref-CR128">Pennington, J., Socher, R. &amp; Manning, C. GloVe: global vectors for word representation. In <i>Proceedings of the 2014 Conference on Empirical Methods in Natural Language Processing</i> (eds Moschitti, A., Pang, B., Daelemans, W.) 15321543 (Association for Computational Linguistics, 2014).</p></li><li class="c-article-references__item js-c-reading-companion-references-item" data-counter="129."><p class="c-article-references__text" id="ref-CR129">Alsentzer, E. et al. Publicly available clinical BERT embeddings. In <i>Proceedings of the 2nd Clinical Natural Language Processing Workshop</i> (eds Rumshisky, A., Roberts, K., Bethard, S. &amp; Naumann, T.) 7278 (Association for Computational Linguistics, 2019).</p></li><li class="c-article-references__item js-c-reading-companion-references-item" data-counter="130."><p class="c-article-references__text" id="ref-CR130">Huang, K., Altosaar, J. &amp; Ranganath, R. ClinicalBERT: modeling clinical notes and predicting hospital readmission. Preprint at <a href="https://arxiv.org/abs/1904.05342v3" data-track="click_references" data-track-action="external reference" data-track-value="external reference" data-track-label="https://arxiv.org/abs/1904.05342v3">https://arxiv.org/abs/1904.05342v3</a> (2019).</p></li><li class="c-article-references__item js-c-reading-companion-references-item" data-counter="131."><p class="c-article-references__text" id="ref-CR131">Peng, Y., Yan, S. &amp; Lu, Z. Transfer learning in biomedical natural language processing: an evaluation of BERT and ELMo on ten benchmarking datasets. In <i>Proceedings of the 18th BioNLP Workshop and Shared Task</i> (eds Demner-Fushman, D., Bretonnel Cohen, K., Ananiadou, S. &amp; Tsujii, J.) 5865 (Association for Computational Linguistics, 2019).</p></li><li class="c-article-references__item js-c-reading-companion-references-item" data-counter="132."><p class="c-article-references__text" id="ref-CR132">Johnson, A. E. W. et al. MIMIC-III, a freely accessible critical care database. <i>Sci. Data</i> <b>3</b>, 160035 (2016).</p><p class="c-article-references__links u-hide-print"><a data-track="click_references" rel="nofollow noopener" data-track-label="10.1038/sdata.2016.35" data-track-item_id="10.1038/sdata.2016.35" data-track-value="article reference" data-track-action="article reference" href="https://doi.org/10.1038%2Fsdata.2016.35" aria-label="Article reference 132" data-doi="10.1038/sdata.2016.35">Article</a>
    <a data-track="click_references" rel="nofollow noopener" data-track-label="link" data-track-item_id="link" data-track-value="cas reference" data-track-action="cas reference" href="/articles/cas-redirect/1:CAS:528:DC%2BC28Xos1Wnu74%3D" aria-label="CAS reference 132">CAS</a>
    <a data-track="click_references" rel="nofollow noopener" data-track-label="link" data-track-item_id="link" data-track-value="pubmed reference" data-track-action="pubmed reference" href="http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?cmd=Retrieve&amp;db=PubMed&amp;dopt=Abstract&amp;list_uids=27219127" aria-label="PubMed reference 132">PubMed</a>
    <a data-track="click_references" rel="nofollow noopener" data-track-label="link" data-track-item_id="link" data-track-value="pubmed central reference" data-track-action="pubmed central reference" href="http://www.ncbi.nlm.nih.gov/pmc/articles/PMC4878278" aria-label="PubMed Central reference 132">PubMed Central</a>
    <a data-track="click_references" data-track-action="google scholar reference" data-track-value="google scholar reference" data-track-label="link" data-track-item_id="link" rel="nofollow noopener" aria-label="Google Scholar reference 132" href="http://scholar.google.com/scholar_lookup?&amp;title=MIMIC-III%2C%20a%20freely%20accessible%20critical%20care%20database&amp;journal=Sci.%20Data&amp;doi=10.1038%2Fsdata.2016.35&amp;volume=3&amp;publication_year=2016&amp;author=Johnson%2CAEW">
                    Google Scholar</a>
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" data-counter="133."><p class="c-article-references__text" id="ref-CR133">Sharir, O., Peleg, B. &amp; Shoham, Y. The cost of training NLP models: a concise overview. Preprint at <a href="https://arxiv.org/abs/2004.08900v1" data-track="click_references" data-track-action="external reference" data-track-value="external reference" data-track-label="https://arxiv.org/abs/2004.08900v1">https://arxiv.org/abs/2004.08900v1</a> (2020).</p></li><li class="c-article-references__item js-c-reading-companion-references-item" data-counter="134."><p class="c-article-references__text" id="ref-CR134">Lee, J. et al. BioBERT: a pre-trained biomedical language representation model for biomedical text mining. <i>Bioinformatics</i> <b>36</b>, 12341240 (2020).</p><p class="c-article-references__links u-hide-print"><a data-track="click_references" rel="nofollow noopener" data-track-label="10.1093/bioinformatics/btz682" data-track-item_id="10.1093/bioinformatics/btz682" data-track-value="article reference" data-track-action="article reference" href="https://doi.org/10.1093%2Fbioinformatics%2Fbtz682" aria-label="Article reference 134" data-doi="10.1093/bioinformatics/btz682">Article</a>
    <a data-track="click_references" rel="nofollow noopener" data-track-label="link" data-track-item_id="link" data-track-value="cas reference" data-track-action="cas reference" href="/articles/cas-redirect/1:CAS:528:DC%2BB3cXhslCisLrL" aria-label="CAS reference 134">CAS</a>
    <a data-track="click_references" rel="nofollow noopener" data-track-label="link" data-track-item_id="link" data-track-value="pubmed reference" data-track-action="pubmed reference" href="http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?cmd=Retrieve&amp;db=PubMed&amp;dopt=Abstract&amp;list_uids=31501885" aria-label="PubMed reference 134">PubMed</a>
    <a data-track="click_references" data-track-action="google scholar reference" data-track-value="google scholar reference" data-track-label="link" data-track-item_id="link" rel="nofollow noopener" aria-label="Google Scholar reference 134" href="http://scholar.google.com/scholar_lookup?&amp;title=BioBERT%3A%20a%20pre-trained%20biomedical%20language%20representation%20model%20for%20biomedical%20text%20mining&amp;journal=Bioinformatics&amp;doi=10.1093%2Fbioinformatics%2Fbtz682&amp;volume=36&amp;pages=1234-1240&amp;publication_year=2020&amp;author=Lee%2CJ">
                    Google Scholar</a>
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" data-counter="135."><p class="c-article-references__text" id="ref-CR135">Beltagy, I., Lo, K. &amp; Cohan, A. SciBERT: A pretrained language model for scientific text. In <i>Proceedings of the 2019 Conference on Empirical Methods in Natural Language Processing and the 9th International Joint Conference on Natural Language Processing</i> (eds Inui, K., Jiang, J., Ng, V. &amp; Wan, X.) 36153620 (Association for Computational Linguistics, 2019).</p></li><li class="c-article-references__item js-c-reading-companion-references-item" data-counter="136."><p class="c-article-references__text" id="ref-CR136">Futoma, J., Morris, J. &amp; Lucas, J. A comparison of models for predicting early hospital readmissions. <i>J. Biomed. Inform.</i> <b>56</b>, 229238 (2015).</p><p class="c-article-references__links u-hide-print"><a data-track="click_references" rel="nofollow noopener" data-track-label="10.1016/j.jbi.2015.05.016" data-track-item_id="10.1016/j.jbi.2015.05.016" data-track-value="article reference" data-track-action="article reference" href="https://doi.org/10.1016%2Fj.jbi.2015.05.016" aria-label="Article reference 136" data-doi="10.1016/j.jbi.2015.05.016">Article</a>
    <a data-track="click_references" rel="nofollow noopener" data-track-label="link" data-track-item_id="link" data-track-value="pubmed reference" data-track-action="pubmed reference" href="http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?cmd=Retrieve&amp;db=PubMed&amp;dopt=Abstract&amp;list_uids=26044081" aria-label="PubMed reference 136">PubMed</a>
    <a data-track="click_references" data-track-action="google scholar reference" data-track-value="google scholar reference" data-track-label="link" data-track-item_id="link" rel="nofollow noopener" aria-label="Google Scholar reference 136" href="http://scholar.google.com/scholar_lookup?&amp;title=A%20comparison%20of%20models%20for%20predicting%20early%20hospital%20readmissions&amp;journal=J.%20Biomed.%20Inform.&amp;doi=10.1016%2Fj.jbi.2015.05.016&amp;volume=56&amp;pages=229-238&amp;publication_year=2015&amp;author=Futoma%2CJ&amp;author=Morris%2CJ&amp;author=Lucas%2CJ">
                    Google Scholar</a>
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" data-counter="137."><p class="c-article-references__text" id="ref-CR137">Caruana, R. et al. Intelligible models for healthcare: predicting pneumonia risk and hospital 30-day readmission. In <i>Proc. 21st ACM SIGKDD International Conference on Knowledge Discovery and Data Mining</i> 17211730 (Association for Computing Machinery, 2015).</p></li><li class="c-article-references__item js-c-reading-companion-references-item" data-counter="138."><p class="c-article-references__text" id="ref-CR138">Wagner, T. et al. Augmented curation of clinical notes from a massive EHR system reveals symptoms of impending COVID-19 diagnosis. <i>Elife</i> <b>9</b>, e58227 (2020).</p><p class="c-article-references__links u-hide-print"><a data-track="click_references" rel="nofollow noopener" data-track-label="10.7554/eLife.58227" data-track-item_id="10.7554/eLife.58227" data-track-value="article reference" data-track-action="article reference" href="https://doi.org/10.7554%2FeLife.58227" aria-label="Article reference 138" data-doi="10.7554/eLife.58227">Article</a>
    <a data-track="click_references" rel="nofollow noopener" data-track-label="link" data-track-item_id="link" data-track-value="cas reference" data-track-action="cas reference" href="/articles/cas-redirect/1:CAS:528:DC%2BB3cXitlKqsrnN" aria-label="CAS reference 138">CAS</a>
    <a data-track="click_references" rel="nofollow noopener" data-track-label="link" data-track-item_id="link" data-track-value="pubmed reference" data-track-action="pubmed reference" href="http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?cmd=Retrieve&amp;db=PubMed&amp;dopt=Abstract&amp;list_uids=32633720" aria-label="PubMed reference 138">PubMed</a>
    <a data-track="click_references" rel="nofollow noopener" data-track-label="link" data-track-item_id="link" data-track-value="pubmed central reference" data-track-action="pubmed central reference" href="http://www.ncbi.nlm.nih.gov/pmc/articles/PMC7410498" aria-label="PubMed Central reference 138">PubMed Central</a>
    <a data-track="click_references" data-track-action="google scholar reference" data-track-value="google scholar reference" data-track-label="link" data-track-item_id="link" rel="nofollow noopener" aria-label="Google Scholar reference 138" href="http://scholar.google.com/scholar_lookup?&amp;title=Augmented%20curation%20of%20clinical%20notes%20from%20a%20massive%20EHR%20system%20reveals%20symptoms%20of%20impending%20COVID-19%20diagnosis&amp;journal=Elife&amp;doi=10.7554%2FeLife.58227&amp;volume=9&amp;publication_year=2020&amp;author=Wagner%2CT">
                    Google Scholar</a>
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" data-counter="139."><p class="c-article-references__text" id="ref-CR139">Eisman, A. S. et al. Extracting angina symptoms from clinical notes using pre-trained transformer architectures. <i>AMIA Annu. Symp. Proc.</i> <b>2020</b>, 412421 (American Medical Informatics Association, 2020).</p></li><li class="c-article-references__item js-c-reading-companion-references-item" data-counter="140."><p class="c-article-references__text" id="ref-CR140">Smit, A. et al. Combining automatic labelers and expert annotations for accurate radiology report labeling using BERT. In <i>Proceedings of the 2020 Conference on Empirical Methods in Natural Language Processing</i> (eds Webber, B., Cohn, T., He, Y. &amp; Liu, Y.) 15001519 (Association for Computational Linguistics, 2020).</p></li><li class="c-article-references__item js-c-reading-companion-references-item" data-counter="141."><p class="c-article-references__text" id="ref-CR141">Soni, S. &amp; Roberts, K. Evaluation of dataset selection for pre-training and fine-tuning transformer language models for clinical question answering. In <i>Proc. 12th Language Resources and Evaluation Conference</i> 55325538 (European Language Resources Association, 2020).</p></li><li class="c-article-references__item js-c-reading-companion-references-item" data-counter="142."><p class="c-article-references__text" id="ref-CR142">Sezgin, E., Huang, Y., Ramtekkar, U. &amp; Lin, S. Readiness for voice assistants to support healthcare delivery during a health crisis and pandemic. <i>npj Digit. Med.</i> <b>3</b>, 122 (2020).</p><p class="c-article-references__links u-hide-print"><a data-track="click_references" rel="nofollow noopener" data-track-label="10.1038/s41746-020-00332-0" data-track-item_id="10.1038/s41746-020-00332-0" data-track-value="article reference" data-track-action="article reference" href="https://doi.org/10.1038%2Fs41746-020-00332-0" aria-label="Article reference 142" data-doi="10.1038/s41746-020-00332-0">Article</a>
    <a data-track="click_references" rel="nofollow noopener" data-track-label="link" data-track-item_id="link" data-track-value="pubmed reference" data-track-action="pubmed reference" href="http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?cmd=Retrieve&amp;db=PubMed&amp;dopt=Abstract&amp;list_uids=33015374" aria-label="PubMed reference 142">PubMed</a>
    <a data-track="click_references" rel="nofollow noopener" data-track-label="link" data-track-item_id="link" data-track-value="pubmed central reference" data-track-action="pubmed central reference" href="http://www.ncbi.nlm.nih.gov/pmc/articles/PMC7494948" aria-label="PubMed Central reference 142">PubMed Central</a>
    <a data-track="click_references" data-track-action="google scholar reference" data-track-value="google scholar reference" data-track-label="link" data-track-item_id="link" rel="nofollow noopener" aria-label="Google Scholar reference 142" href="http://scholar.google.com/scholar_lookup?&amp;title=Readiness%20for%20voice%20assistants%20to%20support%20healthcare%20delivery%20during%20a%20health%20crisis%20and%20pandemic&amp;journal=npj%20Digit.%20Med.&amp;doi=10.1038%2Fs41746-020-00332-0&amp;volume=3&amp;publication_year=2020&amp;author=Sezgin%2CE&amp;author=Huang%2CY&amp;author=Ramtekkar%2CU&amp;author=Lin%2CS">
                    Google Scholar</a>
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" data-counter="143."><p class="c-article-references__text" id="ref-CR143">Sakthive, V., Kesaven, M. P. V., William, J. M. &amp; Kumar, S. K. M. Integrated platform and response system for healthcare using Alexa. <i>Int. J. Commun. Computer Technol.</i> <b>7</b>, 1422 (2019).</p><p class="c-article-references__links u-hide-print"><a data-track="click_references" data-track-action="google scholar reference" data-track-value="google scholar reference" data-track-label="link" data-track-item_id="link" rel="nofollow noopener" aria-label="Google Scholar reference 143" href="http://scholar.google.com/scholar_lookup?&amp;title=Integrated%20platform%20and%20response%20system%20for%20healthcare%20using%20Alexa&amp;journal=Int.%20J.%20Commun.%20Computer%20Technol.&amp;volume=7&amp;pages=14-22&amp;publication_year=2019&amp;author=Sakthive%2CV&amp;author=Kesaven%2CMPV&amp;author=William%2CJM&amp;author=Kumar%2CSKM">
                    Google Scholar</a>
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" data-counter="144."><p class="c-article-references__text" id="ref-CR144">Comstock, J. Buoy Health, CVS MinuteClinic partner to send patients from chatbot to care. <i>mobihealthnews</i> <a href="https://www.mobihealthnews.com/content/buoy-health-cvs-minuteclinic-partner-send-patients-chatbot-care" data-track="click_references" data-track-action="external reference" data-track-value="external reference" data-track-label="https://www.mobihealthnews.com/content/buoy-health-cvs-minuteclinic-partner-send-patients-chatbot-care">https://www.mobihealthnews.com/content/buoy-health-cvs-minuteclinic-partner-send-patients-chatbot-care</a> (2018).</p></li><li class="c-article-references__item js-c-reading-companion-references-item" data-counter="145."><p class="c-article-references__text" id="ref-CR145">Razzaki, S. et al. A comparative study of artificial intelligence and human doctors for the purpose of triage and diagnosis. Preprint at <a href="https://doi.org/10.48550/arXiv.1806.10698" data-track="click_references" data-track-action="external reference" data-track-value="external reference" data-track-label="10.48550/arXiv.1806.10698">https://doi.org/10.48550/arXiv.1806.10698</a> (2018).</p></li><li class="c-article-references__item js-c-reading-companion-references-item" data-counter="146."><p class="c-article-references__text" id="ref-CR146">Xiong, Y., Du, B. &amp; Yan, P. Reinforced transformer for medical image captioning. In <i>Machine Learning in Medical Imaging</i> (eds. Suk, H.-I., Liu, M., Yan, P. &amp; Lian, C.) 673680 (Springer International Publishing, 2019).</p></li><li class="c-article-references__item js-c-reading-companion-references-item" data-counter="147."><p class="c-article-references__text" id="ref-CR147">Meng, Y., Speier, W., Ong, M. K. &amp; Arnold, C. W. Bidirectional representation learning from transformers using multimodal electronic health record data to predict depression. <i>IEEE J. Biomed. Health Inform.</i> <b>25</b>, 31213129 (2021).</p><p class="c-article-references__links u-hide-print"><a data-track="click_references" rel="nofollow noopener" data-track-label="10.1109/JBHI.2021.3063721" data-track-item_id="10.1109/JBHI.2021.3063721" data-track-value="article reference" data-track-action="article reference" href="https://doi.org/10.1109%2FJBHI.2021.3063721" aria-label="Article reference 147" data-doi="10.1109/JBHI.2021.3063721">Article</a>
    <a data-track="click_references" rel="nofollow noopener" data-track-label="link" data-track-item_id="link" data-track-value="pubmed reference" data-track-action="pubmed reference" href="http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?cmd=Retrieve&amp;db=PubMed&amp;dopt=Abstract&amp;list_uids=33661740" aria-label="PubMed reference 147">PubMed</a>
    <a data-track="click_references" rel="nofollow noopener" data-track-label="link" data-track-item_id="link" data-track-value="pubmed central reference" data-track-action="pubmed central reference" href="http://www.ncbi.nlm.nih.gov/pmc/articles/PMC8606118" aria-label="PubMed Central reference 147">PubMed Central</a>
    <a data-track="click_references" data-track-action="google scholar reference" data-track-value="google scholar reference" data-track-label="link" data-track-item_id="link" rel="nofollow noopener" aria-label="Google Scholar reference 147" href="http://scholar.google.com/scholar_lookup?&amp;title=Bidirectional%20representation%20learning%20from%20transformers%20using%20multimodal%20electronic%20health%20record%20data%20to%20predict%20depression&amp;journal=IEEE%20J.%20Biomed.%20Health%20Inform.&amp;doi=10.1109%2FJBHI.2021.3063721&amp;volume=25&amp;pages=3121-3129&amp;publication_year=2021&amp;author=Meng%2CY&amp;author=Speier%2CW&amp;author=Ong%2CMK&amp;author=Arnold%2CCW">
                    Google Scholar</a>
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" data-counter="148."><p class="c-article-references__text" id="ref-CR148">Choi, E. et al. Learning the graphical structure of electronic health records with graph convolutional transformer. <i>Proc. Conf. AAAI Artif. Intell.</i> <b>34</b>, 606613 (2020).</p><p class="c-article-references__links u-hide-print"><a data-track="click_references" data-track-action="google scholar reference" data-track-value="google scholar reference" data-track-label="link" data-track-item_id="link" rel="nofollow noopener" aria-label="Google Scholar reference 148" href="http://scholar.google.com/scholar_lookup?&amp;title=Learning%20the%20graphical%20structure%20of%20electronic%20health%20records%20with%20graph%20convolutional%20transformer&amp;journal=Proc.%20Conf.%20AAAI%20Artif.%20Intell.&amp;volume=34&amp;pages=606-613&amp;publication_year=2020&amp;author=Choi%2CE">
                    Google Scholar</a>
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" data-counter="149."><p class="c-article-references__text" id="ref-CR149">Li, F. et al. Fine-tuning bidirectional encoder representations from transformers (BERT)based models on large-scale electronic health record notes: an empirical study. <i>JMIR Med. Inform.</i> <b>7</b>, e14830 (2019).</p><p class="c-article-references__links u-hide-print"><a data-track="click_references" rel="nofollow noopener" data-track-label="10.2196/14830" data-track-item_id="10.2196/14830" data-track-value="article reference" data-track-action="article reference" href="https://doi.org/10.2196%2F14830" aria-label="Article reference 149" data-doi="10.2196/14830">Article</a>
    <a data-track="click_references" rel="nofollow noopener" data-track-label="link" data-track-item_id="link" data-track-value="pubmed reference" data-track-action="pubmed reference" href="http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?cmd=Retrieve&amp;db=PubMed&amp;dopt=Abstract&amp;list_uids=31516126" aria-label="PubMed reference 149">PubMed</a>
    <a data-track="click_references" rel="nofollow noopener" data-track-label="link" data-track-item_id="link" data-track-value="pubmed central reference" data-track-action="pubmed central reference" href="http://www.ncbi.nlm.nih.gov/pmc/articles/PMC6746103" aria-label="PubMed Central reference 149">PubMed Central</a>
    <a data-track="click_references" data-track-action="google scholar reference" data-track-value="google scholar reference" data-track-label="link" data-track-item_id="link" rel="nofollow noopener" aria-label="Google Scholar reference 149" href="http://scholar.google.com/scholar_lookup?&amp;title=Fine-tuning%20bidirectional%20encoder%20representations%20from%20transformers%20%28BERT%29%E2%80%93based%20models%20on%20large-scale%20electronic%20health%20record%20notes%3A%20an%20empirical%20study&amp;journal=JMIR%20Med.%20Inform.&amp;doi=10.2196%2F14830&amp;volume=7&amp;publication_year=2019&amp;author=Li%2CF">
                    Google Scholar</a>
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" data-counter="150."><p class="c-article-references__text" id="ref-CR150">Rasmy, L., Xiang, Y., Xie, Z., Tao, C. &amp; Zhi, D. Med-BERT: pretrained contextualized embeddings on large-scale structured electronic health records for disease prediction. <i>npj Digital Medicine</i> <b>4</b>, 86 (2021).</p><p class="c-article-references__links u-hide-print"><a data-track="click_references" rel="nofollow noopener" data-track-label="10.1038/s41746-021-00455-y" data-track-item_id="10.1038/s41746-021-00455-y" data-track-value="article reference" data-track-action="article reference" href="https://doi.org/10.1038%2Fs41746-021-00455-y" aria-label="Article reference 150" data-doi="10.1038/s41746-021-00455-y">Article</a>
    <a data-track="click_references" rel="nofollow noopener" data-track-label="link" data-track-item_id="link" data-track-value="pubmed reference" data-track-action="pubmed reference" href="http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?cmd=Retrieve&amp;db=PubMed&amp;dopt=Abstract&amp;list_uids=34017034" aria-label="PubMed reference 150">PubMed</a>
    <a data-track="click_references" rel="nofollow noopener" data-track-label="link" data-track-item_id="link" data-track-value="pubmed central reference" data-track-action="pubmed central reference" href="http://www.ncbi.nlm.nih.gov/pmc/articles/PMC8137882" aria-label="PubMed Central reference 150">PubMed Central</a>
    <a data-track="click_references" data-track-action="google scholar reference" data-track-value="google scholar reference" data-track-label="link" data-track-item_id="link" rel="nofollow noopener" aria-label="Google Scholar reference 150" href="http://scholar.google.com/scholar_lookup?&amp;title=Med-BERT%3A%20pretrained%20contextualized%20embeddings%20on%20large-scale%20structured%20electronic%20health%20records%20for%20disease%20prediction&amp;journal=npj%20Digital%20Medicine&amp;doi=10.1038%2Fs41746-021-00455-y&amp;volume=4&amp;publication_year=2021&amp;author=Rasmy%2CL&amp;author=Xiang%2CY&amp;author=Xie%2CZ&amp;author=Tao%2CC&amp;author=Zhi%2CD">
                    Google Scholar</a>
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" data-counter="151."><p class="c-article-references__text" id="ref-CR151">Shang, J., Ma, T., Xiao, C. &amp; Sun, J. Pre-training of graph augmented transformers for medication recommendation. in <i>Proceedings of the Twenty-Eighth International Joint Conference on Artificial Intelligence</i> (ed. Kraus, S.) 59535959 (International Joint Conferences on Artificial Intelligence Organization, 2019); <a href="https://doi.org/10.24963/ijcai.2019/825" data-track="click_references" data-track-action="external reference" data-track-value="external reference" data-track-label="10.24963/ijcai.2019/825">https://doi.org/10.24963/ijcai.2019/825</a></p></li><li class="c-article-references__item js-c-reading-companion-references-item" data-counter="152."><p class="c-article-references__text" id="ref-CR152">Li, Y. et al. BEHRT: transformer for electronic health records. <i>Sci. Rep.</i> <b>10</b>, 7155 (2020).</p><p class="c-article-references__links u-hide-print"><a data-track="click_references" rel="nofollow noopener" data-track-label="10.1038/s41598-020-62922-y" data-track-item_id="10.1038/s41598-020-62922-y" data-track-value="article reference" data-track-action="article reference" href="https://doi.org/10.1038%2Fs41598-020-62922-y" aria-label="Article reference 152" data-doi="10.1038/s41598-020-62922-y">Article</a>
    <a data-track="click_references" rel="nofollow noopener" data-track-label="link" data-track-item_id="link" data-track-value="cas reference" data-track-action="cas reference" href="/articles/cas-redirect/1:CAS:528:DC%2BB3cXosVOgu78%3D" aria-label="CAS reference 152">CAS</a>
    <a data-track="click_references" rel="nofollow noopener" data-track-label="link" data-track-item_id="link" data-track-value="pubmed reference" data-track-action="pubmed reference" href="http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?cmd=Retrieve&amp;db=PubMed&amp;dopt=Abstract&amp;list_uids=32346050" aria-label="PubMed reference 152">PubMed</a>
    <a data-track="click_references" rel="nofollow noopener" data-track-label="link" data-track-item_id="link" data-track-value="pubmed central reference" data-track-action="pubmed central reference" href="http://www.ncbi.nlm.nih.gov/pmc/articles/PMC7189231" aria-label="PubMed Central reference 152">PubMed Central</a>
    <a data-track="click_references" data-track-action="google scholar reference" data-track-value="google scholar reference" data-track-label="link" data-track-item_id="link" rel="nofollow noopener" aria-label="Google Scholar reference 152" href="http://scholar.google.com/scholar_lookup?&amp;title=BEHRT%3A%20transformer%20for%20electronic%20health%20records&amp;journal=Sci.%20Rep.&amp;doi=10.1038%2Fs41598-020-62922-y&amp;volume=10&amp;publication_year=2020&amp;author=Li%2CY">
                    Google Scholar</a>
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" data-counter="153."><p class="c-article-references__text" id="ref-CR153">Rao, S. et al. BEHRT-HF: an interpretable transformer-based, deep learning model for prediction of incident heart failure. <i>Eur. Heart J.</i> <b>41</b> (Suppl. 2), ehaa946.3553 (2020).</p><p class="c-article-references__links u-hide-print"><a data-track="click_references" rel="nofollow noopener" data-track-label="10.1093/ehjci/ehaa946.3553" data-track-item_id="10.1093/ehjci/ehaa946.3553" data-track-value="article reference" data-track-action="article reference" href="https://doi.org/10.1093%2Fehjci%2Fehaa946.3553" aria-label="Article reference 153" data-doi="10.1093/ehjci/ehaa946.3553">Article</a>
    <a data-track="click_references" data-track-action="google scholar reference" data-track-value="google scholar reference" data-track-label="link" data-track-item_id="link" rel="nofollow noopener" aria-label="Google Scholar reference 153" href="http://scholar.google.com/scholar_lookup?&amp;title=BEHRT-HF%3A%20an%20interpretable%20transformer-based%2C%20deep%20learning%20model%20for%20prediction%20of%20incident%20heart%20failure&amp;journal=Eur.%20Heart%20J.&amp;doi=10.1093%2Fehjci%2Fehaa946.3553&amp;volume=41&amp;issue=Suppl.%202&amp;publication_year=2020&amp;author=Rao%2CS">
                    Google Scholar</a>
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" data-counter="154."><p class="c-article-references__text" id="ref-CR154">Qian, X. et al. Prospective assessment of breast cancer risk from multimodal multiview ultrasound images via clinically applicable deep learning. <i>Nat. Biomed. Eng.</i> <b>5</b>, 522532 (2021).</p><p class="c-article-references__links u-hide-print"><a data-track="click_references" rel="nofollow noopener" data-track-label="10.1038/s41551-021-00711-2" data-track-item_id="10.1038/s41551-021-00711-2" data-track-value="article reference" data-track-action="article reference" href="https://doi.org/10.1038%2Fs41551-021-00711-2" aria-label="Article reference 154" data-doi="10.1038/s41551-021-00711-2">Article</a>
    <a data-track="click_references" rel="nofollow noopener" data-track-label="link" data-track-item_id="link" data-track-value="pubmed reference" data-track-action="pubmed reference" href="http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?cmd=Retrieve&amp;db=PubMed&amp;dopt=Abstract&amp;list_uids=33875840" aria-label="PubMed reference 154">PubMed</a>
    <a data-track="click_references" data-track-action="google scholar reference" data-track-value="google scholar reference" data-track-label="link" data-track-item_id="link" rel="nofollow noopener" aria-label="Google Scholar reference 154" href="http://scholar.google.com/scholar_lookup?&amp;title=Prospective%20assessment%20of%20breast%20cancer%20risk%20from%20multimodal%20multiview%20ultrasound%20images%20via%20clinically%20applicable%20deep%20learning&amp;journal=Nat.%20Biomed.%20Eng.&amp;doi=10.1038%2Fs41551-021-00711-2&amp;volume=5&amp;pages=522-532&amp;publication_year=2021&amp;author=Qian%2CX">
                    Google Scholar</a>
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" data-counter="155."><p class="c-article-references__text" id="ref-CR155">Xing, L., Giger, M. L. &amp; Min, J. K. <i>Artificial Intelligence in Medicine: Technical Basis and Clinical Applications</i> (Academic Press, 2020).</p></li><li class="c-article-references__item js-c-reading-companion-references-item" data-counter="156."><p class="c-article-references__text" id="ref-CR156">Reisman, M. EHRs: the challenge of making electronic data usable and interoperable. <i>P. T.</i> <b>42</b>, 572575 (2017).</p><p class="c-article-references__links u-hide-print"><a data-track="click_references" rel="nofollow noopener" data-track-label="link" data-track-item_id="link" data-track-value="pubmed reference" data-track-action="pubmed reference" href="http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?cmd=Retrieve&amp;db=PubMed&amp;dopt=Abstract&amp;list_uids=28890644" aria-label="PubMed reference 156">PubMed</a>
    <a data-track="click_references" rel="nofollow noopener" data-track-label="link" data-track-item_id="link" data-track-value="pubmed central reference" data-track-action="pubmed central reference" href="http://www.ncbi.nlm.nih.gov/pmc/articles/PMC5565131" aria-label="PubMed Central reference 156">PubMed Central</a>
    <a data-track="click_references" data-track-action="google scholar reference" data-track-value="google scholar reference" data-track-label="link" data-track-item_id="link" rel="nofollow noopener" aria-label="Google Scholar reference 156" href="http://scholar.google.com/scholar_lookup?&amp;title=EHRs%3A%20the%20challenge%20of%20making%20electronic%20data%20usable%20and%20interoperable&amp;journal=P.%20T.&amp;volume=42&amp;pages=572-575&amp;publication_year=2017&amp;author=Reisman%2CM">
                    Google Scholar</a>
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" data-counter="157."><p class="c-article-references__text" id="ref-CR157">Corts, R., Bonnaire, X., Marin, O. &amp; Sens, P. Stream processing of healthcare sensor data: studying user traces to identify challenges from a big data perspective. <i>Procedia Comput. Sci.</i> <b>52</b>, 10041009 (2015).</p><p class="c-article-references__links u-hide-print"><a data-track="click_references" rel="nofollow noopener" data-track-label="10.1016/j.procs.2015.05.093" data-track-item_id="10.1016/j.procs.2015.05.093" data-track-value="article reference" data-track-action="article reference" href="https://doi.org/10.1016%2Fj.procs.2015.05.093" aria-label="Article reference 157" data-doi="10.1016/j.procs.2015.05.093">Article</a>
    <a data-track="click_references" data-track-action="google scholar reference" data-track-value="google scholar reference" data-track-label="link" data-track-item_id="link" rel="nofollow noopener" aria-label="Google Scholar reference 157" href="http://scholar.google.com/scholar_lookup?&amp;title=Stream%20processing%20of%20healthcare%20sensor%20data%3A%20studying%20user%20traces%20to%20identify%20challenges%20from%20a%20big%20data%20perspective&amp;journal=Procedia%20Comput.%20Sci.&amp;doi=10.1016%2Fj.procs.2015.05.093&amp;volume=52&amp;pages=1004-1009&amp;publication_year=2015&amp;author=Cort%C3%A9s%2CR&amp;author=Bonnaire%2CX&amp;author=Marin%2CO&amp;author=Sens%2CP">
                    Google Scholar</a>
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" data-counter="158."><p class="c-article-references__text" id="ref-CR158">Zhang, F., Cao, J., Khan, S. U., Li, K. &amp; Hwang, K. A task-level adaptive MapReduce framework for real-time streaming data in healthcare applications. <i>Future Gener. Comput. Syst.</i> <b>4344</b>, 149160 (2015).</p><p class="c-article-references__links u-hide-print"><a data-track="click_references" rel="nofollow noopener" data-track-label="10.1016/j.future.2014.06.009" data-track-item_id="10.1016/j.future.2014.06.009" data-track-value="article reference" data-track-action="article reference" href="https://doi.org/10.1016%2Fj.future.2014.06.009" aria-label="Article reference 158" data-doi="10.1016/j.future.2014.06.009">Article</a>
    <a data-track="click_references" data-track-action="google scholar reference" data-track-value="google scholar reference" data-track-label="link" data-track-item_id="link" rel="nofollow noopener" aria-label="Google Scholar reference 158" href="http://scholar.google.com/scholar_lookup?&amp;title=A%20task-level%20adaptive%20MapReduce%20framework%20for%20real-time%20streaming%20data%20in%20healthcare%20applications&amp;journal=Future%20Gener.%20Comput.%20Syst.&amp;doi=10.1016%2Fj.future.2014.06.009&amp;volume=43%E2%80%9344&amp;pages=149-160&amp;publication_year=2015&amp;author=Zhang%2CF&amp;author=Cao%2CJ&amp;author=Khan%2CSU&amp;author=Li%2CK&amp;author=Hwang%2CK">
                    Google Scholar</a>
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" data-counter="159."><p class="c-article-references__text" id="ref-CR159">El Aboudi, N. &amp; Benhlima, L. Big data management for healthcare systems: architecture, requirements, and implementation. <i>Adv. Bioinformatics</i> <b>2018</b>, 4059018 (2018).</p><p class="c-article-references__links u-hide-print"><a data-track="click_references" rel="nofollow noopener" data-track-label="10.1155/2018/4059018" data-track-item_id="10.1155/2018/4059018" data-track-value="article reference" data-track-action="article reference" href="https://doi.org/10.1155%2F2018%2F4059018" aria-label="Article reference 159" data-doi="10.1155/2018/4059018">Article</a>
    <a data-track="click_references" rel="nofollow noopener" data-track-label="link" data-track-item_id="link" data-track-value="pubmed reference" data-track-action="pubmed reference" href="http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?cmd=Retrieve&amp;db=PubMed&amp;dopt=Abstract&amp;list_uids=30034468" aria-label="PubMed reference 159">PubMed</a>
    <a data-track="click_references" rel="nofollow noopener" data-track-label="link" data-track-item_id="link" data-track-value="pubmed central reference" data-track-action="pubmed central reference" href="http://www.ncbi.nlm.nih.gov/pmc/articles/PMC6032968" aria-label="PubMed Central reference 159">PubMed Central</a>
    <a data-track="click_references" data-track-action="google scholar reference" data-track-value="google scholar reference" data-track-label="link" data-track-item_id="link" rel="nofollow noopener" aria-label="Google Scholar reference 159" href="http://scholar.google.com/scholar_lookup?&amp;title=Big%20data%20management%20for%20healthcare%20systems%3A%20architecture%2C%20requirements%2C%20and%20implementation&amp;journal=Adv.%20Bioinformatics&amp;doi=10.1155%2F2018%2F4059018&amp;volume=2018&amp;publication_year=2018&amp;author=El%20Aboudi%2CN&amp;author=Benhlima%2CL">
                    Google Scholar</a>
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" data-counter="160."><p class="c-article-references__text" id="ref-CR160">Ta, V.-D., Liu, C.-M. &amp; Nkabinde, G. W. Big data stream computing in healthcare real-time analytics. In <i>IEEE International Conference on Cloud Computing and Big Data Analysis</i> (ICCCBDA) 3742 (ieeexplore.ieee.org, 2016).</p></li><li class="c-article-references__item js-c-reading-companion-references-item" data-counter="161."><p class="c-article-references__text" id="ref-CR161"><i>Data-Driven Healthcare Organizations Use Big Data Analytics for Big Gains</i> White Paper (IBM Software, 2017); <a href="https://silo.tips/download/ibm-software-white-paper-data-driven-healthcare-organizations-use-big-data-analy" data-track="click_references" data-track-action="external reference" data-track-value="external reference" data-track-label="https://silo.tips/download/ibm-software-white-paper-data-driven-healthcare-organizations-use-big-data-analy">https://silo.tips/download/ibm-software-white-paper-data-driven-healthcare-organizations-use-big-data-analy</a></p></li><li class="c-article-references__item js-c-reading-companion-references-item" data-counter="162."><p class="c-article-references__text" id="ref-CR162">Futoma, J., Simons, M., Panch, T., Doshi-Velez, F. &amp; Celi, L. A. The myth of generalisability in clinical research and machine learning in health care. <i>Lancet Digit. Health</i> <b>2</b>, e489e492 (2020).</p><p class="c-article-references__links u-hide-print"><a data-track="click_references" rel="nofollow noopener" data-track-label="10.1016/S2589-7500(20)30186-2" data-track-item_id="10.1016/S2589-7500(20)30186-2" data-track-value="article reference" data-track-action="article reference" href="https://doi.org/10.1016%2FS2589-7500%2820%2930186-2" aria-label="Article reference 162" data-doi="10.1016/S2589-7500(20)30186-2">Article</a>
    <a data-track="click_references" rel="nofollow noopener" data-track-label="link" data-track-item_id="link" data-track-value="pubmed reference" data-track-action="pubmed reference" href="http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?cmd=Retrieve&amp;db=PubMed&amp;dopt=Abstract&amp;list_uids=32864600" aria-label="PubMed reference 162">PubMed</a>
    <a data-track="click_references" rel="nofollow noopener" data-track-label="link" data-track-item_id="link" data-track-value="pubmed central reference" data-track-action="pubmed central reference" href="http://www.ncbi.nlm.nih.gov/pmc/articles/PMC7444947" aria-label="PubMed Central reference 162">PubMed Central</a>
    <a data-track="click_references" data-track-action="google scholar reference" data-track-value="google scholar reference" data-track-label="link" data-track-item_id="link" rel="nofollow noopener" aria-label="Google Scholar reference 162" href="http://scholar.google.com/scholar_lookup?&amp;title=The%20myth%20of%20generalisability%20in%20clinical%20research%20and%20machine%20learning%20in%20health%20care&amp;journal=Lancet%20Digit.%20Health&amp;doi=10.1016%2FS2589-7500%2820%2930186-2&amp;volume=2&amp;pages=e489-e492&amp;publication_year=2020&amp;author=Futoma%2CJ&amp;author=Simons%2CM&amp;author=Panch%2CT&amp;author=Doshi-Velez%2CF&amp;author=Celi%2CLA">
                    Google Scholar</a>
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" data-counter="163."><p class="c-article-references__text" id="ref-CR163">Wang, X. et al. Inconsistent performance of deep learning models on mammogram classification. <i>J. Am. Coll. Radiol.</i> <b>17</b>, 796803 (2020).</p><p class="c-article-references__links u-hide-print"><a data-track="click_references" rel="nofollow noopener" data-track-label="10.1016/j.jacr.2020.01.006" data-track-item_id="10.1016/j.jacr.2020.01.006" data-track-value="article reference" data-track-action="article reference" href="https://doi.org/10.1016%2Fj.jacr.2020.01.006" aria-label="Article reference 163" data-doi="10.1016/j.jacr.2020.01.006">Article</a>
    <a data-track="click_references" rel="nofollow noopener" data-track-label="link" data-track-item_id="link" data-track-value="pubmed reference" data-track-action="pubmed reference" href="http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?cmd=Retrieve&amp;db=PubMed&amp;dopt=Abstract&amp;list_uids=32068005" aria-label="PubMed reference 163">PubMed</a>
    <a data-track="click_references" data-track-action="google scholar reference" data-track-value="google scholar reference" data-track-label="link" data-track-item_id="link" rel="nofollow noopener" aria-label="Google Scholar reference 163" href="http://scholar.google.com/scholar_lookup?&amp;title=Inconsistent%20performance%20of%20deep%20learning%20models%20on%20mammogram%20classification&amp;journal=J.%20Am.%20Coll.%20Radiol.&amp;doi=10.1016%2Fj.jacr.2020.01.006&amp;volume=17&amp;pages=796-803&amp;publication_year=2020&amp;author=Wang%2CX">
                    Google Scholar</a>
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" data-counter="164."><p class="c-article-references__text" id="ref-CR164">Nestor, B., McDermott, M. B. A. &amp; Boag, W. Feature robustness in non-stationary health records: caveats to deployable model performance in common clinical machine learning tasks. Preprint at <a href="https://doi.org/10.48550/arXiv.1908.00690" data-track="click_references" data-track-action="external reference" data-track-value="external reference" data-track-label="10.48550/arXiv.1908.00690">https://doi.org/10.48550/arXiv.1908.00690</a> (2019).</p></li><li class="c-article-references__item js-c-reading-companion-references-item" data-counter="165."><p class="c-article-references__text" id="ref-CR165">Wu, E. et al. How medical AI devices are evaluated: limitations and recommendations from an analysis of FDA approvals. <i>Nat. Med</i>. <a href="https://doi.org/10.1038/s41591-021-01312-x" data-track="click_references" data-track-action="external reference" data-track-value="external reference" data-track-label="10.1038/s41591-021-01312-x">https://doi.org/10.1038/s41591-021-01312-x</a> (2021).</p></li><li class="c-article-references__item js-c-reading-companion-references-item" data-counter="166."><p class="c-article-references__text" id="ref-CR166">Barish, M., Bolourani, S., Lau, L. F., Shah, S. &amp; Zanos, T. P. External validation demonstrates limited clinical utility of the interpretable mortality prediction model for patients with COVID-19. <i>Nat. Mach. Intell.</i> <b>3</b>, 2527 (2020).</p><p class="c-article-references__links u-hide-print"><a data-track="click_references" rel="nofollow noopener" data-track-label="10.1038/s42256-020-00254-2" data-track-item_id="10.1038/s42256-020-00254-2" data-track-value="article reference" data-track-action="article reference" href="https://doi.org/10.1038%2Fs42256-020-00254-2" aria-label="Article reference 166" data-doi="10.1038/s42256-020-00254-2">Article</a>
    <a data-track="click_references" data-track-action="google scholar reference" data-track-value="google scholar reference" data-track-label="link" data-track-item_id="link" rel="nofollow noopener" aria-label="Google Scholar reference 166" href="http://scholar.google.com/scholar_lookup?&amp;title=External%20validation%20demonstrates%20limited%20clinical%20utility%20of%20the%20interpretable%20mortality%20prediction%20model%20for%20patients%20with%20COVID-19&amp;journal=Nat.%20Mach.%20Intell.&amp;doi=10.1038%2Fs42256-020-00254-2&amp;volume=3&amp;pages=25-27&amp;publication_year=2020&amp;author=Barish%2CM&amp;author=Bolourani%2CS&amp;author=Lau%2CLF&amp;author=Shah%2CS&amp;author=Zanos%2CTP">
                    Google Scholar</a>
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" data-counter="167."><p class="c-article-references__text" id="ref-CR167">Davis, S. E., Lasko, T. A., Chen, G., Siew, E. D. &amp; Matheny, M. E. Calibration drift in regression and machine learning models for acute kidney injury. <i>J. Am. Med. Inform. Assoc.</i> <b>24</b>, 10521061 (2017).</p><p class="c-article-references__links u-hide-print"><a data-track="click_references" rel="nofollow noopener" data-track-label="10.1093/jamia/ocx030" data-track-item_id="10.1093/jamia/ocx030" data-track-value="article reference" data-track-action="article reference" href="https://doi.org/10.1093%2Fjamia%2Focx030" aria-label="Article reference 167" data-doi="10.1093/jamia/ocx030">Article</a>
    <a data-track="click_references" rel="nofollow noopener" data-track-label="link" data-track-item_id="link" data-track-value="pubmed reference" data-track-action="pubmed reference" href="http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?cmd=Retrieve&amp;db=PubMed&amp;dopt=Abstract&amp;list_uids=28379439" aria-label="PubMed reference 167">PubMed</a>
    <a data-track="click_references" rel="nofollow noopener" data-track-label="link" data-track-item_id="link" data-track-value="pubmed central reference" data-track-action="pubmed central reference" href="http://www.ncbi.nlm.nih.gov/pmc/articles/PMC6080675" aria-label="PubMed Central reference 167">PubMed Central</a>
    <a data-track="click_references" data-track-action="google scholar reference" data-track-value="google scholar reference" data-track-label="link" data-track-item_id="link" rel="nofollow noopener" aria-label="Google Scholar reference 167" href="http://scholar.google.com/scholar_lookup?&amp;title=Calibration%20drift%20in%20regression%20and%20machine%20learning%20models%20for%20acute%20kidney%20injury&amp;journal=J.%20Am.%20Med.%20Inform.%20Assoc.&amp;doi=10.1093%2Fjamia%2Focx030&amp;volume=24&amp;pages=1052-1061&amp;publication_year=2017&amp;author=Davis%2CSE&amp;author=Lasko%2CTA&amp;author=Chen%2CG&amp;author=Siew%2CED&amp;author=Matheny%2CME">
                    Google Scholar</a>
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" data-counter="168."><p class="c-article-references__text" id="ref-CR168">Wang, G. et al. A deep-learning pipeline for the diagnosis and discrimination of viral, non-viral and COVID-19 pneumonia from chest X-ray images. <i>Nat. Biomed. Eng.</i> <b>5</b>, 509521 (2021).</p><p class="c-article-references__links u-hide-print"><a data-track="click_references" rel="nofollow noopener" data-track-label="10.1038/s41551-021-00704-1" data-track-item_id="10.1038/s41551-021-00704-1" data-track-value="article reference" data-track-action="article reference" href="https://doi.org/10.1038%2Fs41551-021-00704-1" aria-label="Article reference 168" data-doi="10.1038/s41551-021-00704-1">Article</a>
    <a data-track="click_references" rel="nofollow noopener" data-track-label="link" data-track-item_id="link" data-track-value="cas reference" data-track-action="cas reference" href="/articles/cas-redirect/1:CAS:528:DC%2BB3MXpsVSgtb4%3D" aria-label="CAS reference 168">CAS</a>
    <a data-track="click_references" rel="nofollow noopener" data-track-label="link" data-track-item_id="link" data-track-value="pubmed reference" data-track-action="pubmed reference" href="http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?cmd=Retrieve&amp;db=PubMed&amp;dopt=Abstract&amp;list_uids=33859385" aria-label="PubMed reference 168">PubMed</a>
    <a data-track="click_references" rel="nofollow noopener" data-track-label="link" data-track-item_id="link" data-track-value="pubmed central reference" data-track-action="pubmed central reference" href="http://www.ncbi.nlm.nih.gov/pmc/articles/PMC7611049" aria-label="PubMed Central reference 168">PubMed Central</a>
    <a data-track="click_references" data-track-action="google scholar reference" data-track-value="google scholar reference" data-track-label="link" data-track-item_id="link" rel="nofollow noopener" aria-label="Google Scholar reference 168" href="http://scholar.google.com/scholar_lookup?&amp;title=A%20deep-learning%20pipeline%20for%20the%20diagnosis%20and%20discrimination%20of%20viral%2C%20non-viral%20and%20COVID-19%20pneumonia%20from%20chest%20X-ray%20images&amp;journal=Nat.%20Biomed.%20Eng.&amp;doi=10.1038%2Fs41551-021-00704-1&amp;volume=5&amp;pages=509-521&amp;publication_year=2021&amp;author=Wang%2CG">
                    Google Scholar</a>
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" data-counter="169."><p class="c-article-references__text" id="ref-CR169">Ning, W. et al. Open resource of clinical data from patients with pneumonia for the prediction of COVID-19 outcomes via deep learning. <i>Nat. Biomed. Eng.</i> <b>4</b>, 11971207 (2020).</p><p class="c-article-references__links u-hide-print"><a data-track="click_references" rel="nofollow noopener" data-track-label="10.1038/s41551-020-00633-5" data-track-item_id="10.1038/s41551-020-00633-5" data-track-value="article reference" data-track-action="article reference" href="https://doi.org/10.1038%2Fs41551-020-00633-5" aria-label="Article reference 169" data-doi="10.1038/s41551-020-00633-5">Article</a>
    <a data-track="click_references" rel="nofollow noopener" data-track-label="link" data-track-item_id="link" data-track-value="cas reference" data-track-action="cas reference" href="/articles/cas-redirect/1:CAS:528:DC%2BB3cXisVertrvO" aria-label="CAS reference 169">CAS</a>
    <a data-track="click_references" rel="nofollow noopener" data-track-label="link" data-track-item_id="link" data-track-value="pubmed reference" data-track-action="pubmed reference" href="http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?cmd=Retrieve&amp;db=PubMed&amp;dopt=Abstract&amp;list_uids=33208927" aria-label="PubMed reference 169">PubMed</a>
    <a data-track="click_references" rel="nofollow noopener" data-track-label="link" data-track-item_id="link" data-track-value="pubmed central reference" data-track-action="pubmed central reference" href="http://www.ncbi.nlm.nih.gov/pmc/articles/PMC7723858" aria-label="PubMed Central reference 169">PubMed Central</a>
    <a data-track="click_references" data-track-action="google scholar reference" data-track-value="google scholar reference" data-track-label="link" data-track-item_id="link" rel="nofollow noopener" aria-label="Google Scholar reference 169" href="http://scholar.google.com/scholar_lookup?&amp;title=Open%20resource%20of%20clinical%20data%20from%20patients%20with%20pneumonia%20for%20the%20prediction%20of%20COVID-19%20outcomes%20via%20deep%20learning&amp;journal=Nat.%20Biomed.%20Eng.&amp;doi=10.1038%2Fs41551-020-00633-5&amp;volume=4&amp;pages=1197-1207&amp;publication_year=2020&amp;author=Ning%2CW">
                    Google Scholar</a>
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" data-counter="170."><p class="c-article-references__text" id="ref-CR170">Koenecke, A. et al. Racial disparities in automated speech recognition. <i>Proc. Natl Acad. Sci. USA</i> <b>117</b>, 76847689 (2020).</p><p class="c-article-references__links u-hide-print"><a data-track="click_references" rel="nofollow noopener" data-track-label="10.1073/pnas.1915768117" data-track-item_id="10.1073/pnas.1915768117" data-track-value="article reference" data-track-action="article reference" href="https://doi.org/10.1073%2Fpnas.1915768117" aria-label="Article reference 170" data-doi="10.1073/pnas.1915768117">Article</a>
    <a data-track="click_references" rel="nofollow noopener" data-track-label="link" data-track-item_id="link" data-track-value="cas reference" data-track-action="cas reference" href="/articles/cas-redirect/1:CAS:528:DC%2BB3cXms1ygsr4%3D" aria-label="CAS reference 170">CAS</a>
    <a data-track="click_references" rel="nofollow noopener" data-track-label="link" data-track-item_id="link" data-track-value="pubmed reference" data-track-action="pubmed reference" href="http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?cmd=Retrieve&amp;db=PubMed&amp;dopt=Abstract&amp;list_uids=32205437" aria-label="PubMed reference 170">PubMed</a>
    <a data-track="click_references" rel="nofollow noopener" data-track-label="link" data-track-item_id="link" data-track-value="pubmed central reference" data-track-action="pubmed central reference" href="http://www.ncbi.nlm.nih.gov/pmc/articles/PMC7149386" aria-label="PubMed Central reference 170">PubMed Central</a>
    <a data-track="click_references" data-track-action="google scholar reference" data-track-value="google scholar reference" data-track-label="link" data-track-item_id="link" rel="nofollow noopener" aria-label="Google Scholar reference 170" href="http://scholar.google.com/scholar_lookup?&amp;title=Racial%20disparities%20in%20automated%20speech%20recognition&amp;journal=Proc.%20Natl%20Acad.%20Sci.%20USA&amp;doi=10.1073%2Fpnas.1915768117&amp;volume=117&amp;pages=7684-7689&amp;publication_year=2020&amp;author=Koenecke%2CA">
                    Google Scholar</a>
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" data-counter="171."><p class="c-article-references__text" id="ref-CR171">Abid, A., Farooqi, M. &amp; Zou, J. Large language models associate muslims with violence. <i>Nat. Mach. Intell.</i> <b>3</b>, 461463 (2021).</p><p class="c-article-references__links u-hide-print"><a data-track="click_references" rel="nofollow noopener" data-track-label="10.1038/s42256-021-00359-2" data-track-item_id="10.1038/s42256-021-00359-2" data-track-value="article reference" data-track-action="article reference" href="https://doi.org/10.1038%2Fs42256-021-00359-2" aria-label="Article reference 171" data-doi="10.1038/s42256-021-00359-2">Article</a>
    <a data-track="click_references" data-track-action="google scholar reference" data-track-value="google scholar reference" data-track-label="link" data-track-item_id="link" rel="nofollow noopener" aria-label="Google Scholar reference 171" href="http://scholar.google.com/scholar_lookup?&amp;title=Large%20language%20models%20associate%20muslims%20with%20violence&amp;journal=Nat.%20Mach.%20Intell.&amp;doi=10.1038%2Fs42256-021-00359-2&amp;volume=3&amp;pages=461-463&amp;publication_year=2021&amp;author=Abid%2CA&amp;author=Farooqi%2CM&amp;author=Zou%2CJ">
                    Google Scholar</a>
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" data-counter="172."><p class="c-article-references__text" id="ref-CR172">Obermeyer, Z., Powers, B., Vogeli, C. &amp; Mullainathan, S. Dissecting racial bias in an algorithm used to manage the health of populations. <i>Science</i> <b>366</b>, 447453 (2019).</p><p class="c-article-references__links u-hide-print"><a data-track="click_references" rel="nofollow noopener" data-track-label="10.1126/science.aax2342" data-track-item_id="10.1126/science.aax2342" data-track-value="article reference" data-track-action="article reference" href="https://doi.org/10.1126%2Fscience.aax2342" aria-label="Article reference 172" data-doi="10.1126/science.aax2342">Article</a>
    <a data-track="click_references" rel="nofollow noopener" data-track-label="link" data-track-item_id="link" data-track-value="cas reference" data-track-action="cas reference" href="/articles/cas-redirect/1:CAS:528:DC%2BC1MXitVemtrjF" aria-label="CAS reference 172">CAS</a>
    <a data-track="click_references" rel="nofollow noopener" data-track-label="link" data-track-item_id="link" data-track-value="pubmed reference" data-track-action="pubmed reference" href="http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?cmd=Retrieve&amp;db=PubMed&amp;dopt=Abstract&amp;list_uids=31649194" aria-label="PubMed reference 172">PubMed</a>
    <a data-track="click_references" data-track-action="google scholar reference" data-track-value="google scholar reference" data-track-label="link" data-track-item_id="link" rel="nofollow noopener" aria-label="Google Scholar reference 172" href="http://scholar.google.com/scholar_lookup?&amp;title=Dissecting%20racial%20bias%20in%20an%20algorithm%20used%20to%20manage%20the%20health%20of%20populations&amp;journal=Science&amp;doi=10.1126%2Fscience.aax2342&amp;volume=366&amp;pages=447-453&amp;publication_year=2019&amp;author=Obermeyer%2CZ&amp;author=Powers%2CB&amp;author=Vogeli%2CC&amp;author=Mullainathan%2CS">
                    Google Scholar</a>
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" data-counter="173."><p class="c-article-references__text" id="ref-CR173">Adamson, A. S. &amp; Smith, A. Machine learning and health care disparities in dermatology. <i>JAMA Dermatol</i>. <b>154</b>, 12471248 (2018).</p><p class="c-article-references__links u-hide-print"><a data-track="click_references" rel="nofollow noopener" data-track-label="10.1001/jamadermatol.2018.2348" data-track-item_id="10.1001/jamadermatol.2018.2348" data-track-value="article reference" data-track-action="article reference" href="https://doi.org/10.1001%2Fjamadermatol.2018.2348" aria-label="Article reference 173" data-doi="10.1001/jamadermatol.2018.2348">Article</a>
    <a data-track="click_references" rel="nofollow noopener" data-track-label="link" data-track-item_id="link" data-track-value="pubmed reference" data-track-action="pubmed reference" href="http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?cmd=Retrieve&amp;db=PubMed&amp;dopt=Abstract&amp;list_uids=30073260" aria-label="PubMed reference 173">PubMed</a>
    <a data-track="click_references" data-track-action="google scholar reference" data-track-value="google scholar reference" data-track-label="link" data-track-item_id="link" rel="nofollow noopener" aria-label="Google Scholar reference 173" href="http://scholar.google.com/scholar_lookup?&amp;title=Machine%20learning%20and%20health%20care%20disparities%20in%20dermatology&amp;journal=JAMA%20Dermatol&amp;doi=10.1001%2Fjamadermatol.2018.2348&amp;volume=154&amp;pages=1247-1248&amp;publication_year=2018&amp;author=Adamson%2CAS&amp;author=Smith%2CA">
                    Google Scholar</a>
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" data-counter="174."><p class="c-article-references__text" id="ref-CR174">Han, S. S. et al. Classification of the clinical images for benign and malignant cutaneous tumors using a deep learning algorithm. <i>J. Invest. Dermatol.</i> <b>138</b>, 15291538 (2018).</p><p class="c-article-references__links u-hide-print"><a data-track="click_references" rel="nofollow noopener" data-track-label="10.1016/j.jid.2018.01.028" data-track-item_id="10.1016/j.jid.2018.01.028" data-track-value="article reference" data-track-action="article reference" href="https://doi.org/10.1016%2Fj.jid.2018.01.028" aria-label="Article reference 174" data-doi="10.1016/j.jid.2018.01.028">Article</a>
    <a data-track="click_references" rel="nofollow noopener" data-track-label="link" data-track-item_id="link" data-track-value="cas reference" data-track-action="cas reference" href="/articles/cas-redirect/1:CAS:528:DC%2BC1cXks12lsLc%3D" aria-label="CAS reference 174">CAS</a>
    <a data-track="click_references" rel="nofollow noopener" data-track-label="link" data-track-item_id="link" data-track-value="pubmed reference" data-track-action="pubmed reference" href="http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?cmd=Retrieve&amp;db=PubMed&amp;dopt=Abstract&amp;list_uids=29428356" aria-label="PubMed reference 174">PubMed</a>
    <a data-track="click_references" data-track-action="google scholar reference" data-track-value="google scholar reference" data-track-label="link" data-track-item_id="link" rel="nofollow noopener" aria-label="Google Scholar reference 174" href="http://scholar.google.com/scholar_lookup?&amp;title=Classification%20of%20the%20clinical%20images%20for%20benign%20and%20malignant%20cutaneous%20tumors%20using%20a%20deep%20learning%20algorithm&amp;journal=J.%20Invest.%20Dermatol.&amp;doi=10.1016%2Fj.jid.2018.01.028&amp;volume=138&amp;pages=1529-1538&amp;publication_year=2018&amp;author=Han%2CSS">
                    Google Scholar</a>
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" data-counter="175."><p class="c-article-references__text" id="ref-CR175">Subbaswamy, A., Adams, R. &amp; Saria, S. Evaluating model robustness and stability to dataset shift. In <i>Proceedings of The 24th International Conference on Artificial Intelligence and Statistics</i> (eds. Banerjee, A. &amp; Fukumizu, K.) 26112619 (PMLR, 2021).</p></li><li class="c-article-references__item js-c-reading-companion-references-item" data-counter="176."><p class="c-article-references__text" id="ref-CR176">Izzo, Z., Ying, L. &amp; Zou, J. How to learn when data reacts to your model: performative gradient descent. In <i>Proceedings of the 38th International Conference on Machine Learning</i> (eds. Meila, M. &amp; Zhang, T.) 46414650 (PMLR, 2021).</p></li><li class="c-article-references__item js-c-reading-companion-references-item" data-counter="177."><p class="c-article-references__text" id="ref-CR177">Ghorbani, A., Kim, M. &amp; Zou, J. A Distributional framework for data valuation. In <i>Proceedings of the 37th International Conference on Machine Learning</i> (eds. Iii, H. D. &amp; Singh, A.) 35353544 (PMLR, 2020).</p></li><li class="c-article-references__item js-c-reading-companion-references-item" data-counter="178."><p class="c-article-references__text" id="ref-CR178">Zhang, L., Deng, Z., Kawaguchi, K., Ghorbani, A. &amp; Zou, J. How does mixup help with robustness and generalization? In <i>International Conference on Learning Representations 2021</i> Paper 2273 (ICLR, 2021).</p></li><li class="c-article-references__item js-c-reading-companion-references-item" data-counter="179."><p class="c-article-references__text" id="ref-CR179">Schulam, P. &amp; Saria, S. Can you trust this prediction? Auditing pointwise reliability after learning. In <i>Proceedings of the Twenty-Second International Conference on Artificial Intelligence and Statistics</i> (eds. Chaudhuri, K. &amp; Sugiyama, M.) 10221031 (PMLR, 2019).</p></li><li class="c-article-references__item js-c-reading-companion-references-item" data-counter="180."><p class="c-article-references__text" id="ref-CR180">Liu, X. et al. Reporting guidelines for clinical trial reports for interventions involving artificial intelligence: the CONSORT-AI extension. <i>Nat. Med.</i> <b>26</b>, 13641374 (2020).</p><p class="c-article-references__links u-hide-print"><a data-track="click_references" rel="nofollow noopener" data-track-label="10.1038/s41591-020-1034-x" data-track-item_id="10.1038/s41591-020-1034-x" data-track-value="article reference" data-track-action="article reference" href="https://doi.org/10.1038%2Fs41591-020-1034-x" aria-label="Article reference 180" data-doi="10.1038/s41591-020-1034-x">Article</a>
    <a data-track="click_references" rel="nofollow noopener" data-track-label="link" data-track-item_id="link" data-track-value="cas reference" data-track-action="cas reference" href="/articles/cas-redirect/1:CAS:528:DC%2BB3cXhvVyqu7%2FO" aria-label="CAS reference 180">CAS</a>
    <a data-track="click_references" rel="nofollow noopener" data-track-label="link" data-track-item_id="link" data-track-value="pubmed reference" data-track-action="pubmed reference" href="http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?cmd=Retrieve&amp;db=PubMed&amp;dopt=Abstract&amp;list_uids=32908283" aria-label="PubMed reference 180">PubMed</a>
    <a data-track="click_references" rel="nofollow noopener" data-track-label="link" data-track-item_id="link" data-track-value="pubmed central reference" data-track-action="pubmed central reference" href="http://www.ncbi.nlm.nih.gov/pmc/articles/PMC7598943" aria-label="PubMed Central reference 180">PubMed Central</a>
    <a data-track="click_references" data-track-action="google scholar reference" data-track-value="google scholar reference" data-track-label="link" data-track-item_id="link" rel="nofollow noopener" aria-label="Google Scholar reference 180" href="http://scholar.google.com/scholar_lookup?&amp;title=Reporting%20guidelines%20for%20clinical%20trial%20reports%20for%20interventions%20involving%20artificial%20intelligence%3A%20the%20CONSORT-AI%20extension&amp;journal=Nat.%20Med.&amp;doi=10.1038%2Fs41591-020-1034-x&amp;volume=26&amp;pages=1364-1374&amp;publication_year=2020&amp;author=Liu%2CX">
                    Google Scholar</a>
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" data-counter="181."><p class="c-article-references__text" id="ref-CR181">Cruz Rivera, S. et al. Guidelines for clinical trial protocols for interventions involving artificial intelligence: the SPIRIT-AI extension. <i>Nat. Med.</i> <b>26</b>, 13511363 (2020).</p><p class="c-article-references__links u-hide-print"><a data-track="click_references" rel="nofollow noopener" data-track-label="10.1038/s41591-020-1037-7" data-track-item_id="10.1038/s41591-020-1037-7" data-track-value="article reference" data-track-action="article reference" href="https://doi.org/10.1038%2Fs41591-020-1037-7" aria-label="Article reference 181" data-doi="10.1038/s41591-020-1037-7">Article</a>
    <a data-track="click_references" rel="nofollow noopener" data-track-label="link" data-track-item_id="link" data-track-value="cas reference" data-track-action="cas reference" href="/articles/cas-redirect/1:CAS:528:DC%2BB3cXhvVyqu7%2FM" aria-label="CAS reference 181">CAS</a>
    <a data-track="click_references" rel="nofollow noopener" data-track-label="link" data-track-item_id="link" data-track-value="pubmed reference" data-track-action="pubmed reference" href="http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?cmd=Retrieve&amp;db=PubMed&amp;dopt=Abstract&amp;list_uids=32908284" aria-label="PubMed reference 181">PubMed</a>
    <a data-track="click_references" rel="nofollow noopener" data-track-label="link" data-track-item_id="link" data-track-value="pubmed central reference" data-track-action="pubmed central reference" href="http://www.ncbi.nlm.nih.gov/pmc/articles/PMC7598944" aria-label="PubMed Central reference 181">PubMed Central</a>
    <a data-track="click_references" data-track-action="google scholar reference" data-track-value="google scholar reference" data-track-label="link" data-track-item_id="link" rel="nofollow noopener" aria-label="Google Scholar reference 181" href="http://scholar.google.com/scholar_lookup?&amp;title=Guidelines%20for%20clinical%20trial%20protocols%20for%20interventions%20involving%20artificial%20intelligence%3A%20the%20SPIRIT-AI%20extension&amp;journal=Nat.%20Med.&amp;doi=10.1038%2Fs41591-020-1037-7&amp;volume=26&amp;pages=1351-1363&amp;publication_year=2020&amp;author=Cruz%20Rivera%2CS">
                    Google Scholar</a>
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" data-counter="182."><p class="c-article-references__text" id="ref-CR182">Nayak, P. Understanding searches better than ever before. <i>Google The Keyword</i> <a href="https://blog.google/products/search/search-language-understanding-bert/" data-track="click_references" data-track-action="external reference" data-track-value="external reference" data-track-label="https://blog.google/products/search/search-language-understanding-bert/">https://blog.google/products/search/search-language-understanding-bert/</a> (2019).</p></li><li class="c-article-references__item js-c-reading-companion-references-item" data-counter="183."><p class="c-article-references__text" id="ref-CR183">Baur, C., Albarqouni, S. &amp; Navab, N. in <i>OR 2.0 Context-Aware Operating Theaters, Computer Assisted Robotic Endoscopy, Clinical Image-Based Procedures, and Skin Image Analysis</i> (eds Stoyanov, D. et al.) 260267 (Springer International Publishing, 2018).</p></li><li class="c-article-references__item js-c-reading-companion-references-item" data-counter="184."><p class="c-article-references__text" id="ref-CR184">Kang, E., Koo, H. J., Yang, D. H., Seo, J. B. &amp; Ye, J. C. Cycle-consistent adversarial denoising network for multiphase coronary CT angiography. <i>Med. Phys.</i> <b>46</b>, 550562 (2019).</p><p class="c-article-references__links u-hide-print"><a data-track="click_references" rel="nofollow noopener" data-track-label="10.1002/mp.13284" data-track-item_id="10.1002/mp.13284" data-track-value="article reference" data-track-action="article reference" href="https://doi.org/10.1002%2Fmp.13284" aria-label="Article reference 184" data-doi="10.1002/mp.13284">Article</a>
    <a data-track="click_references" rel="nofollow noopener" data-track-label="link" data-track-item_id="link" data-track-value="pubmed reference" data-track-action="pubmed reference" href="http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?cmd=Retrieve&amp;db=PubMed&amp;dopt=Abstract&amp;list_uids=30449055" aria-label="PubMed reference 184">PubMed</a>
    <a data-track="click_references" data-track-action="google scholar reference" data-track-value="google scholar reference" data-track-label="link" data-track-item_id="link" rel="nofollow noopener" aria-label="Google Scholar reference 184" href="http://scholar.google.com/scholar_lookup?&amp;title=Cycle-consistent%20adversarial%20denoising%20network%20for%20multiphase%20coronary%20CT%20angiography&amp;journal=Med.%20Phys.&amp;doi=10.1002%2Fmp.13284&amp;volume=46&amp;pages=550-562&amp;publication_year=2019&amp;author=Kang%2CE&amp;author=Koo%2CHJ&amp;author=Yang%2CDH&amp;author=Seo%2CJB&amp;author=Ye%2CJC">
                    Google Scholar</a>
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" data-counter="185."><p class="c-article-references__text" id="ref-CR185">Vig, J. A multiscale visualization of attention in the transformer model. In <i>Proceedings of the 57th Annual Meeting of the Association for Computational Linguistics: System Demonstrations</i> (Costa-juss, M. R. &amp; Alfonseca, E.) 3742 (Association for Computational Linguistics, 2019).</p></li></ol><p class="c-article-references__download u-hide-print"><a data-track="click" data-track-action="download citation references" data-track-label="link" rel="nofollow" href="https://citation-needed.springer.com/v2/references/10.1038/s41551-022-00898-y?format=refman&amp;flavour=references">Download references<svg width="16" height="16" focusable="false" role="img" aria-hidden="true" class="u-icon"><use xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="#icon-eds-i-download-medium"></use></svg></a></p></div></div></div></section></div><section data-title="Acknowledgements"><div class="c-article-section" id="Ack1-section"><h2 class="c-article-section__title js-section-title js-c-reading-companion-sections-item" id="Ack1">Acknowledgements</h2><div class="c-article-section__content" id="Ack1-content"><p>This work was supported in part by the National Institutes of Health via grants F30HL156478 (to A.Z.), R01CA227713 (to L.X.), R01CA256890 (to L.X.), P30AG059307 (to J.Z.), U01MH098953 (to J.Z.), P01HL141084 (to J.C.W), R01HL163680 (to J.C.W), R01HL130020 (to J.C.W), R01HL146690 (to J.C.W.) and R01HL126527 (to J.C.W.); by the National Science Foundation grant CAREER1942926 (to J.Z.); and by the American Heart Association grant 17MERIT3361009 (to J.C.W.). Figures were created with BioRender.com.</p></div></div></section><section aria-labelledby="author-information" data-title="Author information"><div class="c-article-section" id="author-information-section"><h2 class="c-article-section__title js-section-title js-c-reading-companion-sections-item" id="author-information">Author information</h2><div class="c-article-section__content" id="author-information-content"><h3 class="c-article__sub-heading" id="affiliations">Authors and Affiliations</h3><ol class="c-article-author-affiliation__list"><li id="Aff1"><p class="c-article-author-affiliation__address">Stanford Cardiovascular Institute, School of Medicine, Stanford University, Stanford, CA, USA</p><p class="c-article-author-affiliation__authors-list">Angela Zhang&amp;Joseph C. Wu</p></li><li id="Aff2"><p class="c-article-author-affiliation__address">Department of Genetics, School of Medicine, Stanford University, Stanford, CA, USA</p><p class="c-article-author-affiliation__authors-list">Angela Zhang</p></li><li id="Aff3"><p class="c-article-author-affiliation__address">Greenstone Biosciences, Palo Alto, CA, USA</p><p class="c-article-author-affiliation__authors-list">Angela Zhang&amp;Joseph C. Wu</p></li><li id="Aff4"><p class="c-article-author-affiliation__address">Department of Computer Science, Stanford University, Stanford, CA, USA</p><p class="c-article-author-affiliation__authors-list">Angela Zhang&amp;James Zou</p></li><li id="Aff5"><p class="c-article-author-affiliation__address">Department of Radiation Oncology, School of Medicine, Stanford University, Stanford, CA, USA</p><p class="c-article-author-affiliation__authors-list">Lei Xing</p></li><li id="Aff6"><p class="c-article-author-affiliation__address">Department of Biomedical Informatics, School of Medicine, Stanford University, Stanford, CA, USA</p><p class="c-article-author-affiliation__authors-list">James Zou</p></li><li id="Aff7"><p class="c-article-author-affiliation__address">Departments of Medicine, Division of Cardiovascular Medicine Stanford University, Stanford, CA, USA</p><p class="c-article-author-affiliation__authors-list">Joseph C. Wu</p></li><li id="Aff8"><p class="c-article-author-affiliation__address">Department of Radiology, School of Medicine, Stanford University, Stanford, CA, USA</p><p class="c-article-author-affiliation__authors-list">Joseph C. Wu</p></li></ol><div class="u-js-hide u-hide-print" data-test="author-info"><span class="c-article__sub-heading">Authors</span><ol class="c-article-authors-search u-list-reset"><li id="auth-Angela-Zhang-Aff1-Aff2-Aff3-Aff4"><span class="c-article-authors-search__title u-h3 js-search-name">Angela Zhang</span><div class="c-article-authors-search__list"><div class="c-article-authors-search__item c-article-authors-search__list-item--left"><a href="/search?author=Angela%20Zhang" class="c-article-button" data-track="click" data-track-action="author link - publication" data-track-label="link" rel="nofollow">View author publications</a></div><div class="c-article-authors-search__item c-article-authors-search__list-item--right"><p class="search-in-title-js c-article-authors-search__text"><span class="c-article-authors-search__links-text">Search author on:</span><span class="c-article-identifiers"><a class="c-article-identifiers__item" href="https://www.ncbi.nlm.nih.gov/entrez/query.fcgi?cmd=search&amp;term=Angela%20Zhang" data-track="click" data-track-action="author link - pubmed" data-track-label="link" rel="nofollow">PubMed</a><span class="u-hide"></span><a class="c-article-identifiers__item" href="https://scholar.google.co.uk/scholar?as_q=&amp;num=10&amp;btnG=Search+Scholar&amp;as_epq=&amp;as_oq=&amp;as_eq=&amp;as_occt=any&amp;as_sauthors=%22Angela%20Zhang%22&amp;as_publication=&amp;as_ylo=&amp;as_yhi=&amp;as_allsubj=all&amp;hl=en" data-track="click" data-track-action="author link - scholar" data-track-label="link" rel="nofollow">Google Scholar</a></span></p></div></div></li><li id="auth-Lei-Xing-Aff5"><span class="c-article-authors-search__title u-h3 js-search-name">Lei Xing</span><div class="c-article-authors-search__list"><div class="c-article-authors-search__item c-article-authors-search__list-item--left"><a href="/search?author=Lei%20Xing" class="c-article-button" data-track="click" data-track-action="author link - publication" data-track-label="link" rel="nofollow">View author publications</a></div><div class="c-article-authors-search__item c-article-authors-search__list-item--right"><p class="search-in-title-js c-article-authors-search__text"><span class="c-article-authors-search__links-text">Search author on:</span><span class="c-article-identifiers"><a class="c-article-identifiers__item" href="https://www.ncbi.nlm.nih.gov/entrez/query.fcgi?cmd=search&amp;term=Lei%20Xing" data-track="click" data-track-action="author link - pubmed" data-track-label="link" rel="nofollow">PubMed</a><span class="u-hide"></span><a class="c-article-identifiers__item" href="https://scholar.google.co.uk/scholar?as_q=&amp;num=10&amp;btnG=Search+Scholar&amp;as_epq=&amp;as_oq=&amp;as_eq=&amp;as_occt=any&amp;as_sauthors=%22Lei%20Xing%22&amp;as_publication=&amp;as_ylo=&amp;as_yhi=&amp;as_allsubj=all&amp;hl=en" data-track="click" data-track-action="author link - scholar" data-track-label="link" rel="nofollow">Google Scholar</a></span></p></div></div></li><li id="auth-James-Zou-Aff4-Aff6"><span class="c-article-authors-search__title u-h3 js-search-name">James Zou</span><div class="c-article-authors-search__list"><div class="c-article-authors-search__item c-article-authors-search__list-item--left"><a href="/search?author=James%20Zou" class="c-article-button" data-track="click" data-track-action="author link - publication" data-track-label="link" rel="nofollow">View author publications</a></div><div class="c-article-authors-search__item c-article-authors-search__list-item--right"><p class="search-in-title-js c-article-authors-search__text"><span class="c-article-authors-search__links-text">Search author on:</span><span class="c-article-identifiers"><a class="c-article-identifiers__item" href="https://www.ncbi.nlm.nih.gov/entrez/query.fcgi?cmd=search&amp;term=James%20Zou" data-track="click" data-track-action="author link - pubmed" data-track-label="link" rel="nofollow">PubMed</a><span class="u-hide"></span><a class="c-article-identifiers__item" href="https://scholar.google.co.uk/scholar?as_q=&amp;num=10&amp;btnG=Search+Scholar&amp;as_epq=&amp;as_oq=&amp;as_eq=&amp;as_occt=any&amp;as_sauthors=%22James%20Zou%22&amp;as_publication=&amp;as_ylo=&amp;as_yhi=&amp;as_allsubj=all&amp;hl=en" data-track="click" data-track-action="author link - scholar" data-track-label="link" rel="nofollow">Google Scholar</a></span></p></div></div></li><li id="auth-Joseph_C_-Wu-Aff1-Aff3-Aff7-Aff8"><span class="c-article-authors-search__title u-h3 js-search-name">Joseph C. Wu</span><div class="c-article-authors-search__list"><div class="c-article-authors-search__item c-article-authors-search__list-item--left"><a href="/search?author=Joseph%20C.%20Wu" class="c-article-button" data-track="click" data-track-action="author link - publication" data-track-label="link" rel="nofollow">View author publications</a></div><div class="c-article-authors-search__item c-article-authors-search__list-item--right"><p class="search-in-title-js c-article-authors-search__text"><span class="c-article-authors-search__links-text">Search author on:</span><span class="c-article-identifiers"><a class="c-article-identifiers__item" href="https://www.ncbi.nlm.nih.gov/entrez/query.fcgi?cmd=search&amp;term=Joseph%20C.%20Wu" data-track="click" data-track-action="author link - pubmed" data-track-label="link" rel="nofollow">PubMed</a><span class="u-hide"></span><a class="c-article-identifiers__item" href="https://scholar.google.co.uk/scholar?as_q=&amp;num=10&amp;btnG=Search+Scholar&amp;as_epq=&amp;as_oq=&amp;as_eq=&amp;as_occt=any&amp;as_sauthors=%22Joseph%20C.%20Wu%22&amp;as_publication=&amp;as_ylo=&amp;as_yhi=&amp;as_allsubj=all&amp;hl=en" data-track="click" data-track-action="author link - scholar" data-track-label="link" rel="nofollow">Google Scholar</a></span></p></div></div></li></ol></div><h3 class="c-article__sub-heading" id="contributions">Contributions</h3><p>A.Z. and J.C.W. drafted the manuscript. All authors contributed to the conceptualization and editing of the manuscript.</p><h3 class="c-article__sub-heading" id="corresponding-author">Corresponding authors</h3><p id="corresponding-author-list">Correspondence to
                <a id="corresp-c1" aria-label="email Angela Zhang" href="mailto:angelazhang@greenstonebio.com">Angela Zhang</a> or <a id="corresp-c2" aria-label="email Joseph C. Wu" href="mailto:joewu@stanford.edu">Joseph C. Wu</a>.</p></div></div></section><section data-title="Ethics declarations"><div class="c-article-section" id="ethics-section"><h2 class="c-article-section__title js-section-title js-c-reading-companion-sections-item" id="ethics">Ethics declarations</h2><div class="c-article-section__content" id="ethics-content">
              
                <h3 class="c-article__sub-heading" id="FPar2">Competing interests</h3>
                <p>J.C.W. is a co-founder and scientific advisory board member of Greenstone Biosciences. The other authors declare no competing interests.</p>
              
            </div></div></section><section data-title="Peer review"><div class="c-article-section" id="peer-review-section"><h2 class="c-article-section__title js-section-title js-c-reading-companion-sections-item" id="peer-review">Peer review</h2><div class="c-article-section__content" id="peer-review-content">
              
              
                <h3 class="c-article__sub-heading" id="FPar1">Peer review information</h3>
                <p><i>Nature Biomedical Engineering</i> thanks Pearse Keane, Faisal Mahmood and Hadi Shafiee for their contribution to the peer review of this work.</p>
              
            </div></div></section><section data-title="Additional information"><div class="c-article-section" id="additional-information-section"><h2 class="c-article-section__title js-section-title js-c-reading-companion-sections-item" id="additional-information">Additional information</h2><div class="c-article-section__content" id="additional-information-content"><p><b>Publishers note</b> Springer Nature remains neutral with regard to jurisdictional claims in published maps and institutional affiliations.</p></div></div></section><section data-title="Rights and permissions"><div class="c-article-section" id="rightslink-section"><h2 class="c-article-section__title js-section-title js-c-reading-companion-sections-item" id="rightslink">Rights and permissions</h2><div class="c-article-section__content" id="rightslink-content"><p class="c-article-rights"><a data-track="click" data-track-action="view rights and permissions" data-track-label="link" href="https://s100.copyright.com/AppDispatchServlet?title=Shifting%20machine%20learning%20for%20healthcare%20from%20development%20to%20deployment%20and%20from%20models%20to%20data&amp;author=Angela%20Zhang%20et%20al&amp;contentID=10.1038%2Fs41551-022-00898-y&amp;copyright=Springer%20Nature%20Limited&amp;publication=2157-846X&amp;publicationDate=2022-07-04&amp;publisherName=SpringerNature&amp;orderBeanReset=true">Reprints and permissions</a></p></div></div></section><section aria-labelledby="article-info" data-title="About this article"><div class="c-article-section" id="article-info-section"><h2 class="c-article-section__title js-section-title js-c-reading-companion-sections-item" id="article-info">About this article</h2><div class="c-article-section__content" id="article-info-content"><div class="c-bibliographic-information"><div class="u-hide-print c-bibliographic-information__column c-bibliographic-information__column--border"><a data-crossmark="10.1038/s41551-022-00898-y" target="_blank" rel="noopener" href="https://crossmark.crossref.org/dialog/?doi=10.1038/s41551-022-00898-y" data-track="click" data-track-action="Click Crossmark" data-track-label="link" data-test="crossmark"><img loading="lazy" width="57" height="81" alt="Check for updates. Verify currency and authenticity via CrossMark" src="data:image/svg+xml;base64,<svg height="81" width="57" xmlns="http://www.w3.org/2000/svg"><g fill="none" fill-rule="evenodd"><path d="m17.35 35.45 21.3-14.2v-17.03h-21.3" fill="#989898"/><path d="m38.65 35.45-21.3-14.2v-17.03h21.3" fill="#747474"/><path d="m28 .5c-12.98 0-23.5 10.52-23.5 23.5s10.52 23.5 23.5 23.5 23.5-10.52 23.5-23.5c0-6.23-2.48-12.21-6.88-16.62-4.41-4.4-10.39-6.88-16.62-6.88zm0 41.25c-9.8 0-17.75-7.95-17.75-17.75s7.95-17.75 17.75-17.75 17.75 7.95 17.75 17.75c0 4.71-1.87 9.22-5.2 12.55s-7.84 5.2-12.55 5.2z" fill="#535353"/><path d="m41 36c-5.81 6.23-15.23 7.45-22.43 2.9-7.21-4.55-10.16-13.57-7.03-21.5l-4.92-3.11c-4.95 10.7-1.19 23.42 8.78 29.71 9.97 6.3 23.07 4.22 30.6-4.86z" fill="#9c9c9c"/><path d="m.2 58.45c0-.75.11-1.42.33-2.01s.52-1.09.91-1.5c.38-.41.83-.73 1.34-.94.51-.22 1.06-.32 1.65-.32.56 0 1.06.11 1.51.35.44.23.81.5 1.1.81l-.91 1.01c-.24-.24-.49-.42-.75-.56-.27-.13-.58-.2-.93-.2-.39 0-.73.08-1.05.23-.31.16-.58.37-.81.66-.23.28-.41.63-.53 1.04-.13.41-.19.88-.19 1.39 0 1.04.23 1.86.68 2.46.45.59 1.06.88 1.84.88.41 0 .77-.07 1.07-.23s.59-.39.85-.68l.91 1c-.38.43-.8.76-1.28.99-.47.22-1 .34-1.58.34-.59 0-1.13-.1-1.64-.31-.5-.2-.94-.51-1.31-.91-.38-.4-.67-.9-.88-1.48-.22-.59-.33-1.26-.33-2.02zm8.4-5.33h1.61v2.54l-.05 1.33c.29-.27.61-.51.96-.72s.76-.31 1.24-.31c.73 0 1.27.23 1.61.71.33.47.5 1.14.5 2.02v4.31h-1.61v-4.1c0-.57-.08-.97-.25-1.21-.17-.23-.45-.35-.83-.35-.3 0-.56.08-.79.22-.23.15-.49.36-.78.64v4.8h-1.61zm7.37 6.45c0-.56.09-1.06.26-1.51.18-.45.42-.83.71-1.14.29-.3.63-.54 1.01-.71.39-.17.78-.25 1.18-.25.47 0 .88.08 1.23.24.36.16.65.38.89.67s.42.63.54 1.03c.12.41.18.84.18 1.32 0 .32-.02.57-.07.76h-4.36c.07.62.29 1.1.65 1.44.36.33.82.5 1.38.5.29 0 .57-.04.83-.13s.51-.21.76-.37l.55 1.01c-.33.21-.69.39-1.09.53-.41.14-.83.21-1.26.21-.48 0-.92-.08-1.34-.25-.41-.16-.76-.4-1.07-.7-.31-.31-.55-.69-.72-1.13-.18-.44-.26-.95-.26-1.52zm4.6-.62c0-.55-.11-.98-.34-1.28-.23-.31-.58-.47-1.06-.47-.41 0-.77.15-1.07.45-.31.29-.5.73-.58 1.3zm2.5.62c0-.57.09-1.08.28-1.53.18-.44.43-.82.75-1.13s.69-.54 1.1-.71c.42-.16.85-.24 1.31-.24.45 0 .84.08 1.17.23s.61.34.85.57l-.77 1.02c-.19-.16-.38-.28-.56-.37-.19-.09-.39-.14-.61-.14-.56 0-1.01.21-1.35.63-.35.41-.52.97-.52 1.67 0 .69.17 1.24.51 1.66.34.41.78.62 1.32.62.28 0 .54-.06.78-.17.24-.12.45-.26.64-.42l.67 1.03c-.33.29-.69.51-1.08.65-.39.15-.78.23-1.18.23-.46 0-.9-.08-1.31-.24-.4-.16-.75-.39-1.05-.7s-.53-.69-.7-1.13c-.17-.45-.25-.96-.25-1.53zm6.91-6.45h1.58v6.17h.05l2.54-3.16h1.77l-2.35 2.8 2.59 4.07h-1.75l-1.77-2.98-1.08 1.23v1.75h-1.58zm13.69 1.27c-.25-.11-.5-.17-.75-.17-.58 0-.87.39-.87 1.16v.75h1.34v1.27h-1.34v5.6h-1.61v-5.6h-.92v-1.2l.92-.07v-.72c0-.35.04-.68.13-.98.08-.31.21-.57.4-.79s.42-.39.71-.51c.28-.12.63-.18 1.04-.18.24 0 .48.02.69.07.22.05.41.1.57.17zm.48 5.18c0-.57.09-1.08.27-1.53.17-.44.41-.82.72-1.13.3-.31.65-.54 1.04-.71.39-.16.8-.24 1.23-.24s.84.08 1.24.24c.4.17.74.4 1.04.71s.54.69.72 1.13c.19.45.28.96.28 1.53s-.09 1.08-.28 1.53c-.18.44-.42.82-.72 1.13s-.64.54-1.04.7-.81.24-1.24.24-.84-.08-1.23-.24-.74-.39-1.04-.7c-.31-.31-.55-.69-.72-1.13-.18-.45-.27-.96-.27-1.53zm1.65 0c0 .69.14 1.24.43 1.66.28.41.68.62 1.18.62.51 0 .9-.21 1.19-.62.29-.42.44-.97.44-1.66 0-.7-.15-1.26-.44-1.67-.29-.42-.68-.63-1.19-.63-.5 0-.9.21-1.18.63-.29.41-.43.97-.43 1.67zm6.48-3.44h1.33l.12 1.21h.05c.24-.44.54-.79.88-1.02.35-.24.7-.36 1.07-.36.32 0 .59.05.78.14l-.28 1.4-.33-.09c-.11-.01-.23-.02-.38-.02-.27 0-.56.1-.86.31s-.55.58-.77 1.1v4.2h-1.61zm-47.87 15h1.61v4.1c0 .57.08.97.25 1.2.17.24.44.35.81.35.3 0 .57-.07.8-.22.22-.15.47-.39.73-.73v-4.7h1.61v6.87h-1.32l-.12-1.01h-.04c-.3.36-.63.64-.98.86-.35.21-.76.32-1.24.32-.73 0-1.27-.24-1.61-.71-.33-.47-.5-1.14-.5-2.02zm9.46 7.43v2.16h-1.61v-9.59h1.33l.12.72h.05c.29-.24.61-.45.97-.63.35-.17.72-.26 1.1-.26.43 0 .81.08 1.15.24.33.17.61.4.84.71.24.31.41.68.53 1.11.13.42.19.91.19 1.44 0 .59-.09 1.11-.25 1.57-.16.47-.38.85-.65 1.16-.27.32-.58.56-.94.73-.35.16-.72.25-1.1.25-.3 0-.6-.07-.9-.2s-.59-.31-.87-.56zm0-2.3c.26.22.5.37.73.45.24.09.46.13.66.13.46 0 .84-.2 1.15-.6.31-.39.46-.98.46-1.77 0-.69-.12-1.22-.35-1.61-.23-.38-.61-.57-1.13-.57-.49 0-.99.26-1.52.77zm5.87-1.69c0-.56.08-1.06.25-1.51.16-.45.37-.83.65-1.14.27-.3.58-.54.93-.71s.71-.25 1.08-.25c.39 0 .73.07 1 .2.27.14.54.32.81.55l-.06-1.1v-2.49h1.61v9.88h-1.33l-.11-.74h-.06c-.25.25-.54.46-.88.64-.33.18-.69.27-1.06.27-.87 0-1.56-.32-2.07-.95s-.76-1.51-.76-2.65zm1.67-.01c0 .74.13 1.31.4 1.7.26.38.65.58 1.15.58.51 0 .99-.26 1.44-.77v-3.21c-.24-.21-.48-.36-.7-.45-.23-.08-.46-.12-.7-.12-.45 0-.82.19-1.13.59-.31.39-.46.95-.46 1.68zm6.35 1.59c0-.73.32-1.3.97-1.71.64-.4 1.67-.68 3.08-.84 0-.17-.02-.34-.07-.51-.05-.16-.12-.3-.22-.43s-.22-.22-.38-.3c-.15-.06-.34-.1-.58-.1-.34 0-.68.07-1 .2s-.63.29-.93.47l-.59-1.08c.39-.24.81-.45 1.28-.63.47-.17.99-.26 1.54-.26.86 0 1.51.25 1.93.76s.63 1.25.63 2.21v4.07h-1.32l-.12-.76h-.05c-.3.27-.63.48-.98.66s-.73.27-1.14.27c-.61 0-1.1-.19-1.48-.56-.38-.36-.57-.85-.57-1.46zm1.57-.12c0 .3.09.53.27.67.19.14.42.21.71.21.28 0 .54-.07.77-.2s.48-.31.73-.56v-1.54c-.47.06-.86.13-1.18.23-.31.09-.57.19-.76.31s-.33.25-.41.4c-.09.15-.13.31-.13.48zm6.29-3.63h-.98v-1.2l1.06-.07.2-1.88h1.34v1.88h1.75v1.27h-1.75v3.28c0 .8.32 1.2.97 1.2.12 0 .24-.01.37-.04.12-.03.24-.07.34-.11l.28 1.19c-.19.06-.4.12-.64.17-.23.05-.49.08-.76.08-.4 0-.74-.06-1.02-.18-.27-.13-.49-.3-.67-.52-.17-.21-.3-.48-.37-.78-.08-.3-.12-.64-.12-1.01zm4.36 2.17c0-.56.09-1.06.27-1.51s.41-.83.71-1.14c.29-.3.63-.54 1.01-.71.39-.17.78-.25 1.18-.25.47 0 .88.08 1.23.24.36.16.65.38.89.67s.42.63.54 1.03c.12.41.18.84.18 1.32 0 .32-.02.57-.07.76h-4.37c.08.62.29 1.1.65 1.44.36.33.82.5 1.38.5.3 0 .58-.04.84-.13.25-.09.51-.21.76-.37l.54 1.01c-.32.21-.69.39-1.09.53s-.82.21-1.26.21c-.47 0-.92-.08-1.33-.25-.41-.16-.77-.4-1.08-.7-.3-.31-.54-.69-.72-1.13-.17-.44-.26-.95-.26-1.52zm4.61-.62c0-.55-.11-.98-.34-1.28-.23-.31-.58-.47-1.06-.47-.41 0-.77.15-1.08.45-.31.29-.5.73-.57 1.3zm3.01 2.23c.31.24.61.43.92.57.3.13.63.2.98.2.38 0 .65-.08.83-.23s.27-.35.27-.6c0-.14-.05-.26-.13-.37-.08-.1-.2-.2-.34-.28-.14-.09-.29-.16-.47-.23l-.53-.22c-.23-.09-.46-.18-.69-.3-.23-.11-.44-.24-.62-.4s-.33-.35-.45-.55c-.12-.21-.18-.46-.18-.75 0-.61.23-1.1.68-1.49.44-.38 1.06-.57 1.83-.57.48 0 .91.08 1.29.25s.71.36.99.57l-.74.98c-.24-.17-.49-.32-.73-.42-.25-.11-.51-.16-.78-.16-.35 0-.6.07-.76.21-.17.15-.25.33-.25.54 0 .14.04.26.12.36s.18.18.31.26c.14.07.29.14.46.21l.54.19c.23.09.47.18.7.29s.44.24.64.4c.19.16.34.35.46.58.11.23.17.5.17.82 0 .3-.06.58-.17.83-.12.26-.29.48-.51.68-.23.19-.51.34-.84.45-.34.11-.72.17-1.15.17-.48 0-.95-.09-1.41-.27-.46-.19-.86-.41-1.2-.68z" fill="#535353"/></g></svg>"></a></div><div class="c-bibliographic-information__column"><h3 class="c-article__sub-heading" id="citeas">Cite this article</h3><p class="c-bibliographic-information__citation">Zhang, A., Xing, L., Zou, J. <i>et al.</i> Shifting machine learning for healthcare from development to deployment and from models to data.
                    <i>Nat. Biomed. Eng</i> <b>6</b>, 13301345 (2022). https://doi.org/10.1038/s41551-022-00898-y</p><p class="c-bibliographic-information__download-citation u-hide-print"><a data-test="citation-link" data-track="click" data-track-action="download article citation" data-track-label="link" data-track-external="" rel="nofollow" href="https://citation-needed.springer.com/v2/references/10.1038/s41551-022-00898-y?format=refman&amp;flavour=citation">Download citation<svg width="16" height="16" focusable="false" role="img" aria-hidden="true" class="u-icon"><use xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="#icon-eds-i-download-medium"></use></svg></a></p><ul class="c-bibliographic-information__list" data-test="publication-history"><li class="c-bibliographic-information__list-item"><p>Received<span class="u-hide">: </span><span class="c-bibliographic-information__value"><time datetime="2021-01-24">24 January 2021</time></span></p></li><li class="c-bibliographic-information__list-item"><p>Accepted<span class="u-hide">: </span><span class="c-bibliographic-information__value"><time datetime="2022-05-03">03 May 2022</time></span></p></li><li class="c-bibliographic-information__list-item"><p>Published<span class="u-hide">: </span><span class="c-bibliographic-information__value"><time datetime="2022-07-04">04 July 2022</time></span></p></li><li class="c-bibliographic-information__list-item"><p>Version of record<span class="u-hide">: </span><span class="c-bibliographic-information__value"><time datetime="2022-07-04">04 July 2022</time></span></p></li><li class="c-bibliographic-information__list-item"><p>Issue date<span class="u-hide">: </span><span class="c-bibliographic-information__value"><time datetime="2022-12">December 2022</time></span></p></li><li class="c-bibliographic-information__list-item c-bibliographic-information__list-item--full-width"><p><abbr title="Digital Object Identifier">DOI</abbr><span class="u-hide">: </span><span class="c-bibliographic-information__value">https://doi.org/10.1038/s41551-022-00898-y</span></p></li></ul><div data-component="share-box"><div class="c-article-share-box u-display-none" hidden=""><h3 class="c-article__sub-heading">Share this article</h3><p class="c-article-share-box__description">Anyone you share the following link with will be able to read this content:</p><button class="js-get-share-url c-article-share-box__button" type="button" id="get-share-url" data-track="click" data-track-label="button" data-track-external="" data-track-action="get shareable link">Get shareable link</button><div class="js-no-share-url-container u-display-none" hidden=""><p class="js-c-article-share-box__no-sharelink-info c-article-share-box__no-sharelink-info">Sorry, a shareable link is not currently available for this article.</p></div><div class="js-share-url-container u-display-none" hidden=""><p class="js-share-url c-article-share-box__only-read-input" id="share-url" data-track="click" data-track-label="button" data-track-action="select share url"></p><button class="js-copy-share-url c-article-share-box__button--link-like" type="button" id="copy-share-url" data-track="click" data-track-label="button" data-track-action="copy share url" data-track-external="">Copy shareable link to clipboard</button></div><p class="js-c-article-share-box__additional-info c-article-share-box__additional-info">
                            Provided by the Springer Nature SharedIt content-sharing initiative
                        </p></div></div><div data-component="article-info-list"></div></div></div></div></div></section>
            </div>

            
        <section>
            <div class="c-article-section js-article-section" id="further-reading-section" data-test="further-reading-section">
                <h2 class="c-article-section__title js-section-title js-c-reading-companion-sections-item" id="further-reading">This article is cited by</h2>
                <div class="c-article-section__content js-collapsible-section" id="further-reading-content">
                    <ul class="c-article-further-reading__list" id="further-reading-list">
                        
                            <li class="c-article-further-reading__item js-ref-item">
                            
                                <h3 class="c-article-further-reading__title" data-test="article-title">
                                    <a class="print-link" data-track="click" data-track-action="view further reading article"
                                       data-track-label="link:Postoperative fever following surgery for oral cancer: Incidence, risk factors, and the formulation of a machine learning-based predictive model" href="https://doi.org/10.1186/s12903-025-05555-9">
                                        Postoperative fever following surgery for oral cancer: Incidence, risk factors, and the formulation of a machine learning-based predictive model
                                    </a>
                                </h3>
                            
                                
                                    <ul data-test="author-list" class="app-author-list app-author-list--compact app-author-list--truncated u-sans-serif u-mb-4 u-mt-auto">
                                        <li>Yanling Zhang</li><li>Kun Long</li><li>Shuiting Zhang</li>
                                    </ul>
                                
                                <p class="c-article-further-reading__journal-title"><i>BMC Oral Health</i> (2025)</p>
                            </li>
                        
                            <li class="c-article-further-reading__item js-ref-item">
                            
                                <h3 class="c-article-further-reading__title" data-test="article-title">
                                    <a class="print-link" data-track="click" data-track-action="view further reading article"
                                       data-track-label="link:Externally validated and clinically useful machine learning algorithms to support patient-related decision-making in oncology: a scoping review" href="https://doi.org/10.1186/s12874-025-02463-y">
                                        Externally validated and clinically useful machine learning algorithms to support patient-related decision-making in oncology: a scoping review
                                    </a>
                                </h3>
                            
                                
                                    <ul data-test="author-list" class="app-author-list app-author-list--compact u-sans-serif u-mb-4 u-mt-auto">
                                        <li>Catarina Sousa Santos</li><li>Mrio Amorim-Lopes</li>
                                    </ul>
                                
                                <p class="c-article-further-reading__journal-title"><i>BMC Medical Research Methodology</i> (2025)</p>
                            </li>
                        
                            <li class="c-article-further-reading__item js-ref-item">
                            
                                <h3 class="c-article-further-reading__title" data-test="article-title">
                                    <a class="print-link" data-track="click" data-track-action="view further reading article"
                                       data-track-label="link:Machinometrics, a new framework towards explainable machine learning in healthcare" href="https://doi.org/10.1186/s44330-025-00031-w">
                                        Machinometrics, a new framework towards explainable machine learning in healthcare
                                    </a>
                                </h3>
                            
                                
                                    <ul data-test="author-list" class="app-author-list app-author-list--compact app-author-list--truncated u-sans-serif u-mb-4 u-mt-auto">
                                        <li>Jionghui Lin</li><li>Shwetha Hegde</li><li>Jinlong Gao</li>
                                    </ul>
                                
                                <p class="c-article-further-reading__journal-title"><i>BMC Methods</i> (2025)</p>
                            </li>
                        
                            <li class="c-article-further-reading__item js-ref-item">
                            
                                <h3 class="c-article-further-reading__title" data-test="article-title">
                                    <a class="print-link" data-track="click" data-track-action="view further reading article"
                                       data-track-label="link:Identification of risk factors for latent tuberculosis infection in Xinjiang using machine learning" href="https://doi.org/10.1186/s12889-025-25844-w">
                                        Identification of risk factors for latent tuberculosis infection in Xinjiang using machine learning
                                    </a>
                                </h3>
                            
                                
                                    <ul data-test="author-list" class="app-author-list app-author-list--compact app-author-list--truncated u-sans-serif u-mb-4 u-mt-auto">
                                        <li>YanJie Wang</li><li>Zhen Luo</li><li>Yang Xiang</li>
                                    </ul>
                                
                                <p class="c-article-further-reading__journal-title"><i>BMC Public Health</i> (2025)</p>
                            </li>
                        
                            <li class="c-article-further-reading__item js-ref-item">
                            
                                <h3 class="c-article-further-reading__title" data-test="article-title">
                                    <a class="print-link" data-track="click" data-track-action="view further reading article"
                                       data-track-label="link:Application of the random forest algorithm to predict skilled birth attendance and identify determinants among reproductive-age women in 27 Sub-Saharan African countries; machine learning analysis" href="https://doi.org/10.1186/s12889-025-22007-9">
                                        Application of the random forest algorithm to predict skilled birth attendance and identify determinants among reproductive-age women in 27 Sub-Saharan African countries; machine learning analysis
                                    </a>
                                </h3>
                            
                                
                                    <ul data-test="author-list" class="app-author-list app-author-list--compact app-author-list--truncated u-sans-serif u-mb-4 u-mt-auto">
                                        <li>Eliyas Addisu Taye</li><li>Eden Yitbarek Woubet</li><li>Abel Temeche Kassaw</li>
                                    </ul>
                                
                                <p class="c-article-further-reading__journal-title"><i>BMC Public Health</i> (2025)</p>
                            </li>
                        
                    </ul>
                </div>
            </div>
        </section>
    
            

        </div>
</article>
</main>

<aside class="c-article-extras u-hide-print" aria-label="Article navigation" data-component-reading-companion data-container-type="reading-companion" data-track-component="reading companion">
    <div class="u-mb-48 js-context-bar-sticky-point-desktop" data-track-context="reading companion">
        

        
            
                <div class="c-nature-box__wrapper c-nature-box__wrapper--placeholder">
                        
        <div class="c-nature-box c-nature-box--side " data-test="entitlement-box">
        
            <div>
                <a href="https://wayf.springernature.com?redirect_uri&#x3D;https%3A%2F%2Fwww.nature.com%2Farticles%2Fs41551-022-00898-y" class="c-article__button" data-test="ra21">
                    <svg class="u-icon" width="18" height="18" aria-hidden="true" focusable="false"><use href="#icon-institution"></use></svg>
                    <span class="c-article__button-text">Access through your institution</span>
                </a>
            </div>
        
        
            
                <div data-test="entitlement-box-buy-button">
                    <a href="#access-options" class="c-article__button c-article__button--inverted" data-test="ra21">
                        <span>Buy or subscribe</span>
                    </a>
                </div>
            
        
        </div>
    

                </div>
            
        
    </div>

    
        
    

    
    
        <div class="c-article-associated-content__container">
            <section>
                <h2 class="c-article-associated-content__title u-mb-24">Associated content</h2>
                
                    
                        <div class="c-article-associated-content__collection collection u-mb-24">
                            <section>
                                <p class="c-article-associated-content__collection-label u-sans-serif u-text-bold u-mb-8">Collection</p>
                                <h3 class="c-article-associated-content__collection-title u-h3 u-mb-8">
                                    <a href="https://www.nature.com/collections/dedffgdgjf"
                                       class="u-link-inherit"
                                       data-track="click"
                                       data-track-action="view collection"
                                       data-track-category="associated content"
                                       data-track-label="collection"
                                       data-test="collection-link">Electrical Engineering</a>
                                </h3>
                            </section>
                        </div>
                    
                        <div class="c-article-associated-content__collection collection u-mb-24">
                            <section>
                                <p class="c-article-associated-content__collection-label u-sans-serif u-text-bold u-mb-8">Collection</p>
                                <h3 class="c-article-associated-content__collection-title u-h3 u-mb-8">
                                    <a href="https://www.nature.com/collections/zbkpvddmhm"
                                       class="u-link-inherit"
                                       data-track="click"
                                       data-track-action="view collection"
                                       data-track-category="associated content"
                                       data-track-label="collection"
                                       data-test="collection-link">Machine learning in healthcare</a>
                                </h3>
                            </section>
                        </div>
                    
                    
                
            </section>
        </div>
        <script>
            window.dataLayer = window.dataLayer || [];
            window.dataLayer[0] = window.dataLayer[0] || {};
            window.dataLayer[0].content = window.dataLayer[0].content || {};
            window.dataLayer[0].content.associatedContentTypes = "collection;collection";
            window.dataLayer[0].content.collections = "dedffgdgjf;zbkpvddmhm";
        </script>
    

    

    <div class="c-reading-companion">
        <div class="c-reading-companion__sticky" data-component="reading-companion-sticky" data-test="reading-companion-sticky">
            <div class="c-reading-companion__panel c-reading-companion__sections c-reading-companion__panel--active" id="tabpanel-sections">
                <div class="u-lazy-ad-wrapper u-mt-16 u-hide" data-component-mpu>
                    <div class="c-ad c-ad--300x250">
                        <div class="c-ad__inner">
                            <p class="c-ad__label">Advertisement</p>
                            
    <div id="div-gpt-ad-right-2"
         class="div-gpt-ad advert medium-rectangle js-ad text-center hide-print grade-c-hide"
         data-ad-type="right"
         data-test="right-ad"
         data-pa11y-ignore
         data-gpt
         data-gpt-unitpath="/285/natbiomedeng.nature.com/article"
         data-gpt-sizes="300x250"
         data-gpt-targeting="type=article;pos=right;artid=s41551-022-00898-y;doi=10.1038/s41551-022-00898-y;subjmeta=1042,114,1305,1421,166,308,575,631,639,692,700,705,985;kwrd=Biomedical+engineering,Computational+science,Machine+learning,Medical+imaging,Translational+research">
        
        <script>
            window.SN = window.SN || {};
            window.SN.libs = window.SN.libs || {};
            window.SN.libs.ads = window.SN.libs.ads || {};
            window.SN.libs.ads.slotConfig = window.SN.libs.ads.slotConfig || {};
            
                window.SN.libs.ads.slotConfig['right'] = {
                    'pos': 'right',
                    'type': 'article',
                    'path': 's41551-022-00898-y'
                };
            
            
            window.SN.libs.ads.slotConfig['kwrd'] = 'Biomedical+engineering,Computational+science,Machine+learning,Medical+imaging,Translational+research';
            
            
            window.SN.libs.ads.slotConfig['subjmeta'] = '1042,114,1305,1421,166,308,575,631,639,692,700,705,985';
            
            
        </script>
        <noscript>
            <a href="//pubads.g.doubleclick.net/gampad/jump?iu=/285/natbiomedeng.nature.com/article&amp;sz=300x250&amp;c=103663721&amp;t=pos%3Dright%26type%3Darticle%26artid%3Ds41551-022-00898-y%26doi%3D10.1038/s41551-022-00898-y%26subjmeta%3D1042,114,1305,1421,166,308,575,631,639,692,700,705,985%26kwrd%3DBiomedical+engineering,Computational+science,Machine+learning,Medical+imaging,Translational+research">
                <img data-test="gpt-advert-fallback-img"
                     src="//pubads.g.doubleclick.net/gampad/ad?iu=/285/natbiomedeng.nature.com/article&amp;sz=300x250&amp;c=103663721&amp;t=pos%3Dright%26type%3Darticle%26artid%3Ds41551-022-00898-y%26doi%3D10.1038/s41551-022-00898-y%26subjmeta%3D1042,114,1305,1421,166,308,575,631,639,692,700,705,985%26kwrd%3DBiomedical+engineering,Computational+science,Machine+learning,Medical+imaging,Translational+research"
                     alt="Advertisement"
                     width="300"
                     height="250"></a>
        </noscript>
    </div>

                        </div>
                    </div>
                </div>
            </div>
            <div class="c-reading-companion__panel c-reading-companion__figures c-reading-companion__panel--full-width" id="tabpanel-figures"></div>
            <div class="c-reading-companion__panel c-reading-companion__references c-reading-companion__panel--full-width" id="tabpanel-references"></div>
        </div>
    </div>
</aside>
</div>


    
        <nav class="c-header__dropdown" aria-labelledby="Explore-content" data-test="Explore-content" id="explore" data-track-component="nature-150-split-header">
            <div class="c-header__container">
                <h2 id="Explore-content" class="c-header__heading c-header__heading--js-hide">Explore content</h2>
                <ul class="c-header__list c-header__list--js-stack">
                    
                        
                            <li class="c-header__item">
                                <a class="c-header__link"
                                   href="/natbiomedeng/research-articles"
                                   data-track="click"
                                   data-track-action="research articles"
                                   data-track-label="link"
                                   data-test="explore-nav-item">
                                    Research articles
                                </a>
                            </li>
                        
                            <li class="c-header__item">
                                <a class="c-header__link"
                                   href="/natbiomedeng/reviews-and-analysis"
                                   data-track="click"
                                   data-track-action="reviews &amp; analysis"
                                   data-track-label="link"
                                   data-test="explore-nav-item">
                                    Reviews &amp; Analysis
                                </a>
                            </li>
                        
                            <li class="c-header__item">
                                <a class="c-header__link"
                                   href="/natbiomedeng/news-and-comment"
                                   data-track="click"
                                   data-track-action="news &amp; comment"
                                   data-track-label="link"
                                   data-test="explore-nav-item">
                                    News &amp; Comment
                                </a>
                            </li>
                        
                            <li class="c-header__item">
                                <a class="c-header__link"
                                   href="/natbiomedeng/videos"
                                   data-track="click"
                                   data-track-action="videos"
                                   data-track-label="link"
                                   data-test="explore-nav-item">
                                    Videos
                                </a>
                            </li>
                        
                            <li class="c-header__item">
                                <a class="c-header__link"
                                   href="/natbiomedeng/current-issue"
                                   data-track="click"
                                   data-track-action="current issue"
                                   data-track-label="link"
                                   data-test="explore-nav-item">
                                    Current issue
                                </a>
                            </li>
                        
                            <li class="c-header__item">
                                <a class="c-header__link"
                                   href="/natbiomedeng/collections"
                                   data-track="click"
                                   data-track-action="collections"
                                   data-track-label="link"
                                   data-test="explore-nav-item">
                                    Collections
                                </a>
                            </li>
                        
                    
                </ul>
                <ul class="c-header__list c-header__list--js-stack">
                    
                        <li class="c-header__item">
                            <a class="c-header__link"
                               href="https://www.facebook.com/natBME"
                               data-track="click"
                               data-track-action="facebook"
                               data-track-label="link">Follow us on Facebook
                            </a>
                        </li>
                    
                    
                        <li class="c-header__item">
                            <a class="c-header__link"
                               href="https://twitter.com/natBME"
                               data-track="click"
                               data-track-action="twitter"
                               data-track-label="link">Follow us on Twitter
                            </a>
                        </li>
                    
                    
                        <li class="c-header__item c-header__item--hide-lg">
                            <a data-test="subscribe-button" class="c-header__link"
                               href="https://www.nature.com/natbiomedeng/subscribe"
                               data-track="click"
                               data-track-action="subscribe"
                               data-track-label="link">
                                <span>Subscribe</span>
                            </a>
                        </li>
                    
                    
                        <li class="c-header__item c-header__item--hide-lg">
                            <a class="c-header__link"
                               href="https://journal-alerts.springernature.com/subscribe?journal_id&#x3D;41551"
                               rel="nofollow"
                               data-track="nav_sign_up_for_alerts"
                               data-track-action="Sign up for alerts"
                               data-track-external
                               data-track-label="link (mobile dropdown)">Sign up for alerts<svg role="img" aria-hidden="true" focusable="false" height="18" viewBox="0 0 18 18" width="18" xmlns="http://www.w3.org/2000/svg"><path d="m4 10h2.5c.27614237 0 .5.2238576.5.5s-.22385763.5-.5.5h-3.08578644l-1.12132034 1.1213203c-.18753638.1875364-.29289322.4418903-.29289322.7071068v.1715729h14v-.1715729c0-.2652165-.1053568-.5195704-.2928932-.7071068l-1.7071068-1.7071067v-3.4142136c0-2.76142375-2.2385763-5-5-5-2.76142375 0-5 2.23857625-5 5zm3 4c0 1.1045695.8954305 2 2 2s2-.8954305 2-2zm-5 0c-.55228475 0-1-.4477153-1-1v-.1715729c0-.530433.21071368-1.0391408.58578644-1.4142135l1.41421356-1.4142136v-3c0-3.3137085 2.6862915-6 6-6s6 2.6862915 6 6v3l1.4142136 1.4142136c.3750727.3750727.5857864.8837805.5857864 1.4142135v.1715729c0 .5522847-.4477153 1-1 1h-4c0 1.6568542-1.3431458 3-3 3-1.65685425 0-3-1.3431458-3-3z" fill="#fff"/></svg>
                            </a>
                        </li>
                    
                    
                        <li class="c-header__item c-header__item--hide-lg">
                            <a class="c-header__link"
                               href="https://www.nature.com/natbiomedeng.rss"
                               data-track="click"
                               data-track-action="rss feed"
                               data-track-label="link">
                                <span>RSS feed</span>
                            </a>
                        </li>
                    
                </ul>
            </div>
        </nav>
    
    
        
            <nav class="c-header__dropdown" aria-labelledby="About-the-journal" id="about-the-journal" data-test="about-the-journal" data-track-component="nature-150-split-header">
                <div class="c-header__container">
                    <h2 id="About-the-journal" class="c-header__heading c-header__heading--js-hide">About the journal</h2>
                    <ul class="c-header__list c-header__list--js-stack">
                        
                            <li class="c-header__item">
                                <a class="c-header__link"
                                   href="/natbiomedeng/aims"
                                   data-track="click"
                                   data-track-action="aims &amp; scope"
                                   data-track-label="link">
                                    Aims &amp; Scope
                                </a>
                            </li>
                        
                            <li class="c-header__item">
                                <a class="c-header__link"
                                   href="/natbiomedeng/journal-information"
                                   data-track="click"
                                   data-track-action="journal information"
                                   data-track-label="link">
                                    Journal Information
                                </a>
                            </li>
                        
                            <li class="c-header__item">
                                <a class="c-header__link"
                                   href="/natbiomedeng/journal-impact"
                                   data-track="click"
                                   data-track-action="journal metrics"
                                   data-track-label="link">
                                    Journal Metrics
                                </a>
                            </li>
                        
                            <li class="c-header__item">
                                <a class="c-header__link"
                                   href="/natbiomedeng/editors"
                                   data-track="click"
                                   data-track-action="about the editors"
                                   data-track-label="link">
                                    About the Editors
                                </a>
                            </li>
                        
                            <li class="c-header__item">
                                <a class="c-header__link"
                                   href="/natbiomedeng/research-cross-journal-editorial-team"
                                   data-track="click"
                                   data-track-action="research cross-journal editorial team"
                                   data-track-label="link">
                                    Research Cross-Journal Editorial Team
                                </a>
                            </li>
                        
                            <li class="c-header__item">
                                <a class="c-header__link"
                                   href="/natbiomedeng/reviews-cross-journal-editorial-team"
                                   data-track="click"
                                   data-track-action="reviews cross-journal editorial team"
                                   data-track-label="link">
                                    Reviews Cross-Journal Editorial Team
                                </a>
                            </li>
                        
                            <li class="c-header__item">
                                <a class="c-header__link"
                                   href="/natbiomedeng/our-publishing-models"
                                   data-track="click"
                                   data-track-action="our publishing models"
                                   data-track-label="link">
                                    Our publishing models
                                </a>
                            </li>
                        
                            <li class="c-header__item">
                                <a class="c-header__link"
                                   href="/natbiomedeng/editorial-values-statement"
                                   data-track="click"
                                   data-track-action="editorial values statement"
                                   data-track-label="link">
                                    Editorial Values Statement
                                </a>
                            </li>
                        
                            <li class="c-header__item">
                                <a class="c-header__link"
                                   href="/natbiomedeng/editorial-policies"
                                   data-track="click"
                                   data-track-action="editorial policies"
                                   data-track-label="link">
                                    Editorial Policies
                                </a>
                            </li>
                        
                            <li class="c-header__item">
                                <a class="c-header__link"
                                   href="/natbiomedeng/content"
                                   data-track="click"
                                   data-track-action="content types"
                                   data-track-label="link">
                                    Content Types
                                </a>
                            </li>
                        
                            <li class="c-header__item">
                                <a class="c-header__link"
                                   href="/natbiomedeng/contact"
                                   data-track="click"
                                   data-track-action="contact"
                                   data-track-label="link">
                                    Contact
                                </a>
                            </li>
                        
                    </ul>
                </div>
            </nav>
        

        
            <nav class="c-header__dropdown" aria-labelledby="Publish-with-us-label" id="publish-with-us" data-test="publish-with-us" data-track-component="nature-150-split-header">
                <div class="c-header__container">
                    <h2 id="Publish-with-us-label" class="c-header__heading c-header__heading--js-hide">Publish with us</h2>
                    <ul class="c-header__list c-header__list--js-stack">
                        
                            <li class="c-header__item">
                                <a class="c-header__link"
                                   href="/natbiomedeng/submission-guidelines"
                                   data-track="click"
                                   data-track-action="submission guidelines"
                                   data-track-label="link">
                                    Submission Guidelines
                                </a>
                            </li>
                        
                            <li class="c-header__item">
                                <a class="c-header__link"
                                   href="/natbiomedeng/for-reviewers"
                                   data-track="click"
                                   data-track-action="for reviewers"
                                   data-track-label="link">
                                    For Reviewers
                                </a>
                            </li>
                        
                        
                            <li class="c-header__item">
                                <a class="c-header__link" data-test="nature-author-services"
                                   data-track="nav_language_services"
                                   data-track-context="header publish with us dropdown menu"
                                   data-track-action="manuscript author services"
                                   data-track-label="link manuscript author services"
                                   href="https://authorservices.springernature.com/go/sn/?utm_source=For+Authors&utm_medium=Website_Nature&utm_campaign=Platform+Experimentation+2022&utm_id=PE2022">
                                    Language editing services
                                </a>
                            </li>
                        
                        
                            <li class="c-header__item">
                                <a class="c-header__link"
                                   href="/natbiomedeng/open-access-funding"
                                   data-test="funding-eligibility-link"
                                   data-track="click_explore_funding"
                                   data-track-context="header publish with us"
                                   data-track-action="funding eligibility">Open access funding</a>
                            </li>
                        
                        
                            <li class="c-header__item c-header__item--keyline">
                                <a class="c-header__link"
                                   href="https://mts-natbiomedeng.nature.com"
                                   data-track="click_submit_manuscript"
                                   data-track-context="submit link in Nature header dropdown menu"
                                   data-track-action="submit manuscript"
                                   data-track-label="link (publish with us dropdown menu)"
                                   data-track-external
                                   data-gtm-criteo="submit-manuscript">Submit manuscript<svg role="img" aria-hidden="true" focusable="false" height="18" viewBox="0 0 18 18" width="18" xmlns="http://www.w3.org/2000/svg"><path d="m15 0c1.1045695 0 2 .8954305 2 2v5.5c0 .27614237-.2238576.5-.5.5s-.5-.22385763-.5-.5v-5.5c0-.51283584-.3860402-.93550716-.8833789-.99327227l-.1166211-.00672773h-9v3c0 1.1045695-.8954305 2-2 2h-3v10c0 .5128358.38604019.9355072.88337887.9932723l.11662113.0067277h7.5c.27614237 0 .5.2238576.5.5s-.22385763.5-.5.5h-7.5c-1.1045695 0-2-.8954305-2-2v-10.17157288c0-.53043297.21071368-1.0391408.58578644-1.41421356l3.82842712-3.82842712c.37507276-.37507276.88378059-.58578644 1.41421356-.58578644zm-.5442863 8.18867991 3.3545404 3.35454039c.2508994.2508994.2538696.6596433.0035959.909917-.2429543.2429542-.6561449.2462671-.9065387-.0089489l-2.2609825-2.3045251.0010427 7.2231989c0 .3569916-.2898381.6371378-.6473715.6371378-.3470771 0-.6473715-.2852563-.6473715-.6371378l-.0010428-7.2231995-2.2611222 2.3046654c-.2531661.2580415-.6562868.2592444-.9065605.0089707-.24295423-.2429542-.24865597-.6576651.0036132-.9099343l3.3546673-3.35466731c.2509089-.25090888.6612706-.25227691.9135302-.00001728zm-.9557137-3.18867991c.2761424 0 .5.22385763.5.5s-.2238576.5-.5.5h-6c-.27614237 0-.5-.22385763-.5-.5s.22385763-.5.5-.5zm-8.5-3.587-3.587 3.587h2.587c.55228475 0 1-.44771525 1-1zm8.5 1.587c.2761424 0 .5.22385763.5.5s-.2238576.5-.5.5h-6c-.27614237 0-.5-.22385763-.5-.5s.22385763-.5.5-.5z" fill="#fff"/></svg>
                                </a>
                            </li>
                        
                    </ul>
                </div>
            </nav>
        
    
    <script>
        window.dataLayer = window.dataLayer || [];
        window.dataLayer.push({
            page: {
                content: {
                    fundingWidget: "true",
                        }
                    }
                });
    </script>


<div id="search-menu" class="c-header__dropdown c-header__dropdown--full-width" data-track-component="nature-150-split-header">
    <div class="c-header__container">
        <h2 class="c-header__visually-hidden">Search</h2>
        <form class="c-header__search-form" action="/search" method="get" role="search" autocomplete="off" data-test="inline-search">
            <label class="c-header__heading" for="keywords">Search articles by subject, keyword or author</label>
            <div class="c-header__search-layout c-header__search-layout--max-width">
                <div>
                    <input type="text" required="" class="c-header__input" id="keywords" name="q" value="">
                </div>
                <div class="c-header__search-layout">
                    <div>
                        <label for="results-from" class="c-header__visually-hidden">Show results from</label>
                        <select id="results-from" name="journal" class="c-header__select">
                            
                                
                                    <option value="" selected>All journals</option>
                                    <option value="natbiomedeng">This journal</option>
                                
                            
                        </select>
                    </div>
                    <div>
                        <button type="submit" class="c-header__search-button">Search</button>
                    </div>
                </div>

            </div>
        </form>

        <div class="c-header__flush">
            <a class="c-header__link" href="/search/advanced"
               data-track="click" data-track-action="advanced search" data-track-label="link">
                Advanced search
            </a>
        </div>

        <h3 class="c-header__heading c-header__heading--keyline">Quick links</h3>
        <ul class="c-header__list">
            <li><a class="c-header__link" href="/subjects" data-track="click" data-track-action="explore articles by subject" data-track-label="link">Explore articles by subject</a></li>
            <li><a class="c-header__link" href="/naturecareers" data-track="click" data-track-action="find a job" data-track-label="link">Find a job</a></li>
            <li><a class="c-header__link" href="/authors/index.html" data-track="click" data-track-action="guide to authors" data-track-label="link">Guide to authors</a></li>
            <li><a class="c-header__link" href="/authors/editorial_policies/" data-track="click" data-track-action="editorial policies" data-track-label="link">Editorial policies</a></li>
        </ul>
    </div>
</div>

<footer class="composite-layer" itemscope itemtype="http://schema.org/Periodical">
        <meta itemprop="publisher" content="Springer Nature">
        

        <div class="u-mt-16 u-mb-16">
    <div class="u-container">
        <div class="u-display-flex u-flex-wrap u-justify-content-space-between">
            

            <div class="c-meta u-ma-0 u-flex-shrink">
                <p class="c-meta__item c-meta__type u-mt-0">
                    <span itemprop="name">
                        Nature Biomedical Engineering
                    </span>
                    (<i itemprop="alternateName">Nat. Biomed. Eng</i>)
                </p>
                
    
        <p class="c-meta__item u-mt-0">
            <abbr title="International Standard Serial Number">ISSN</abbr> <span itemprop="issn">2157-846X</span> (online)
        </p>
    

                
    

            </div>
        </div>
    </div>
</div>

    <div class="c-footer">
        <div class="u-hide-print" data-track-component="footer">
    <h2 class="u-visually-hidden">nature.com sitemap</h2>
    <div class="c-footer__container">
        <div class="c-footer__grid c-footer__group--separator">
            <div class="c-footer__group">
                <h3 class="c-footer__heading u-mt-0">About Nature Portfolio</h3>
                <ul class="c-footer__list">
                    <li class="c-footer__item"><a class="c-footer__link"
                                                  href="https://www.nature.com/npg_/company_info/index.html"
                                                  data-track="click" data-track-action="about us"
                                                  data-track-label="link">About us</a></li>
                    <li class="c-footer__item"><a class="c-footer__link"
                                                  href="https://www.nature.com/npg_/press_room/press_releases.html"
                                                  data-track="click" data-track-action="press releases"
                                                  data-track-label="link">Press releases</a></li>
                    <li class="c-footer__item"><a class="c-footer__link" href="https://press.nature.com/"
                                                  data-track="click" data-track-action="press office"
                                                  data-track-label="link">Press office</a></li>
                    <li class="c-footer__item"><a class="c-footer__link" href="https://support.nature.com/support/home"
                                                  data-track="click" data-track-action="contact us"
                                                  data-track-label="link">Contact us</a></li>
                </ul>
            </div>

            <div class="c-footer__group">
                <h3 class="c-footer__heading u-mt-0">Discover content</h3>
                <ul class="c-footer__list">
                    <li class="c-footer__item"><a class="c-footer__link" href="https://www.nature.com/siteindex"
                                                  data-track="click" data-track-action="journals a-z"
                                                  data-track-label="link">Journals A-Z</a></li>
                    <li class="c-footer__item"><a class="c-footer__link" href="https://www.nature.com/subjects"
                                                  data-track="click" data-track-action="article by subject"
                                                  data-track-label="link">Articles by subject</a></li>
                    <li class="c-footer__item"><a class="c-footer__link" href="https://www.protocols.io/"
                                                  data-track="click" data-track-action="protocols.io"
                                                  data-track-label="link">protocols.io</a></li>
                    <li class="c-footer__item"><a class="c-footer__link" href="https://www.natureindex.com/"
                                                  data-track="click" data-track-action="nature index"
                                                  data-track-label="link">Nature Index</a></li>
                </ul>
            </div>

            <div class="c-footer__group">
                <h3 class="c-footer__heading u-mt-0">Publishing policies</h3>
                <ul class="c-footer__list">
                    <li class="c-footer__item"><a class="c-footer__link"
                                                  href="https://www.nature.com/authors/editorial_policies"
                                                  data-track="click" data-track-action="Nature portfolio policies"
                                                  data-track-label="link">Nature portfolio policies</a></li>
                    <li class="c-footer__item"><a class="c-footer__link"
                                                  href="https://www.nature.com/nature-research/open-access"
                                                  data-track="click" data-track-action="open access"
                                                  data-track-label="link">Open access</a></li>
                </ul>
            </div>

            <div class="c-footer__group">
                <h3 class="c-footer__heading u-mt-0">Author &amp; Researcher services</h3>
                <ul class="c-footer__list">
                    <li class="c-footer__item"><a class="c-footer__link" href="https://www.nature.com/reprints"
                                                  data-track="click" data-track-action="reprints and permissions"
                                                  data-track-label="link">Reprints &amp; permissions</a></li>
                    <li class="c-footer__item"><a class="c-footer__link"
                                                  href="https://www.springernature.com/gp/authors/research-data"
                                                  data-track="click" data-track-action="data research service"
                                                  data-track-label="link">Research data</a></li>
                    <li class="c-footer__item"><a class="c-footer__link"
                                                  href="https://authorservices.springernature.com/language-editing/"
                                                  data-track="click" data-track-action="language editing"
                                                  data-track-label="link">Language editing</a></li>
                    <li class="c-footer__item"><a class="c-footer__link"
                                                  href="https://authorservices.springernature.com/scientific-editing/"
                                                  data-track="click" data-track-action="scientific editing"
                                                  data-track-label="link">Scientific editing</a></li>
                    <li class="c-footer__item"><a class="c-footer__link" href="https://masterclasses.nature.com/"
                                                  data-track="click" data-track-action="nature masterclasses"
                                                  data-track-label="link">Nature Masterclasses</a></li>
                    <li class="c-footer__item"><a class="c-footer__link" href="https://solutions.springernature.com/"
                                                  data-track="click" data-track-action="research solutions"
                                                  data-track-label="link">Research Solutions</a></li>
                </ul>
            </div>

            <div class="c-footer__group">
                <h3 class="c-footer__heading u-mt-0">Libraries &amp; institutions</h3>
                <ul class="c-footer__list">
                    <li class="c-footer__item"><a class="c-footer__link"
                                                  href="https://www.springernature.com/gp/librarians/tools-services"
                                                  data-track="click" data-track-action="librarian service and tools"
                                                  data-track-label="link">Librarian service &amp; tools</a></li>
                    <li class="c-footer__item"><a class="c-footer__link"
                                                  href="https://www.springernature.com/gp/librarians/manage-your-account/librarianportal"
                                                  data-track="click" data-track-action="librarian portal"
                                                  data-track-label="link">Librarian portal</a></li>
                    <li class="c-footer__item"><a class="c-footer__link"
                                                  href="https://www.nature.com/openresearch/about-open-access/information-for-institutions"
                                                  data-track="click" data-track-action="open research"
                                                  data-track-label="link">Open research</a></li>
                    <li class="c-footer__item"><a class="c-footer__link"
                                                  href="https://www.springernature.com/gp/librarians/recommend-to-your-library"
                                                  data-track="click" data-track-action="Recommend to library"
                                                  data-track-label="link">Recommend to library</a></li>
                </ul>
            </div>

            <div class="c-footer__group">
                <h3 class="c-footer__heading u-mt-0">Advertising &amp; partnerships</h3>
                <ul class="c-footer__list">
                    <li class="c-footer__item"><a class="c-footer__link"
                                                  href="https://partnerships.nature.com/product/digital-advertising/"
                                                  data-track="click" data-track-action="advertising"
                                                  data-track-label="link">Advertising</a></li>
                    <li class="c-footer__item"><a class="c-footer__link" href="https://partnerships.nature.com/"
                                                  data-track="click" data-track-action="partnerships and services"
                                                  data-track-label="link">Partnerships &amp; Services</a></li>
                    <li class="c-footer__item"><a class="c-footer__link"
                                                  href="https://partnerships.nature.com/media-kits/" data-track="click"
                                                  data-track-action="media kits" data-track-label="link">Media kits</a>
                    </li>
                    <li class="c-footer__item"><a class="c-footer__link"
                                                  href="https://partnerships.nature.com/product/branded-content-native-advertising/"
                                                  data-track-action="branded content" data-track-label="link">Branded
                        content</a></li>
                </ul>
            </div>

            <div class="c-footer__group">
                <h3 class="c-footer__heading u-mt-0">Professional development</h3>
                <ul class="c-footer__list">
                    <li class="c-footer__item"><a class="c-footer__link" href="https://www.nature.com/immersive/natureawards/index.html"
                                                  data-track="click" data-track-action="nature awards"
                                                  data-track-label="link">Nature Awards</a></li>
                    <li class="c-footer__item"><a class="c-footer__link" href="https://www.nature.com/naturecareers/"
                                                  data-track="click" data-track-action="nature careers"
                                                  data-track-label="link">Nature Careers</a></li>
                    <li class="c-footer__item"><a class="c-footer__link" href="https://conferences.nature.com"
                                                  data-track="click" data-track-action="nature conferences"
                                                  data-track-label="link">Nature<span class="u-visually-hidden"> </span>
                        Conferences</a></li>
                </ul>
            </div>

            <div class="c-footer__group">
                <h3 class="c-footer__heading u-mt-0">Regional websites</h3>
                <ul class="c-footer__list">
                    <li class="c-footer__item"><a class="c-footer__link" href="https://www.nature.com/natafrica"
                                                  data-track="click" data-track-action="nature africa"
                                                  data-track-label="link">Nature Africa</a></li>
                    <li class="c-footer__item"><a class="c-footer__link" href="http://www.naturechina.com"
                                                  data-track="click" data-track-action="nature china"
                                                  data-track-label="link">Nature China</a></li>
                    <li class="c-footer__item"><a class="c-footer__link" href="https://www.nature.com/nindia"
                                                  data-track="click" data-track-action="nature india"
                                                  data-track-label="link">Nature India</a></li>
                    <li class="c-footer__item"><a class="c-footer__link" href="https://www.natureasia.com/ja-jp"
                                                  data-track="click" data-track-action="nature japan"
                                                  data-track-label="link">Nature Japan</a></li>
                    <li class="c-footer__item"><a class="c-footer__link" href="https://www.nature.com/nmiddleeast"
                                                  data-track="click" data-track-action="nature middle east"
                                                  data-track-label="link">Nature Middle East</a></li>
                </ul>
            </div>

        </div>
    </div>
    <div class="c-footer__container">
        <ul class="c-footer__links">
            <li class="c-footer__item"><a class="c-footer__link" href="https://www.nature.com/info/privacy"
                                          data-track="click" data-track-action="privacy policy" data-track-label="link">Privacy
                Policy</a></li>
            <li class="c-footer__item"><a class="c-footer__link" href="https://www.nature.com/info/cookies"
                                          data-track="click" data-track-action="use of cookies" data-track-label="link">Use
                of cookies</a></li>
            <li class="c-footer__item">
                <button class="optanon-toggle-display c-footer__link" onclick="javascript:;"
                        data-cc-action="preferences" data-track="click" data-track-action="manage cookies"
                        data-track-label="link">Your privacy choices/Manage cookies
                </button>
            </li>
            <li class="c-footer__item"><a class="c-footer__link" href="https://www.nature.com/info/legal-notice"
                                          data-track="click" data-track-action="legal notice" data-track-label="link">Legal
                notice</a></li>
            <li class="c-footer__item"><a class="c-footer__link"
                                          href="https://www.nature.com/info/accessibility-statement" data-track="click"
                                          data-track-action="accessibility statement" data-track-label="link">Accessibility
                statement</a></li>
            <li class="c-footer__item"><a class="c-footer__link" href="https://www.nature.com/info/terms-and-conditions"
                                          data-track="click" data-track-action="terms and conditions"
                                          data-track-label="link">Terms &amp; Conditions</a></li>
            <li class="c-footer__item"><a class="c-footer__link" href="https://www.springernature.com/ccpa"
                                          data-track="click" data-track-action="california privacy statement"
                                          data-track-label="link">Your US state privacy rights</a></li>
            
        </ul>
    </div>
</div>


        <div class="c-footer__container">
    <a href="https://www.springernature.com/" class="c-footer__link">
        <img src="/static/images/logos/sn-logo-white-ea63208b81.svg" alt="Springer Nature" loading="lazy" width="200" height="20"/>
    </a>
    <p class="c-footer__legal" data-test="copyright">&copy; 2026 Springer Nature Limited</p>
</div>

    </div>
    <div class="u-visually-hidden" aria-hidden="true">
    
    <svg xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink"><defs><path id="a" d="M0 .74h56.72v55.24H0z"/></defs><symbol id="icon-access" viewBox="0 0 18 18"><path d="m14 8c.5522847 0 1 .44771525 1 1v7h2.5c.2761424 0 .5.2238576.5.5v1.5h-18v-1.5c0-.2761424.22385763-.5.5-.5h2.5v-7c0-.55228475.44771525-1 1-1s1 .44771525 1 1v6.9996556h8v-6.9996556c0-.55228475.4477153-1 1-1zm-8 0 2 1v5l-2 1zm6 0v7l-2-1v-5zm-2.42653766-7.59857636 7.03554716 4.92488299c.4162533.29137735.5174853.86502537.226108 1.28127873-.1721584.24594054-.4534847.39241464-.7536934.39241464h-14.16284822c-.50810197 0-.92-.41189803-.92-.92 0-.30020869.1464741-.58153499.39241464-.75369337l7.03554714-4.92488299c.34432015-.2410241.80260453-.2410241 1.14692468 0zm-.57346234 2.03988748-3.65526982 2.55868888h7.31053962z" fill-rule="evenodd"/></symbol><symbol id="icon-account" viewBox="0 0 18 18"><path d="m10.2379028 16.9048051c1.3083556-.2032362 2.5118471-.7235183 3.5294683-1.4798399-.8731327-2.5141501-2.0638925-3.935978-3.7673711-4.3188248v-1.27684611c1.1651924-.41183641 2-1.52307546 2-2.82929429 0-1.65685425-1.3431458-3-3-3-1.65685425 0-3 1.34314575-3 3 0 1.30621883.83480763 2.41745788 2 2.82929429v1.27684611c-1.70347856.3828468-2.89423845 1.8046747-3.76737114 4.3188248 1.01762123.7563216 2.22111275 1.2766037 3.52946833 1.4798399.40563808.0629726.81921174.0951949 1.23790281.0951949s.83226473-.0322223 1.2379028-.0951949zm4.3421782-2.1721994c1.4927655-1.4532925 2.419919-3.484675 2.419919-5.7326057 0-4.418278-3.581722-8-8-8s-8 3.581722-8 8c0 2.2479307.92715352 4.2793132 2.41991895 5.7326057.75688473-2.0164459 1.83949951-3.6071894 3.48926591-4.3218837-1.14534283-.70360829-1.90918486-1.96796271-1.90918486-3.410722 0-2.209139 1.790861-4 4-4s4 1.790861 4 4c0 1.44275929-.763842 2.70711371-1.9091849 3.410722 1.6497664.7146943 2.7323812 2.3054378 3.4892659 4.3218837zm-5.580081 3.2673943c-4.97056275 0-9-4.0294373-9-9 0-4.97056275 4.02943725-9 9-9 4.9705627 0 9 4.02943725 9 9 0 4.9705627-4.0294373 9-9 9z" fill-rule="evenodd"/></symbol><symbol id="icon-alert" viewBox="0 0 18 18"><path d="m4 10h2.5c.27614237 0 .5.2238576.5.5s-.22385763.5-.5.5h-3.08578644l-1.12132034 1.1213203c-.18753638.1875364-.29289322.4418903-.29289322.7071068v.1715729h14v-.1715729c0-.2652165-.1053568-.5195704-.2928932-.7071068l-1.7071068-1.7071067v-3.4142136c0-2.76142375-2.2385763-5-5-5-2.76142375 0-5 2.23857625-5 5zm3 4c0 1.1045695.8954305 2 2 2s2-.8954305 2-2zm-5 0c-.55228475 0-1-.4477153-1-1v-.1715729c0-.530433.21071368-1.0391408.58578644-1.4142135l1.41421356-1.4142136v-3c0-3.3137085 2.6862915-6 6-6s6 2.6862915 6 6v3l1.4142136 1.4142136c.3750727.3750727.5857864.8837805.5857864 1.4142135v.1715729c0 .5522847-.4477153 1-1 1h-4c0 1.6568542-1.3431458 3-3 3-1.65685425 0-3-1.3431458-3-3z" fill-rule="evenodd"/></symbol><symbol id="icon-arrow-broad" viewBox="0 0 16 16"><path d="m6.10307866 2.97190702v7.69043288l2.44965196-2.44676915c.38776071-.38730439 1.0088052-.39493524 1.38498697-.01919617.38609051.38563612.38643641 1.01053024-.00013864 1.39665039l-4.12239817 4.11754683c-.38616704.3857126-1.01187344.3861062-1.39846576-.0000311l-4.12258206-4.11773056c-.38618426-.38572979-.39254614-1.00476697-.01636437-1.38050605.38609047-.38563611 1.01018509-.38751562 1.4012233.00306241l2.44985644 2.4469734v-8.67638639c0-.54139983.43698413-.98042709.98493125-.98159081l7.89910522-.0043627c.5451687 0 .9871152.44142642.9871152.98595351s-.4419465.98595351-.9871152.98595351z" fill-rule="evenodd" transform="matrix(-1 0 0 -1 14 15)"/></symbol><symbol id="icon-arrow-down" viewBox="0 0 16 16"><path d="m3.28337502 11.5302405 4.03074001 4.176208c.37758093.3912076.98937525.3916069 1.367372-.0000316l4.03091977-4.1763942c.3775978-.3912252.3838182-1.0190815.0160006-1.4001736-.3775061-.39113013-.9877245-.39303641-1.3700683.003106l-2.39538585 2.4818345v-11.6147896l-.00649339-.11662112c-.055753-.49733869-.46370161-.88337888-.95867408-.88337888-.49497246 0-.90292107.38604019-.95867408.88337888l-.00649338.11662112v11.6147896l-2.39518594-2.4816273c-.37913917-.39282218-.98637524-.40056175-1.35419292-.0194697-.37750607.3911302-.37784433 1.0249269.00013556 1.4165479z" fill-rule="evenodd"/></symbol><symbol id="icon-arrow-left" viewBox="0 0 16 16"><path d="m4.46975946 3.28337502-4.17620792 4.03074001c-.39120768.37758093-.39160691.98937525.0000316 1.367372l4.1763942 4.03091977c.39122514.3775978 1.01908149.3838182 1.40017357.0160006.39113012-.3775061.3930364-.9877245-.00310603-1.3700683l-2.48183446-2.39538585h11.61478958l.1166211-.00649339c.4973387-.055753.8833789-.46370161.8833789-.95867408 0-.49497246-.3860402-.90292107-.8833789-.95867408l-.1166211-.00649338h-11.61478958l2.4816273-2.39518594c.39282216-.37913917.40056173-.98637524.01946965-1.35419292-.39113012-.37750607-1.02492687-.37784433-1.41654791.00013556z" fill-rule="evenodd"/></symbol><symbol id="icon-arrow-right" viewBox="0 0 16 16"><path d="m11.5302405 12.716625 4.176208-4.03074003c.3912076-.37758093.3916069-.98937525-.0000316-1.367372l-4.1763942-4.03091981c-.3912252-.37759778-1.0190815-.38381821-1.4001736-.01600053-.39113013.37750607-.39303641.98772445.003106 1.37006824l2.4818345 2.39538588h-11.6147896l-.11662112.00649339c-.49733869.055753-.88337888.46370161-.88337888.95867408 0 .49497246.38604019.90292107.88337888.95867408l.11662112.00649338h11.6147896l-2.4816273 2.39518592c-.39282218.3791392-.40056175.9863753-.0194697 1.3541929.3911302.3775061 1.0249269.3778444 1.4165479-.0001355z" fill-rule="evenodd"/></symbol><symbol id="icon-arrow-sub" viewBox="0 0 16 16"><path d="m7.89692134 4.97190702v7.69043288l-2.44965196-2.4467692c-.38776071-.38730434-1.0088052-.39493519-1.38498697-.0191961-.38609047.3856361-.38643643 1.0105302.00013864 1.3966504l4.12239817 4.1175468c.38616704.3857126 1.01187344.3861062 1.39846576-.0000311l4.12258202-4.1177306c.3861843-.3857298.3925462-1.0047669.0163644-1.380506-.3860905-.38563612-1.0101851-.38751563-1.4012233.0030624l-2.44985643 2.4469734v-8.67638639c0-.54139983-.43698413-.98042709-.98493125-.98159081l-7.89910525-.0043627c-.54516866 0-.98711517.44142642-.98711517.98595351s.44194651.98595351.98711517.98595351z" fill-rule="evenodd"/></symbol><symbol id="icon-arrow-up" viewBox="0 0 16 16"><path d="m12.716625 4.46975946-4.03074003-4.17620792c-.37758093-.39120768-.98937525-.39160691-1.367372.0000316l-4.03091981 4.1763942c-.37759778.39122514-.38381821 1.01908149-.01600053 1.40017357.37750607.39113012.98772445.3930364 1.37006824-.00310603l2.39538588-2.48183446v11.61478958l.00649339.1166211c.055753.4973387.46370161.8833789.95867408.8833789.49497246 0 .90292107-.3860402.95867408-.8833789l.00649338-.1166211v-11.61478958l2.39518592 2.4816273c.3791392.39282216.9863753.40056173 1.3541929.01946965.3775061-.39113012.3778444-1.02492687-.0001355-1.41654791z" fill-rule="evenodd"/></symbol><symbol id="icon-article" viewBox="0 0 18 18"><path d="m13 15v-12.9906311c0-.0073595-.0019884-.0093689.0014977-.0093689l-11.00158888.00087166v13.00506804c0 .5482678.44615281.9940603.99415146.9940603h10.27350412c-.1701701-.2941734-.2675644-.6357129-.2675644-1zm-12 .0059397v-13.00506804c0-.5562408.44704472-1.00087166.99850233-1.00087166h11.00299537c.5510129 0 .9985023.45190985.9985023 1.0093689v2.9906311h3v9.9914698c0 1.1065798-.8927712 2.0085302-1.9940603 2.0085302h-12.01187942c-1.09954652 0-1.99406028-.8927712-1.99406028-1.9940603zm13-9.0059397v9c0 .5522847.4477153 1 1 1s1-.4477153 1-1v-9zm-10-2h7v4h-7zm1 1v2h5v-2zm-1 4h7v1h-7zm0 2h7v1h-7zm0 2h7v1h-7z" fill-rule="evenodd"/></symbol><symbol id="icon-audio" viewBox="0 0 18 18"><path d="m13.0957477 13.5588459c-.195279.1937043-.5119137.193729-.7072234.0000551-.1953098-.193674-.1953346-.5077061-.0000556-.7014104 1.0251004-1.0168342 1.6108711-2.3905226 1.6108711-3.85745208 0-1.46604976-.5850634-2.83898246-1.6090736-3.85566829-.1951894-.19379323-.1950192-.50782531.0003802-.70141028.1953993-.19358497.512034-.19341614.7072234.00037709 1.2094886 1.20083761 1.901635 2.8250555 1.901635 4.55670148 0 1.73268608-.6929822 3.35779608-1.9037571 4.55880738zm2.1233994 2.1025159c-.195234.193749-.5118687.1938462-.7072235.0002171-.1953548-.1936292-.1954528-.5076613-.0002189-.7014104 1.5832215-1.5711805 2.4881302-3.6939808 2.4881302-5.96012998 0-2.26581266-.9046382-4.3883241-2.487443-5.95944795-.1952117-.19377107-.1950777-.50780316.0002993-.70141031s.5120117-.19347426.7072234.00029682c1.7683321 1.75528196 2.7800854 4.12911258 2.7800854 6.66056144 0 2.53182498-1.0120556 4.90597838-2.7808529 6.66132328zm-14.21898205-3.6854911c-.5523759 0-1.00016505-.4441085-1.00016505-.991944v-3.96777631c0-.54783558.44778915-.99194407 1.00016505-.99194407h2.0003301l5.41965617-3.8393633c.44948677-.31842296 1.07413994-.21516983 1.39520191.23062232.12116339.16823446.18629727.36981184.18629727.57655577v12.01603479c0 .5478356-.44778914.9919441-1.00016505.9919441-.20845738 0-.41170538-.0645985-.58133413-.184766l-5.41965617-3.8393633zm0-.991944h2.32084805l5.68047235 4.0241292v-12.01603479l-5.68047235 4.02412928h-2.32084805z" fill-rule="evenodd"/></symbol><symbol id="icon-block" viewBox="0 0 24 24"><path d="m0 0h24v24h-24z" fill-rule="evenodd"/></symbol><symbol id="icon-book" viewBox="0 0 18 18"><path d="m4 13v-11h1v11h11v-11h-13c-.55228475 0-1 .44771525-1 1v10.2675644c.29417337-.1701701.63571286-.2675644 1-.2675644zm12 1h-13c-.55228475 0-1 .4477153-1 1s.44771525 1 1 1h13zm0 3h-13c-1.1045695 0-2-.8954305-2-2v-12c0-1.1045695.8954305-2 2-2h13c.5522847 0 1 .44771525 1 1v14c0 .5522847-.4477153 1-1 1zm-8.5-13h6c.2761424 0 .5.22385763.5.5s-.2238576.5-.5.5h-6c-.27614237 0-.5-.22385763-.5-.5s.22385763-.5.5-.5zm1 2h4c.2761424 0 .5.22385763.5.5s-.2238576.5-.5.5h-4c-.27614237 0-.5-.22385763-.5-.5s.22385763-.5.5-.5z" fill-rule="evenodd"/></symbol><symbol id="icon-broad" viewBox="0 0 24 24"><path d="m9.18274226 7.81v7.7999954l2.48162734-2.4816273c.3928221-.3928221 1.0219731-.4005617 1.4030652-.0194696.3911301.3911301.3914806 1.0249268-.0001404 1.4165479l-4.17620796 4.1762079c-.39120769.3912077-1.02508144.3916069-1.41671995-.0000316l-4.1763942-4.1763942c-.39122514-.3912251-.39767006-1.0190815-.01657798-1.4001736.39113012-.3911301 1.02337106-.3930364 1.41951349.0031061l2.48183446 2.4818344v-8.7999954c0-.54911294.4426881-.99439484.99778758-.99557515l8.00221246-.00442485c.5522847 0 1 .44771525 1 1s-.4477153 1-1 1z" fill-rule="evenodd" transform="matrix(-1 0 0 -1 20.182742 24.805206)"/></symbol><symbol id="icon-calendar" viewBox="0 0 18 18"><path d="m12.5 0c.2761424 0 .5.21505737.5.49047852v.50952148h2c1.1072288 0 2 .89451376 2 2v12c0 1.1072288-.8945138 2-2 2h-12c-1.1072288 0-2-.8945138-2-2v-12c0-1.1072288.89451376-2 2-2h1v1h-1c-.55393837 0-1 .44579254-1 1v3h14v-3c0-.55393837-.4457925-1-1-1h-2v1.50952148c0 .27088381-.2319336.49047852-.5.49047852-.2761424 0-.5-.21505737-.5-.49047852v-3.01904296c0-.27088381.2319336-.49047852.5-.49047852zm3.5 7h-14v8c0 .5539384.44579254 1 1 1h12c.5539384 0 1-.4457925 1-1zm-11 6v1h-1v-1zm3 0v1h-1v-1zm3 0v1h-1v-1zm-6-2v1h-1v-1zm3 0v1h-1v-1zm6 0v1h-1v-1zm-3 0v1h-1v-1zm-3-2v1h-1v-1zm6 0v1h-1v-1zm-3 0v1h-1v-1zm-5.5-9c.27614237 0 .5.21505737.5.49047852v.50952148h5v1h-5v1.50952148c0 .27088381-.23193359.49047852-.5.49047852-.27614237 0-.5-.21505737-.5-.49047852v-3.01904296c0-.27088381.23193359-.49047852.5-.49047852z" fill-rule="evenodd"/></symbol><symbol id="icon-cart" viewBox="0 0 18 18"><path d="m5 14c1.1045695 0 2 .8954305 2 2s-.8954305 2-2 2-2-.8954305-2-2 .8954305-2 2-2zm10 0c1.1045695 0 2 .8954305 2 2s-.8954305 2-2 2-2-.8954305-2-2 .8954305-2 2-2zm-10 1c-.55228475 0-1 .4477153-1 1s.44771525 1 1 1 1-.4477153 1-1-.44771525-1-1-1zm10 0c-.5522847 0-1 .4477153-1 1s.4477153 1 1 1 1-.4477153 1-1-.4477153-1-1-1zm-12.82032249-15c.47691417 0 .88746157.33678127.98070211.80449199l.23823144 1.19501025 13.36277974.00045554c.5522847.00001882.9999659.44774934.9999659 1.00004222 0 .07084994-.0075361.14150708-.022474.2107727l-1.2908094 5.98534344c-.1007861.46742419-.5432548.80388386-1.0571651.80388386h-10.24805106c-.59173366 0-1.07142857.4477153-1.07142857 1 0 .5128358.41361449.9355072.94647737.9932723l.1249512.0067277h10.35933776c.2749512 0 .4979349.2228539.4979349.4978051 0 .2749417-.2227336.4978951-.4976753.4980063l-10.35959736.0041886c-1.18346732 0-2.14285714-.8954305-2.14285714-2 0-.6625717.34520317-1.24989198.87690425-1.61383592l-1.63768102-8.19004794c-.01312273-.06561364-.01950005-.131011-.0196107-.19547395l-1.71961253-.00064219c-.27614237 0-.5-.22385762-.5-.5 0-.27614237.22385763-.5.5-.5zm14.53193359 2.99950224h-13.11300004l1.20580469 6.02530174c.11024034-.0163252.22327998-.02480398.33844139-.02480398h10.27064786z"/></symbol><symbol id="icon-chevron-less" viewBox="0 0 10 10"><path d="m5.58578644 4-3.29289322-3.29289322c-.39052429-.39052429-.39052429-1.02368927 0-1.41421356s1.02368927-.39052429 1.41421356 0l4 4c.39052429.39052429.39052429 1.02368927 0 1.41421356l-4 4c-.39052429.39052429-1.02368927.39052429-1.41421356 0s-.39052429-1.02368927 0-1.41421356z" fill-rule="evenodd" transform="matrix(0 -1 -1 0 9 9)"/></symbol><symbol id="icon-chevron-more" viewBox="0 0 10 10"><path d="m5.58578644 6-3.29289322-3.29289322c-.39052429-.39052429-.39052429-1.02368927 0-1.41421356s1.02368927-.39052429 1.41421356 0l4 4c.39052429.39052429.39052429 1.02368927 0 1.41421356l-4 4.00000002c-.39052429.3905243-1.02368927.3905243-1.41421356 0s-.39052429-1.02368929 0-1.41421358z" fill-rule="evenodd" transform="matrix(0 1 -1 0 11 1)"/></symbol><symbol id="icon-chevron-right" viewBox="0 0 10 10"><path d="m5.96738168 4.70639573 2.39518594-2.41447274c.37913917-.38219212.98637524-.38972225 1.35419292-.01894278.37750606.38054586.37784436.99719163-.00013556 1.37821513l-4.03074001 4.06319683c-.37758093.38062133-.98937525.38100976-1.367372-.00003075l-4.03091981-4.06337806c-.37759778-.38063832-.38381821-.99150444-.01600053-1.3622839.37750607-.38054587.98772445-.38240057 1.37006824.00302197l2.39538588 2.4146743.96295325.98624457z" fill-rule="evenodd" transform="matrix(0 -1 1 0 0 10)"/></symbol><symbol id="icon-circle-fill" viewBox="0 0 16 16"><path d="m8 14c-3.3137085 0-6-2.6862915-6-6s2.6862915-6 6-6 6 2.6862915 6 6-2.6862915 6-6 6z" fill-rule="evenodd"/></symbol><symbol id="icon-circle" viewBox="0 0 16 16"><path d="m8 12c2.209139 0 4-1.790861 4-4s-1.790861-4-4-4-4 1.790861-4 4 1.790861 4 4 4zm0 2c-3.3137085 0-6-2.6862915-6-6s2.6862915-6 6-6 6 2.6862915 6 6-2.6862915 6-6 6z" fill-rule="evenodd"/></symbol><symbol id="icon-citation" viewBox="0 0 18 18"><path d="m8.63593473 5.99995183c2.20913897 0 3.99999997 1.79084375 3.99999997 3.99996146 0 1.40730761-.7267788 2.64486871-1.8254829 3.35783281 1.6240224.6764218 2.8754442 2.0093871 3.4610603 3.6412466l-1.0763845.000006c-.5310008-1.2078237-1.5108121-2.1940153-2.7691712-2.7181346l-.79002167-.329052v-1.023992l.63016577-.4089232c.8482885-.5504661 1.3698342-1.4895187 1.3698342-2.51898361 0-1.65683828-1.3431457-2.99996146-2.99999997-2.99996146-1.65685425 0-3 1.34312318-3 2.99996146 0 1.02946491.52154569 1.96851751 1.36983419 2.51898361l.63016581.4089232v1.023992l-.79002171.329052c-1.25835905.5241193-2.23817037 1.5103109-2.76917113 2.7181346l-1.07638453-.000006c.58561612-1.6318595 1.8370379-2.9648248 3.46106024-3.6412466-1.09870405-.7129641-1.82548287-1.9505252-1.82548287-3.35783281 0-2.20911771 1.790861-3.99996146 4-3.99996146zm7.36897597-4.99995183c1.1018574 0 1.9950893.89353404 1.9950893 2.00274083v5.994422c0 1.10608317-.8926228 2.00274087-1.9950893 2.00274087l-3.0049107-.0009037v-1l3.0049107.00091329c.5490631 0 .9950893-.44783123.9950893-1.00275046v-5.994422c0-.55646537-.4450595-1.00275046-.9950893-1.00275046h-14.00982141c-.54906309 0-.99508929.44783123-.99508929 1.00275046v5.9971821c0 .66666024.33333333.99999036 1 .99999036l2-.00091329v1l-2 .0009037c-1 0-2-.99999041-2-1.99998077v-5.9971821c0-1.10608322.8926228-2.00274083 1.99508929-2.00274083zm-8.5049107 2.9999711c.27614237 0 .5.22385547.5.5 0 .2761349-.22385763.5-.5.5h-4c-.27614237 0-.5-.2238651-.5-.5 0-.27614453.22385763-.5.5-.5zm3 0c.2761424 0 .5.22385547.5.5 0 .2761349-.2238576.5-.5.5h-1c-.27614237 0-.5-.2238651-.5-.5 0-.27614453.22385763-.5.5-.5zm4 0c.2761424 0 .5.22385547.5.5 0 .2761349-.2238576.5-.5.5h-2c-.2761424 0-.5-.2238651-.5-.5 0-.27614453.2238576-.5.5-.5z" fill-rule="evenodd"/></symbol><symbol id="icon-close" viewBox="0 0 16 16"><path d="m2.29679575 12.2772478c-.39658757.3965876-.39438847 1.0328109-.00062148 1.4265779.39651227.3965123 1.03246768.3934888 1.42657791-.0006214l4.27724782-4.27724787 4.2772478 4.27724787c.3965876.3965875 1.0328109.3943884 1.4265779.0006214.3965123-.3965122.3934888-1.0324677-.0006214-1.4265779l-4.27724787-4.2772478 4.27724787-4.27724782c.3965875-.39658757.3943884-1.03281091.0006214-1.42657791-.3965122-.39651226-1.0324677-.39348875-1.4265779.00062148l-4.2772478 4.27724782-4.27724782-4.27724782c-.39658757-.39658757-1.03281091-.39438847-1.42657791-.00062148-.39651226.39651227-.39348875 1.03246768.00062148 1.42657791l4.27724782 4.27724782z" fill-rule="evenodd"/></symbol><symbol id="icon-collections" viewBox="0 0 18 18"><path d="m15 4c1.1045695 0 2 .8954305 2 2v9c0 1.1045695-.8954305 2-2 2h-8c-1.1045695 0-2-.8954305-2-2h1c0 .5128358.38604019.9355072.88337887.9932723l.11662113.0067277h8c.5128358 0 .9355072-.3860402.9932723-.8833789l.0067277-.1166211v-9c0-.51283584-.3860402-.93550716-.8833789-.99327227l-.1166211-.00672773h-1v-1zm-4-3c1.1045695 0 2 .8954305 2 2v9c0 1.1045695-.8954305 2-2 2h-8c-1.1045695 0-2-.8954305-2-2v-9c0-1.1045695.8954305-2 2-2zm0 1h-8c-.51283584 0-.93550716.38604019-.99327227.88337887l-.00672773.11662113v9c0 .5128358.38604019.9355072.88337887.9932723l.11662113.0067277h8c.5128358 0 .9355072-.3860402.9932723-.8833789l.0067277-.1166211v-9c0-.51283584-.3860402-.93550716-.8833789-.99327227zm-1.5 7c.27614237 0 .5.22385763.5.5s-.22385763.5-.5.5h-5c-.27614237 0-.5-.22385763-.5-.5s.22385763-.5.5-.5zm0-2c.27614237 0 .5.22385763.5.5s-.22385763.5-.5.5h-5c-.27614237 0-.5-.22385763-.5-.5s.22385763-.5.5-.5zm0-2c.27614237 0 .5.22385763.5.5s-.22385763.5-.5.5h-5c-.27614237 0-.5-.22385763-.5-.5s.22385763-.5.5-.5z" fill-rule="evenodd"/></symbol><symbol id="icon-compare" viewBox="0 0 18 18"><path d="m12 3c3.3137085 0 6 2.6862915 6 6s-2.6862915 6-6 6c-1.0928452 0-2.11744941-.2921742-2.99996061-.8026704-.88181407.5102749-1.90678042.8026704-3.00003939.8026704-3.3137085 0-6-2.6862915-6-6s2.6862915-6 6-6c1.09325897 0 2.11822532.29239547 3.00096303.80325037.88158756-.51107621 1.90619177-.80325037 2.99903697-.80325037zm-6 1c-2.76142375 0-5 2.23857625-5 5 0 2.7614237 2.23857625 5 5 5 .74397391 0 1.44999672-.162488 2.08451611-.4539116-1.27652344-1.1000812-2.08451611-2.7287264-2.08451611-4.5460884s.80799267-3.44600721 2.08434391-4.5463015c-.63434719-.29121054-1.34037-.4536985-2.08434391-.4536985zm6 0c-.7439739 0-1.4499967.16248796-2.08451611.45391156 1.27652341 1.10008123 2.08451611 2.72872644 2.08451611 4.54608844s-.8079927 3.4460072-2.08434391 4.5463015c.63434721.2912105 1.34037001.4536985 2.08434391.4536985 2.7614237 0 5-2.2385763 5-5 0-2.76142375-2.2385763-5-5-5zm-1.4162763 7.0005324h-3.16744736c.15614659.3572676.35283837.6927622.58425872 1.0006671h1.99892988c.23142036-.3079049.42811216-.6433995.58425876-1.0006671zm.4162763-2.0005324h-4c0 .34288501.0345146.67770871.10025909 1.0011864h3.79948181c.0657445-.32347769.1002591-.65830139.1002591-1.0011864zm-.4158423-1.99953894h-3.16831543c-.13859957.31730812-.24521946.651783-.31578599.99935097h3.79988742c-.0705665-.34756797-.1771864-.68204285-.315786-.99935097zm-1.58295822-1.999926-.08316107.06199199c-.34550042.27081213-.65446126.58611297-.91825862.93727862h2.00044041c-.28418626-.37830727-.6207872-.71499149-.99902072-.99927061z" fill-rule="evenodd"/></symbol><symbol id="icon-download-file" viewBox="0 0 18 18"><path d="m10.0046024 0c.5497429 0 1.3179837.32258606 1.707238.71184039l4.5763192 4.57631922c.3931386.39313859.7118404 1.16760135.7118404 1.71431368v8.98899651c0 1.1092806-.8945138 2.0085302-1.9940603 2.0085302h-12.01187942c-1.10128908 0-1.99406028-.8926228-1.99406028-1.9950893v-14.00982141c0-1.10185739.88743329-1.99508929 1.99961498-1.99508929zm0 1h-7.00498742c-.55709576 0-.99961498.44271433-.99961498.99508929v14.00982141c0 .5500396.44491393.9950893.99406028.9950893h12.01187942c.5463747 0 .9940603-.4506622.9940603-1.0085302v-8.98899651c0-.28393444-.2150684-.80332809-.4189472-1.0072069l-4.5763192-4.57631922c-.2038461-.20384606-.718603-.41894717-1.0001312-.41894717zm-1.5046024 4c.27614237 0 .5.21637201.5.49209595v6.14827645l1.7462789-1.77990922c.1933927-.1971171.5125222-.19455839.7001689-.0069117.1932998.19329992.1910058.50899492-.0027774.70277812l-2.59089271 2.5908927c-.19483374.1948337-.51177825.1937771-.70556873-.0000133l-2.59099079-2.5909908c-.19484111-.1948411-.19043735-.5151448-.00279066-.70279146.19329987-.19329987.50465175-.19237083.70018565.00692852l1.74638684 1.78001764v-6.14827695c0-.27177709.23193359-.49209595.5-.49209595z" fill-rule="evenodd"/></symbol><symbol id="icon-download" viewBox="0 0 16 16"><path d="m12.9975267 12.999368c.5467123 0 1.0024733.4478567 1.0024733 1.000316 0 .5563109-.4488226 1.000316-1.0024733 1.000316h-9.99505341c-.54671233 0-1.00247329-.4478567-1.00247329-1.000316 0-.5563109.44882258-1.000316 1.00247329-1.000316zm-4.9975267-11.999368c.55228475 0 1 .44497754 1 .99589209v6.80214418l2.4816273-2.48241149c.3928222-.39294628 1.0219732-.4006883 1.4030652-.01947579.3911302.39125371.3914806 1.02525073-.0001404 1.41699553l-4.17620792 4.17752758c-.39120769.3913313-1.02508144.3917306-1.41671995-.0000316l-4.17639421-4.17771394c-.39122513-.39134876-.39767006-1.01940351-.01657797-1.40061601.39113012-.39125372 1.02337105-.3931606 1.41951349.00310701l2.48183446 2.48261871v-6.80214418c0-.55001601.44386482-.99589209 1-.99589209z" fill-rule="evenodd"/></symbol><symbol id="icon-editors" viewBox="0 0 18 18"><path d="m8.72592184 2.54588137c-.48811714-.34391207-1.08343326-.54588137-1.72592184-.54588137-1.65685425 0-3 1.34314575-3 3 0 1.02947485.5215457 1.96853646 1.3698342 2.51900785l.6301658.40892721v1.02400182l-.79002171.32905522c-1.93395773.8055207-3.20997829 2.7024791-3.20997829 4.8180274v.9009805h-1v-.9009805c0-2.5479714 1.54557359-4.79153984 3.82548288-5.7411543-1.09870406-.71297106-1.82548288-1.95054399-1.82548288-3.3578652 0-2.209139 1.790861-4 4-4 1.09079823 0 2.07961816.43662103 2.80122451 1.1446278-.37707584.09278571-.7373238.22835063-1.07530267.40125357zm-2.72592184 14.45411863h-1v-.9009805c0-2.5479714 1.54557359-4.7915398 3.82548288-5.7411543-1.09870406-.71297106-1.82548288-1.95054399-1.82548288-3.3578652 0-2.209139 1.790861-4 4-4s4 1.790861 4 4c0 1.40732121-.7267788 2.64489414-1.8254829 3.3578652 2.2799093.9496145 3.8254829 3.1931829 3.8254829 5.7411543v.9009805h-1v-.9009805c0-2.1155483-1.2760206-4.0125067-3.2099783-4.8180274l-.7900217-.3290552v-1.02400184l.6301658-.40892721c.8482885-.55047139 1.3698342-1.489533 1.3698342-2.51900785 0-1.65685425-1.3431458-3-3-3-1.65685425 0-3 1.34314575-3 3 0 1.02947485.5215457 1.96853646 1.3698342 2.51900785l.6301658.40892721v1.02400184l-.79002171.3290552c-1.93395773.8055207-3.20997829 2.7024791-3.20997829 4.8180274z" fill-rule="evenodd"/></symbol><symbol id="icon-email" viewBox="0 0 18 18"><path d="m16.0049107 2c1.1018574 0 1.9950893.89706013 1.9950893 2.00585866v9.98828264c0 1.1078052-.8926228 2.0058587-1.9950893 2.0058587h-14.00982141c-1.10185739 0-1.99508929-.8970601-1.99508929-2.0058587v-9.98828264c0-1.10780515.8926228-2.00585866 1.99508929-2.00585866zm0 1h-14.00982141c-.54871518 0-.99508929.44887827-.99508929 1.00585866v9.98828264c0 .5572961.44630695 1.0058587.99508929 1.0058587h14.00982141c.5487152 0 .9950893-.4488783.9950893-1.0058587v-9.98828264c0-.55729607-.446307-1.00585866-.9950893-1.00585866zm-.0049107 2.55749512v1.44250488l-7 4-7-4v-1.44250488l7 4z" fill-rule="evenodd"/></symbol><symbol id="icon-error" viewBox="0 0 18 18"><path d="m9 0c4.9705627 0 9 4.02943725 9 9 0 4.9705627-4.0294373 9-9 9-4.97056275 0-9-4.0294373-9-9 0-4.97056275 4.02943725-9 9-9zm2.8630343 4.71100931-2.8630343 2.86303426-2.86303426-2.86303426c-.39658757-.39658757-1.03281091-.39438847-1.4265779-.00062147-.39651227.39651226-.39348876 1.03246767.00062147 1.4265779l2.86303426 2.86303426-2.86303426 2.8630343c-.39658757.3965875-.39438847 1.0328109-.00062147 1.4265779.39651226.3965122 1.03246767.3934887 1.4265779-.0006215l2.86303426-2.8630343 2.8630343 2.8630343c.3965875.3965876 1.0328109.3943885 1.4265779.0006215.3965122-.3965123.3934887-1.0324677-.0006215-1.4265779l-2.8630343-2.8630343 2.8630343-2.86303426c.3965876-.39658757.3943885-1.03281091.0006215-1.4265779-.3965123-.39651227-1.0324677-.39348876-1.4265779.00062147z" fill-rule="evenodd"/></symbol><symbol id="icon-ethics" viewBox="0 0 18 18"><path d="m6.76384967 1.41421356.83301651-.8330165c.77492941-.77492941 2.03133823-.77492941 2.80626762 0l.8330165.8330165c.3750728.37507276.8837806.58578644 1.4142136.58578644h1.3496361c1.1045695 0 2 .8954305 2 2v1.34963611c0 .53043298.2107137 1.03914081.5857864 1.41421356l.8330165.83301651c.7749295.77492941.7749295 2.03133823 0 2.80626762l-.8330165.8330165c-.3750727.3750728-.5857864.8837806-.5857864 1.4142136v1.3496361c0 1.1045695-.8954305 2-2 2h-1.3496361c-.530433 0-1.0391408.2107137-1.4142136.5857864l-.8330165.8330165c-.77492939.7749295-2.03133821.7749295-2.80626762 0l-.83301651-.8330165c-.37507275-.3750727-.88378058-.5857864-1.41421356-.5857864h-1.34963611c-1.1045695 0-2-.8954305-2-2v-1.3496361c0-.530433-.21071368-1.0391408-.58578644-1.4142136l-.8330165-.8330165c-.77492941-.77492939-.77492941-2.03133821 0-2.80626762l.8330165-.83301651c.37507276-.37507275.58578644-.88378058.58578644-1.41421356v-1.34963611c0-1.1045695.8954305-2 2-2h1.34963611c.53043298 0 1.03914081-.21071368 1.41421356-.58578644zm-1.41421356 1.58578644h-1.34963611c-.55228475 0-1 .44771525-1 1v1.34963611c0 .79564947-.31607052 1.55871121-.87867966 2.12132034l-.8330165.83301651c-.38440512.38440512-.38440512 1.00764896 0 1.39205408l.8330165.83301646c.56260914.5626092.87867966 1.3256709.87867966 2.1213204v1.3496361c0 .5522847.44771525 1 1 1h1.34963611c.79564947 0 1.55871121.3160705 2.12132034.8786797l.83301651.8330165c.38440512.3844051 1.00764896.3844051 1.39205408 0l.83301646-.8330165c.5626092-.5626092 1.3256709-.8786797 2.1213204-.8786797h1.3496361c.5522847 0 1-.4477153 1-1v-1.3496361c0-.7956495.3160705-1.5587112.8786797-2.1213204l.8330165-.83301646c.3844051-.38440512.3844051-1.00764896 0-1.39205408l-.8330165-.83301651c-.5626092-.56260913-.8786797-1.32567087-.8786797-2.12132034v-1.34963611c0-.55228475-.4477153-1-1-1h-1.3496361c-.7956495 0-1.5587112-.31607052-2.1213204-.87867966l-.83301646-.8330165c-.38440512-.38440512-1.00764896-.38440512-1.39205408 0l-.83301651.8330165c-.56260913.56260914-1.32567087.87867966-2.12132034.87867966zm3.58698944 11.4960218c-.02081224.002155-.04199226.0030286-.06345763.002542-.98766446-.0223875-1.93408568-.3063547-2.75885125-.8155622-.23496767-.1450683-.30784554-.4531483-.16277726-.688116.14506827-.2349677.45314827-.3078455.68811595-.1627773.67447084.4164161 1.44758575.6483839 2.25617384.6667123.01759529.0003988.03495764.0017019.05204365.0038639.01713363-.0017748.03452416-.0026845.05212715-.0026845 2.4852814 0 4.5-2.0147186 4.5-4.5 0-1.04888973-.3593547-2.04134635-1.0074477-2.83787157-.1742817-.21419731-.1419238-.5291218.0722736-.70340353.2141973-.17428173.5291218-.14192375.7034035.07227357.7919032.97327203 1.2317706 2.18808682 1.2317706 3.46900153 0 3.0375661-2.4624339 5.5-5.5 5.5-.02146768 0-.04261937-.0013529-.06337445-.0039782zm1.57975095-10.78419583c.2654788.07599731.419084.35281842.3430867.61829728-.0759973.26547885-.3528185.419084-.6182973.3430867-.37560116-.10752146-.76586237-.16587951-1.15568824-.17249193-2.5587807-.00064534-4.58547766 2.00216524-4.58547766 4.49928198 0 .62691557.12797645 1.23496.37274865 1.7964426.11035133.2531347-.0053975.5477984-.25853224.6581497-.25313473.1103514-.54779841-.0053975-.65814974-.2585322-.29947131-.6869568-.45606667-1.43097603-.45606667-2.1960601 0-3.05211432 2.47714695-5.50006595 5.59399617-5.49921198.48576182.00815502.96289603.0795037 1.42238033.21103795zm-1.9766658 6.41091303 2.69835-2.94655317c.1788432-.21040373.4943901-.23598862.7047939-.05714545.2104037.17884318.2359886.49439014.0571454.70479387l-3.01637681 3.34277395c-.18039088.1999106-.48669547.2210637-.69285412.0478478l-1.93095347-1.62240047c-.21213845-.17678204-.24080048-.49206439-.06401844-.70420284.17678204-.21213844.49206439-.24080048.70420284-.06401844z" fill-rule="evenodd"/></symbol><symbol id="icon-expand"><path d="M7.498 11.918a.997.997 0 0 0-.003-1.411.995.995 0 0 0-1.412-.003l-4.102 4.102v-3.51A1 1 0 0 0 .98 10.09.992.992 0 0 0 0 11.092V17c0 .554.448 1.002 1.002 1.002h5.907c.554 0 1.002-.45 1.002-1.003 0-.539-.45-.978-1.006-.978h-3.51zm3.005-5.835a.997.997 0 0 0 .003 1.412.995.995 0 0 0 1.411.003l4.103-4.103v3.51a1 1 0 0 0 1.001 1.006A.992.992 0 0 0 18 6.91V1.002A1 1 0 0 0 17 0h-5.907a1.003 1.003 0 0 0-1.002 1.003c0 .539.45.978 1.006.978h3.51z" fill-rule="evenodd"/></symbol><symbol id="icon-explore" viewBox="0 0 18 18"><path d="m9 17c4.418278 0 8-3.581722 8-8s-3.581722-8-8-8-8 3.581722-8 8 3.581722 8 8 8zm0 1c-4.97056275 0-9-4.0294373-9-9 0-4.97056275 4.02943725-9 9-9 4.9705627 0 9 4.02943725 9 9 0 4.9705627-4.0294373 9-9 9zm0-2.5c-.27614237 0-.5-.2238576-.5-.5s.22385763-.5.5-.5c2.969509 0 5.400504-2.3575119 5.497023-5.31714844.0090007-.27599565.2400359-.49243782.5160315-.48343711.2759957.0090007.4924378.2400359.4834371.51603155-.114093 3.4985237-2.9869632 6.284554-6.4964916 6.284554zm-.29090657-12.99359748c.27587424-.01216621.50937715.20161139.52154336.47748563.01216621.27587423-.20161139.50937715-.47748563.52154336-2.93195733.12930094-5.25315116 2.54886451-5.25315116 5.49456849 0 .27614237-.22385763.5-.5.5s-.5-.22385763-.5-.5c0-3.48142406 2.74307146-6.34074398 6.20909343-6.49359748zm1.13784138 8.04763908-1.2004882-1.20048821c-.19526215-.19526215-.19526215-.51184463 0-.70710678s.51184463-.19526215.70710678 0l1.20048821 1.2004882 1.6006509-4.00162734-4.50670359 1.80268144-1.80268144 4.50670359zm4.10281269-6.50378907-2.6692597 6.67314927c-.1016411.2541026-.3029834.4554449-.557086.557086l-6.67314927 2.6692597 2.66925969-6.67314926c.10164107-.25410266.30298336-.45544495.55708602-.55708602z" fill-rule="evenodd"/></symbol><symbol id="icon-filter" viewBox="0 0 16 16"><path d="m14.9738641 0c.5667192 0 1.0261359.4477136 1.0261359 1 0 .24221858-.0902161.47620768-.2538899.65849851l-5.6938314 6.34147206v5.49997973c0 .3147562-.1520673.6111434-.4104543.7999971l-2.05227171 1.4999945c-.45337535.3313696-1.09655869.2418269-1.4365902-.1999993-.13321514-.1730955-.20522717-.3836284-.20522717-.5999978v-6.99997423l-5.69383133-6.34147206c-.3731872-.41563511-.32996891-1.0473954.09653074-1.41107611.18705584-.15950448.42716133-.2474224.67571519-.2474224zm-5.9218641 8.5h-2.105v6.491l.01238459.0070843.02053271.0015705.01955278-.0070558 2.0532976-1.4990996zm-8.02585008-7.5-.01564945.00240169 5.83249953 6.49759831h2.313l5.836-6.499z"/></symbol><symbol id="icon-home" viewBox="0 0 18 18"><path d="m9 5-6 6v5h4v-4h4v4h4v-5zm7 6.5857864v4.4142136c0 .5522847-.4477153 1-1 1h-5v-4h-2v4h-5c-.55228475 0-1-.4477153-1-1v-4.4142136c-.25592232 0-.51184464-.097631-.70710678-.2928932l-.58578644-.5857864c-.39052429-.3905243-.39052429-1.02368929 0-1.41421358l8.29289322-8.29289322 8.2928932 8.29289322c.3905243.39052429.3905243 1.02368928 0 1.41421358l-.5857864.5857864c-.1952622.1952622-.4511845.2928932-.7071068.2928932zm-7-9.17157284-7.58578644 7.58578644.58578644.5857864 7-6.99999996 7 6.99999996.5857864-.5857864z" fill-rule="evenodd"/></symbol><symbol id="icon-image" viewBox="0 0 18 18"><path d="m10.0046024 0c.5497429 0 1.3179837.32258606 1.707238.71184039l4.5763192 4.57631922c.3931386.39313859.7118404 1.16760135.7118404 1.71431368v8.98899651c0 1.1092806-.8945138 2.0085302-1.9940603 2.0085302h-12.01187942c-1.10128908 0-1.99406028-.8926228-1.99406028-1.9950893v-14.00982141c0-1.10185739.88743329-1.99508929 1.99961498-1.99508929zm-3.49645283 10.1752453-3.89407257 6.7495552c.11705545.048464.24538859.0751995.37998328.0751995h10.60290092l-2.4329715-4.2154691-1.57494129 2.7288098zm8.49779013 6.8247547c.5463747 0 .9940603-.4506622.9940603-1.0085302v-8.98899651c0-.28393444-.2150684-.80332809-.4189472-1.0072069l-4.5763192-4.57631922c-.2038461-.20384606-.718603-.41894717-1.0001312-.41894717h-7.00498742c-.55709576 0-.99961498.44271433-.99961498.99508929v13.98991071l4.50814957-7.81026689 3.08089884 5.33809539 1.57494129-2.7288097 3.5875735 6.2159812zm-3.0059397-11c1.1045695 0 2 .8954305 2 2s-.8954305 2-2 2-2-.8954305-2-2 .8954305-2 2-2zm0 1c-.5522847 0-1 .44771525-1 1s.4477153 1 1 1 1-.44771525 1-1-.4477153-1-1-1z" fill-rule="evenodd"/></symbol><symbol id="icon-info" viewBox="0 0 18 18"><path d="m9 0c4.9705627 0 9 4.02943725 9 9 0 4.9705627-4.0294373 9-9 9-4.97056275 0-9-4.0294373-9-9 0-4.97056275 4.02943725-9 9-9zm0 7h-1.5l-.11662113.00672773c-.49733868.05776511-.88337887.48043643-.88337887.99327227 0 .47338693.32893365.86994729.77070917.97358929l.1126697.01968298.11662113.00672773h.5v3h-.5l-.11662113.0067277c-.42082504.0488782-.76196299.3590206-.85696816.7639815l-.01968298.1126697-.00672773.1166211.00672773.1166211c.04887817.4208251.35902055.761963.76398144.8569682l.1126697.019683.11662113.0067277h3l.1166211-.0067277c.4973387-.0577651.8833789-.4804365.8833789-.9932723 0-.4733869-.3289337-.8699473-.7707092-.9735893l-.1126697-.019683-.1166211-.0067277h-.5v-4l-.00672773-.11662113c-.04887817-.42082504-.35902055-.76196299-.76398144-.85696816l-.1126697-.01968298zm0-3.25c-.69035594 0-1.25.55964406-1.25 1.25s.55964406 1.25 1.25 1.25 1.25-.55964406 1.25-1.25-.55964406-1.25-1.25-1.25z" fill-rule="evenodd"/></symbol><symbol id="icon-institution" viewBox="0 0 18 18"><path d="m7 16.9998189v-2.0003623h4v2.0003623h2v-3.0005434h-8v3.0005434zm-3-10.00181122h-1.52632364c-.27614237 0-.5-.22389817-.5-.50009056 0-.13995446.05863589-.27350497.16166338-.36820841l1.23156713-1.13206327h-2.36690687v12.00217346h3v-2.0003623h-3v-1.0001811h3v-1.0001811h1v-4.00072448h-1zm10 0v2.00036224h-1v4.00072448h1v1.0001811h3v1.0001811h-3v2.0003623h3v-12.00217346h-2.3695309l1.2315671 1.13206327c.2033191.186892.2166633.50325042.0298051.70660631-.0946863.10304615-.2282126.16169266-.3681417.16169266zm3-3.00054336c.5522847 0 1 .44779634 1 1.00018112v13.00235456h-18v-13.00235456c0-.55238478.44771525-1.00018112 1-1.00018112h3.45499992l4.20535144-3.86558216c.19129876-.17584288.48537447-.17584288.67667324 0l4.2053514 3.86558216zm-4 3.00054336h-8v1.00018112h8zm-2 6.00108672h1v-4.00072448h-1zm-1 0v-4.00072448h-2v4.00072448zm-3 0v-4.00072448h-1v4.00072448zm8-4.00072448c.5522847 0 1 .44779634 1 1.00018112v2.00036226h-2v-2.00036226c0-.55238478.4477153-1.00018112 1-1.00018112zm-12 0c.55228475 0 1 .44779634 1 1.00018112v2.00036226h-2v-2.00036226c0-.55238478.44771525-1.00018112 1-1.00018112zm5.99868798-7.81907007-5.24205601 4.81852671h10.48411203zm.00131202 3.81834559c-.55228475 0-1-.44779634-1-1.00018112s.44771525-1.00018112 1-1.00018112 1 .44779634 1 1.00018112-.44771525 1.00018112-1 1.00018112zm-1 11.00199236v1.0001811h2v-1.0001811z" fill-rule="evenodd"/></symbol><symbol id="icon-location" viewBox="0 0 18 18"><path d="m9.39521328 16.2688008c.79596342-.7770119 1.59208152-1.6299956 2.33285652-2.5295081 1.4020032-1.7024324 2.4323601-3.3624519 2.9354918-4.871847.2228715-.66861448.3364384-1.29323246.3364384-1.8674457 0-3.3137085-2.6862915-6-6-6-3.36356866 0-6 2.60156856-6 6 0 .57421324.11356691 1.19883122.3364384 1.8674457.50313169 1.5093951 1.53348863 3.1694146 2.93549184 4.871847.74077492.8995125 1.53689309 1.7524962 2.33285648 2.5295081.13694479.1336842.26895677.2602648.39521328.3793207.12625651-.1190559.25826849-.2456365.39521328-.3793207zm-.39521328 1.7311992s-7-6-7-11c0-4 3.13400675-7 7-7 3.8659932 0 7 3.13400675 7 7 0 5-7 11-7 11zm0-8c-1.65685425 0-3-1.34314575-3-3s1.34314575-3 3-3c1.6568542 0 3 1.34314575 3 3s-1.3431458 3-3 3zm0-1c1.1045695 0 2-.8954305 2-2s-.8954305-2-2-2-2 .8954305-2 2 .8954305 2 2 2z" fill-rule="evenodd"/></symbol><symbol id="icon-minus" viewBox="0 0 16 16"><path d="m2.00087166 7h11.99825664c.5527662 0 1.0008717.44386482 1.0008717 1 0 .55228475-.4446309 1-1.0008717 1h-11.99825664c-.55276616 0-1.00087166-.44386482-1.00087166-1 0-.55228475.44463086-1 1.00087166-1z" fill-rule="evenodd"/></symbol><symbol id="icon-newsletter" viewBox="0 0 18 18"><path d="m9 11.8482489 2-1.1428571v-1.7053918h-4v1.7053918zm-3-1.7142857v-2.1339632h6v2.1339632l3-1.71428574v-6.41967746h-12v6.41967746zm10-5.3839632 1.5299989.95624934c.2923814.18273835.4700011.50320827.4700011.8479983v8.44575236c0 1.1045695-.8954305 2-2 2h-14c-1.1045695 0-2-.8954305-2-2v-8.44575236c0-.34479003.1776197-.66525995.47000106-.8479983l1.52999894-.95624934v-2.75c0-.55228475.44771525-1 1-1h12c.5522847 0 1 .44771525 1 1zm0 1.17924764v3.07075236l-7 4-7-4v-3.07075236l-1 .625v8.44575236c0 .5522847.44771525 1 1 1h14c.5522847 0 1-.4477153 1-1v-8.44575236zm-10-1.92924764h6v1h-6zm-1 2h8v1h-8z" fill-rule="evenodd"/></symbol><symbol id="icon-orcid" viewBox="0 0 18 18"><path d="m9 1c4.418278 0 8 3.581722 8 8s-3.581722 8-8 8-8-3.581722-8-8 3.581722-8 8-8zm-2.90107518 5.2732337h-1.41865256v7.1712107h1.41865256zm4.55867178.02508949h-2.99247027v7.14612121h2.91062487c.7673039 0 1.4476365-.1483432 2.0410182-.445034s1.0511995-.7152915 1.3734671-1.2558144c.3222677-.540523.4833991-1.1603247.4833991-1.85942385 0-.68545815-.1602789-1.30270225-.4808414-1.85175082-.3205625-.54904856-.7707074-.97532211-1.3504481-1.27883343-.5797408-.30351132-1.2413173-.45526471-1.9847495-.45526471zm-.1892674 1.07933542c.7877654 0 1.4143875.22336734 1.8798852.67010873.4654977.44674138.698243 1.05546001.698243 1.82617415 0 .74343221-.2310402 1.34447791-.6931277 1.80315511-.4620874.4586773-1.0750688.6880124-1.8389625.6880124h-1.46810075v-4.98745039zm-5.08652545-3.71099194c-.21825533 0-.410525.08444276-.57681478.25333081-.16628977.16888806-.24943341.36245684-.24943341.58071218 0 .22345188.08314364.41961891.24943341.58850696.16628978.16888806.35855945.25333082.57681478.25333082.233845 0 .43390938-.08314364.60019916-.24943342.16628978-.16628977.24943342-.36375592.24943342-.59240436 0-.233845-.08314364-.43131115-.24943342-.59240437s-.36635416-.24163862-.60019916-.24163862z" fill-rule="evenodd"/></symbol><symbol id="icon-plus" viewBox="0 0 16 16"><path d="m2.00087166 7h4.99912834v-4.99912834c0-.55276616.44386482-1.00087166 1-1.00087166.55228475 0 1 .44463086 1 1.00087166v4.99912834h4.9991283c.5527662 0 1.0008717.44386482 1.0008717 1 0 .55228475-.4446309 1-1.0008717 1h-4.9991283v4.9991283c0 .5527662-.44386482 1.0008717-1 1.0008717-.55228475 0-1-.4446309-1-1.0008717v-4.9991283h-4.99912834c-.55276616 0-1.00087166-.44386482-1.00087166-1 0-.55228475.44463086-1 1.00087166-1z" fill-rule="evenodd"/></symbol><symbol id="icon-print" viewBox="0 0 18 18"><path d="m16.0049107 5h-14.00982141c-.54941618 0-.99508929.4467783-.99508929.99961498v6.00077002c0 .5570958.44271433.999615.99508929.999615h1.00491071v-3h12v3h1.0049107c.5494162 0 .9950893-.4467783.9950893-.999615v-6.00077002c0-.55709576-.4427143-.99961498-.9950893-.99961498zm-2.0049107-1v-2.00208688c0-.54777062-.4519464-.99791312-1.0085302-.99791312h-7.9829396c-.55661731 0-1.0085302.44910695-1.0085302.99791312v2.00208688zm1 10v2.0018986c0 1.103521-.9019504 1.9981014-2.0085302 1.9981014h-7.9829396c-1.1092806 0-2.0085302-.8867064-2.0085302-1.9981014v-2.0018986h-1.00491071c-1.10185739 0-1.99508929-.8874333-1.99508929-1.999615v-6.00077002c0-1.10435686.8926228-1.99961498 1.99508929-1.99961498h1.00491071v-2.00208688c0-1.10341695.90195036-1.99791312 2.0085302-1.99791312h7.9829396c1.1092806 0 2.0085302.89826062 2.0085302 1.99791312v2.00208688h1.0049107c1.1018574 0 1.9950893.88743329 1.9950893 1.99961498v6.00077002c0 1.1043569-.8926228 1.999615-1.9950893 1.999615zm-1-3h-10v5.0018986c0 .5546075.44702548.9981014 1.0085302.9981014h7.9829396c.5565964 0 1.0085302-.4491701 1.0085302-.9981014zm-9 1h8v1h-8zm0 2h5v1h-5zm9-5c-.5522847 0-1-.44771525-1-1s.4477153-1 1-1 1 .44771525 1 1-.4477153 1-1 1z" fill-rule="evenodd"/></symbol><symbol id="icon-search" viewBox="0 0 22 22"><path d="M21.697 20.261a1.028 1.028 0 01.01 1.448 1.034 1.034 0 01-1.448-.01l-4.267-4.267A9.812 9.811 0 010 9.812a9.812 9.811 0 1117.43 6.182zM9.812 18.222A8.41 8.41 0 109.81 1.403a8.41 8.41 0 000 16.82z" fill-rule="evenodd"/></symbol><symbol id="icon-social-facebook" viewBox="0 0 24 24"><path d="m6.00368507 20c-1.10660471 0-2.00368507-.8945138-2.00368507-1.9940603v-12.01187942c0-1.10128908.89451376-1.99406028 1.99406028-1.99406028h12.01187942c1.1012891 0 1.9940603.89451376 1.9940603 1.99406028v12.01187942c0 1.1012891-.88679 1.9940603-2.0032184 1.9940603h-2.9570132v-6.1960818h2.0797387l.3114113-2.414723h-2.39115v-1.54164807c0-.69911803.1941355-1.1755439 1.1966615-1.1755439l1.2786739-.00055875v-2.15974763l-.2339477-.02492088c-.3441234-.03134957-.9500153-.07025255-1.6293054-.07025255-1.8435726 0-3.1057323 1.12531866-3.1057323 3.19187953v1.78079225h-2.0850778v2.414723h2.0850778v6.1960818z" fill-rule="evenodd"/></symbol><symbol id="icon-social-twitter" viewBox="0 0 24 24"><path d="m18.8767135 6.87445248c.7638174-.46908424 1.351611-1.21167363 1.6250764-2.09636345-.7135248.43394112-1.50406.74870123-2.3464594.91677702-.6695189-.73342162-1.6297913-1.19486605-2.6922204-1.19486605-2.0399895 0-3.6933555 1.69603749-3.6933555 3.78628909 0 .29642457.0314329.58673729.0942985.8617704-3.06469922-.15890802-5.78835241-1.66547825-7.60988389-3.9574208-.3174714.56076194-.49978171 1.21167363-.49978171 1.90536824 0 1.31404706.65223085 2.47224203 1.64236444 3.15218497-.60350999-.0198635-1.17401554-.1925232-1.67222562-.47366811v.04583885c0 1.83355406 1.27302891 3.36609966 2.96411421 3.71294696-.31118484.0886217-.63651445.1329326-.97441718.1329326-.2357461 0-.47149219-.0229194-.69466516-.0672303.47149219 1.5065703 1.83253297 2.6036468 3.44975116 2.632678-1.2651707 1.0160946-2.85724264 1.6196394-4.5891906 1.6196394-.29861172 0-.59093688-.0152796-.88011875-.0504227 1.63450624 1.0726291 3.57548241 1.6990934 5.66104951 1.6990934 6.79263079 0 10.50641749-5.7711113 10.50641749-10.7751859l-.0094298-.48894775c.7229547-.53478659 1.3516109-1.20250585 1.8419628-1.96190282-.6632323.30100846-1.3751855.50422736-2.1217148.59590507z" fill-rule="evenodd"/></symbol><symbol id="icon-social-youtube" viewBox="0 0 24 24"><path d="m10.1415 14.3973208-.0005625-5.19318431 4.863375 2.60554491zm9.963-7.92753362c-.6845625-.73643756-1.4518125-.73990314-1.803375-.7826454-2.518875-.18714178-6.2971875-.18714178-6.2971875-.18714178-.007875 0-3.7861875 0-6.3050625.18714178-.352125.04274226-1.1188125.04620784-1.8039375.7826454-.5394375.56084773-.7149375 1.8344515-.7149375 1.8344515s-.18 1.49597903-.18 2.99138042v1.4024082c0 1.495979.18 2.9913804.18 2.9913804s.1755 1.2736038.7149375 1.8344515c.685125.7364376 1.5845625.7133337 1.9850625.7901542 1.44.1420891 6.12.1859866 6.12.1859866s3.78225-.005776 6.301125-.1929178c.3515625-.0433198 1.1188125-.0467854 1.803375-.783223.5394375-.5608477.7155-1.8344515.7155-1.8344515s.18-1.4954014.18-2.9913804v-1.4024082c0-1.49540139-.18-2.99138042-.18-2.99138042s-.1760625-1.27360377-.7155-1.8344515z" fill-rule="evenodd"/></symbol><symbol id="icon-subject-medicine" viewBox="0 0 18 18"><path d="m12.5 8h-6.5c-1.65685425 0-3 1.34314575-3 3v1c0 1.6568542 1.34314575 3 3 3h1v-2h-.5c-.82842712 0-1.5-.6715729-1.5-1.5s.67157288-1.5 1.5-1.5h1.5 2 1 2c1.6568542 0 3-1.34314575 3-3v-1c0-1.65685425-1.3431458-3-3-3h-2v2h1.5c.8284271 0 1.5.67157288 1.5 1.5s-.6715729 1.5-1.5 1.5zm-5.5-1v-1h-3.5c-1.38071187 0-2.5-1.11928813-2.5-2.5s1.11928813-2.5 2.5-2.5h1.02786405c.46573528 0 .92507448.10843528 1.34164078.31671843l1.13382424.56691212c.06026365-1.05041141.93116291-1.88363055 1.99667093-1.88363055 1.1045695 0 2 .8954305 2 2h2c2.209139 0 4 1.790861 4 4v1c0 2.209139-1.790861 4-4 4h-2v1h2c1.1045695 0 2 .8954305 2 2s-.8954305 2-2 2h-2c0 1.1045695-.8954305 2-2 2s-2-.8954305-2-2h-1c-2.209139 0-4-1.790861-4-4v-1c0-2.209139 1.790861-4 4-4zm0-2v-2.05652691c-.14564246-.03538148-.28733393-.08714006-.42229124-.15461871l-1.15541752-.57770876c-.27771087-.13885544-.583937-.21114562-.89442719-.21114562h-1.02786405c-.82842712 0-1.5.67157288-1.5 1.5s.67157288 1.5 1.5 1.5zm4 1v1h1.5c.2761424 0 .5-.22385763.5-.5s-.2238576-.5-.5-.5zm-1 1v-5c0-.55228475-.44771525-1-1-1s-1 .44771525-1 1v5zm-2 4v5c0 .5522847.44771525 1 1 1s1-.4477153 1-1v-5zm3 2v2h2c.5522847 0 1-.4477153 1-1s-.4477153-1-1-1zm-4-1v-1h-.5c-.27614237 0-.5.2238576-.5.5s.22385763.5.5.5zm-3.5-9h1c.27614237 0 .5.22385763.5.5s-.22385763.5-.5.5h-1c-.27614237 0-.5-.22385763-.5-.5s.22385763-.5.5-.5z" fill-rule="evenodd"/></symbol><symbol id="icon-success" viewBox="0 0 18 18"><path d="m9 0c4.9705627 0 9 4.02943725 9 9 0 4.9705627-4.0294373 9-9 9-4.97056275 0-9-4.0294373-9-9 0-4.97056275 4.02943725-9 9-9zm3.4860198 4.98163161-4.71802968 5.50657859-2.62834168-2.02300024c-.42862421-.36730544-1.06564993-.30775346-1.42283677.13301307-.35718685.44076653-.29927542 1.0958383.12934879 1.46314377l3.40735508 2.7323063c.42215801.3385221 1.03700951.2798252 1.38749189-.1324571l5.38450527-6.33394549c.3613513-.43716226.3096573-1.09278382-.115462-1.46437175-.4251192-.37158792-1.0626796-.31842941-1.4240309.11873285z" fill-rule="evenodd"/></symbol><symbol id="icon-table" viewBox="0 0 18 18"><path d="m16.0049107 2c1.1018574 0 1.9950893.89706013 1.9950893 2.00585866v9.98828264c0 1.1078052-.8926228 2.0058587-1.9950893 2.0058587l-4.0059107-.001.001.001h-1l-.001-.001h-5l.001.001h-1l-.001-.001-3.00391071.001c-1.10185739 0-1.99508929-.8970601-1.99508929-2.0058587v-9.98828264c0-1.10780515.8926228-2.00585866 1.99508929-2.00585866zm-11.0059107 5h-3.999v6.9941413c0 .5572961.44630695 1.0058587.99508929 1.0058587h3.00391071zm6 0h-5v8h5zm5.0059107-4h-4.0059107v3h5.001v1h-5.001v7.999l4.0059107.001c.5487152 0 .9950893-.4488783.9950893-1.0058587v-9.98828264c0-.55729607-.446307-1.00585866-.9950893-1.00585866zm-12.5049107 9c.27614237 0 .5.2238576.5.5s-.22385763.5-.5.5h-1c-.27614237 0-.5-.2238576-.5-.5s.22385763-.5.5-.5zm12 0c.2761424 0 .5.2238576.5.5s-.2238576.5-.5.5h-2c-.2761424 0-.5-.2238576-.5-.5s.2238576-.5.5-.5zm-6 0c.27614237 0 .5.2238576.5.5s-.22385763.5-.5.5h-2c-.27614237 0-.5-.2238576-.5-.5s.22385763-.5.5-.5zm-6-2c.27614237 0 .5.2238576.5.5s-.22385763.5-.5.5h-1c-.27614237 0-.5-.2238576-.5-.5s.22385763-.5.5-.5zm12 0c.2761424 0 .5.2238576.5.5s-.2238576.5-.5.5h-2c-.2761424 0-.5-.2238576-.5-.5s.2238576-.5.5-.5zm-6 0c.27614237 0 .5.2238576.5.5s-.22385763.5-.5.5h-2c-.27614237 0-.5-.2238576-.5-.5s.22385763-.5.5-.5zm-6-2c.27614237 0 .5.22385763.5.5s-.22385763.5-.5.5h-1c-.27614237 0-.5-.22385763-.5-.5s.22385763-.5.5-.5zm12 0c.2761424 0 .5.22385763.5.5s-.2238576.5-.5.5h-2c-.2761424 0-.5-.22385763-.5-.5s.2238576-.5.5-.5zm-6 0c.27614237 0 .5.22385763.5.5s-.22385763.5-.5.5h-2c-.27614237 0-.5-.22385763-.5-.5s.22385763-.5.5-.5zm1.499-5h-5v3h5zm-6 0h-3.00391071c-.54871518 0-.99508929.44887827-.99508929 1.00585866v1.99414134h3.999z" fill-rule="evenodd"/></symbol><symbol id="icon-tick-circle" viewBox="0 0 24 24"><path d="m12 2c5.5228475 0 10 4.4771525 10 10s-4.4771525 10-10 10-10-4.4771525-10-10 4.4771525-10 10-10zm0 1c-4.97056275 0-9 4.02943725-9 9 0 4.9705627 4.02943725 9 9 9 4.9705627 0 9-4.0294373 9-9 0-4.97056275-4.0294373-9-9-9zm4.2199868 5.36606669c.3613514-.43716226.9989118-.49032077 1.424031-.11873285s.4768133 1.02720949.115462 1.46437175l-6.093335 6.94397871c-.3622945.4128716-.9897871.4562317-1.4054264.0971157l-3.89719065-3.3672071c-.42862421-.3673054-.48653564-1.0223772-.1293488-1.4631437s.99421256-.5003185 1.42283677-.1330131l3.11097438 2.6987741z" fill-rule="evenodd"/></symbol><symbol id="icon-tick" viewBox="0 0 16 16"><path d="m6.76799012 9.21106946-3.1109744-2.58349728c-.42862421-.35161617-1.06564993-.29460792-1.42283677.12733148s-.29927541 1.04903009.1293488 1.40064626l3.91576307 3.23873978c.41034319.3393961 1.01467563.2976897 1.37450571-.0948578l6.10568327-6.660841c.3613513-.41848908.3096572-1.04610608-.115462-1.4018218-.4251192-.35571573-1.0626796-.30482786-1.424031.11366122z" fill-rule="evenodd"/></symbol><symbol id="icon-update" viewBox="0 0 18 18"><path d="m1 13v1c0 .5522847.44771525 1 1 1h14c.5522847 0 1-.4477153 1-1v-1h-1v-10h-14v10zm16-1h1v2c0 1.1045695-.8954305 2-2 2h-14c-1.1045695 0-2-.8954305-2-2v-2h1v-9c0-.55228475.44771525-1 1-1h14c.5522847 0 1 .44771525 1 1zm-1 0v1h-4.5857864l-1 1h-2.82842716l-1-1h-4.58578644v-1h5l1 1h2l1-1zm-13-8h12v7h-12zm1 1v5h10v-5zm1 1h4v1h-4zm0 2h4v1h-4z" fill-rule="evenodd"/></symbol><symbol id="icon-upload" viewBox="0 0 18 18"><path d="m10.0046024 0c.5497429 0 1.3179837.32258606 1.707238.71184039l4.5763192 4.57631922c.3931386.39313859.7118404 1.16760135.7118404 1.71431368v8.98899651c0 1.1092806-.8945138 2.0085302-1.9940603 2.0085302h-12.01187942c-1.10128908 0-1.99406028-.8926228-1.99406028-1.9950893v-14.00982141c0-1.10185739.88743329-1.99508929 1.99961498-1.99508929zm0 1h-7.00498742c-.55709576 0-.99961498.44271433-.99961498.99508929v14.00982141c0 .5500396.44491393.9950893.99406028.9950893h12.01187942c.5463747 0 .9940603-.4506622.9940603-1.0085302v-8.98899651c0-.28393444-.2150684-.80332809-.4189472-1.0072069l-4.5763192-4.57631922c-.2038461-.20384606-.718603-.41894717-1.0001312-.41894717zm-1.85576936 4.14572769c.19483374-.19483375.51177826-.19377714.70556874.00001334l2.59099082 2.59099079c.1948411.19484112.1904373.51514474.0027906.70279143-.1932998.19329987-.5046517.19237083-.7001856-.00692852l-1.74638687-1.7800176v6.14827687c0 .2717771-.23193359.492096-.5.492096-.27614237 0-.5-.216372-.5-.492096v-6.14827641l-1.74627892 1.77990922c-.1933927.1971171-.51252214.19455839-.70016883.0069117-.19329987-.19329988-.19100584-.50899493.00277731-.70277808z" fill-rule="evenodd"/></symbol><symbol id="icon-video" viewBox="0 0 18 18"><path d="m16.0049107 2c1.1018574 0 1.9950893.89706013 1.9950893 2.00585866v9.98828264c0 1.1078052-.8926228 2.0058587-1.9950893 2.0058587h-14.00982141c-1.10185739 0-1.99508929-.8970601-1.99508929-2.0058587v-9.98828264c0-1.10780515.8926228-2.00585866 1.99508929-2.00585866zm0 1h-14.00982141c-.54871518 0-.99508929.44887827-.99508929 1.00585866v9.98828264c0 .5572961.44630695 1.0058587.99508929 1.0058587h14.00982141c.5487152 0 .9950893-.4488783.9950893-1.0058587v-9.98828264c0-.55729607-.446307-1.00585866-.9950893-1.00585866zm-8.30912922 2.24944486 4.60460462 2.73982242c.9365543.55726659.9290753 1.46522435 0 2.01804082l-4.60460462 2.7398224c-.93655425.5572666-1.69578148.1645632-1.69578148-.8937585v-5.71016863c0-1.05087579.76670616-1.446575 1.69578148-.89375851zm-.67492769.96085624v5.5750128c0 .2995102-.10753745.2442517.16578928.0847713l4.58452283-2.67497259c.3050619-.17799716.3051624-.21655446 0-.39461026l-4.58452283-2.67497264c-.26630747-.15538481-.16578928-.20699944-.16578928.08477139z" fill-rule="evenodd"/></symbol><symbol id="icon-warning" viewBox="0 0 18 18"><path d="m9 11.75c.69035594 0 1.25.5596441 1.25 1.25s-.55964406 1.25-1.25 1.25-1.25-.5596441-1.25-1.25.55964406-1.25 1.25-1.25zm.41320045-7.75c.55228475 0 1.00000005.44771525 1.00000005 1l-.0034543.08304548-.3333333 4c-.043191.51829212-.47645714.91695452-.99654578.91695452h-.15973424c-.52008864 0-.95335475-.3986624-.99654576-.91695452l-.33333333-4c-.04586475-.55037702.36312325-1.03372649.91350028-1.07959124l.04148683-.00259031zm-.41320045 14c-4.97056275 0-9-4.0294373-9-9 0-4.97056275 4.02943725-9 9-9 4.9705627 0 9 4.02943725 9 9 0 4.9705627-4.0294373 9-9 9z" fill-rule="evenodd"/></symbol><symbol id="icon-checklist-banner" viewBox="0 0 56.69 56.69"><path style="fill:none" d="M0 0h56.69v56.69H0z"/><clipPath id="b"><use xlink:href="#a" style="overflow:visible"/></clipPath><path d="M21.14 34.46c0-6.77 5.48-12.26 12.24-12.26s12.24 5.49 12.24 12.26-5.48 12.26-12.24 12.26c-6.76-.01-12.24-5.49-12.24-12.26zm19.33 10.66 10.23 9.22s1.21 1.09 2.3-.12l2.09-2.32s1.09-1.21-.12-2.3l-10.23-9.22m-19.29-5.92c0-4.38 3.55-7.94 7.93-7.94s7.93 3.55 7.93 7.94c0 4.38-3.55 7.94-7.93 7.94-4.38-.01-7.93-3.56-7.93-7.94zm17.58 12.99 4.14-4.81" style="clip-path:url(#b);fill:none;stroke:#01324b;stroke-width:2;stroke-linecap:round"/><path d="M8.26 9.75H28.6M8.26 15.98H28.6m-20.34 6.2h12.5m14.42-5.2V4.86s0-2.93-2.93-2.93H4.13s-2.93 0-2.93 2.93v37.57s0 2.93 2.93 2.93h15.01M8.26 9.75H28.6M8.26 15.98H28.6m-20.34 6.2h12.5" style="clip-path:url(#b);fill:none;stroke:#01324b;stroke-width:2;stroke-linecap:round;stroke-linejoin:round"/></symbol><symbol id="icon-chevron-down" viewBox="0 0 16 16"><path d="m5.58578644 3-3.29289322-3.29289322c-.39052429-.39052429-.39052429-1.02368927 0-1.41421356s1.02368927-.39052429 1.41421356 0l4 4c.39052429.39052429.39052429 1.02368927 0 1.41421356l-4 4c-.39052429.39052429-1.02368927.39052429-1.41421356 0s-.39052429-1.02368927 0-1.41421356z" fill-rule="evenodd" transform="matrix(0 1 -1 0 11 1)"/></symbol><symbol id="icon-eds-i-arrow-right-medium" viewBox="0 0 24 24"><path d="m12.728 3.293 7.98 7.99a.996.996 0 0 1 .281.561l.011.157c0 .32-.15.605-.384.788l-7.908 7.918a1 1 0 0 1-1.416-1.414L17.576 13H4a1 1 0 0 1 0-2h13.598l-6.285-6.293a1 1 0 0 1-.082-1.32l.083-.095a1 1 0 0 1 1.414.001Z"/></symbol><symbol id="icon-eds-i-check-circle-medium" viewBox="0 0 24 24"><path d="M12 1c6.075 0 11 4.925 11 11s-4.925 11-11 11S1 18.075 1 12 5.925 1 12 1Zm0 2a9 9 0 1 0 0 18 9 9 0 0 0 0-18Zm5.125 4.72a1 1 0 0 1 .156 1.405l-6 7.5a1 1 0 0 1-1.421.143l-3-2.5a1 1 0 0 1 1.28-1.536l2.217 1.846 5.362-6.703a1 1 0 0 1 1.406-.156Z"/></symbol><symbol id="icon-eds-i-chevron-down-medium" viewBox="0 0 16 16"><path d="m2.00087166 7h4.99912834v-4.99912834c0-.55276616.44386482-1.00087166 1-1.00087166.55228475 0 1 .44463086 1 1.00087166v4.99912834h4.9991283c.5527662 0 1.0008717.44386482 1.0008717 1 0 .55228475-.4446309 1-1.0008717 1h-4.9991283v4.9991283c0 .5527662-.44386482 1.0008717-1 1.0008717-.55228475 0-1-.4446309-1-1.0008717v-4.9991283h-4.99912834c-.55276616 0-1.00087166-.44386482-1.00087166-1 0-.55228475.44463086-1 1.00087166-1z" fill-rule="evenodd"/></symbol><symbol id="icon-eds-i-chevron-down-small" viewBox="0 0 16 16"><path d="M13.692 5.278a1 1 0 0 1 .03 1.414L9.103 11.51a1.491 1.491 0 0 1-2.188.019L2.278 6.692a1 1 0 0 1 1.444-1.384L8 9.771l4.278-4.463a1 1 0 0 1 1.318-.111l.096.081Z"/></symbol><symbol id="icon-eds-i-chevron-right-medium" viewBox="0 0 10 10"><path d="m5.96738168 4.70639573 2.39518594-2.41447274c.37913917-.38219212.98637524-.38972225 1.35419292-.01894278.37750606.38054586.37784436.99719163-.00013556 1.37821513l-4.03074001 4.06319683c-.37758093.38062133-.98937525.38100976-1.367372-.00003075l-4.03091981-4.06337806c-.37759778-.38063832-.38381821-.99150444-.01600053-1.3622839.37750607-.38054587.98772445-.38240057 1.37006824.00302197l2.39538588 2.4146743.96295325.98624457z" fill-rule="evenodd" transform="matrix(0 -1 1 0 0 10)"/></symbol><symbol id="icon-eds-i-chevron-right-small" viewBox="0 0 10 10"><path d="m5.96738168 4.70639573 2.39518594-2.41447274c.37913917-.38219212.98637524-.38972225 1.35419292-.01894278.37750606.38054586.37784436.99719163-.00013556 1.37821513l-4.03074001 4.06319683c-.37758093.38062133-.98937525.38100976-1.367372-.00003075l-4.03091981-4.06337806c-.37759778-.38063832-.38381821-.99150444-.01600053-1.3622839.37750607-.38054587.98772445-.38240057 1.37006824.00302197l2.39538588 2.4146743.96295325.98624457z" fill-rule="evenodd" transform="matrix(0 -1 1 0 0 10)"/></symbol><symbol id="icon-eds-i-chevron-up-medium" viewBox="0 0 16 16"><path d="m2.00087166 7h11.99825664c.5527662 0 1.0008717.44386482 1.0008717 1 0 .55228475-.4446309 1-1.0008717 1h-11.99825664c-.55276616 0-1.00087166-.44386482-1.00087166-1 0-.55228475.44463086-1 1.00087166-1z" fill-rule="evenodd"/></symbol><symbol id="icon-eds-i-close-medium" viewBox="0 0 24 24"><path d="M12 1c6.075 0 11 4.925 11 11s-4.925 11-11 11S1 18.075 1 12 5.925 1 12 1Zm0 2a9 9 0 1 0 0 18 9 9 0 0 0 0-18ZM8.707 7.293 12 10.585l3.293-3.292a1 1 0 0 1 1.414 1.414L13.415 12l3.292 3.293a1 1 0 0 1-1.414 1.414L12 13.415l-3.293 3.292a1 1 0 1 1-1.414-1.414L10.585 12 7.293 8.707a1 1 0 0 1 1.414-1.414Z"/></symbol><symbol id="icon-eds-i-copy-link" viewBox="0 0 24 24"><path fill-rule="evenodd" clip-rule="evenodd" d="M19.4594 8.57015C19.0689 8.17963 19.0689 7.54646 19.4594 7.15594L20.2927 6.32261C20.2927 6.32261 20.2927 6.32261 20.2927 6.32261C21.0528 5.56252 21.0528 4.33019 20.2928 3.57014C19.5327 2.81007 18.3004 2.81007 17.5404 3.57014L16.7071 4.40347C16.3165 4.794 15.6834 4.794 15.2928 4.40348C14.9023 4.01296 14.9023 3.3798 15.2928 2.98927L16.1262 2.15594C17.6673 0.614803 20.1659 0.614803 21.707 2.15593C23.2481 3.69705 23.248 6.19569 21.707 7.7368L20.8737 8.57014C20.4831 8.96067 19.85 8.96067 19.4594 8.57015Z"/><path fill-rule="evenodd" clip-rule="evenodd" d="M18.0944 5.90592C18.4849 6.29643 18.4849 6.9296 18.0944 7.32013L16.4278 8.9868C16.0373 9.37733 15.4041 9.37734 15.0136 8.98682C14.6231 8.59631 14.6231 7.96314 15.0136 7.57261L16.6802 5.90594C17.0707 5.51541 17.7039 5.5154 18.0944 5.90592Z"/><path fill-rule="evenodd" clip-rule="evenodd" d="M13.5113 6.32243C13.9018 6.71295 13.9018 7.34611 13.5113 7.73664L12.678 8.56997C12.678 8.56997 12.678 8.56997 12.678 8.56997C11.9179 9.33006 11.9179 10.5624 12.6779 11.3224C13.438 12.0825 14.6703 12.0825 15.4303 11.3224L16.2636 10.4891C16.6542 10.0986 17.2873 10.0986 17.6779 10.4891C18.0684 10.8796 18.0684 11.5128 17.6779 11.9033L16.8445 12.7366C15.3034 14.2778 12.8048 14.2778 11.2637 12.7366C9.72262 11.1955 9.72266 8.69689 11.2637 7.15578L12.097 6.32244C12.4876 5.93191 13.1207 5.93191 13.5113 6.32243Z"/><path d="M8 20V22H19.4619C20.136 22 20.7822 21.7311 21.2582 21.2529C21.7333 20.7757 22 20.1289 22 19.4549V15C22 14.4477 21.5523 14 21 14C20.4477 14 20 14.4477 20 15V19.4549C20 19.6004 19.9426 19.7397 19.8408 19.842C19.7399 19.9433 19.6037 20 19.4619 20H8Z"/><path d="M4 13H2V19.4619C2 20.136 2.26889 20.7822 2.74705 21.2582C3.22434 21.7333 3.87105 22 4.5451 22H9C9.55228 22 10 21.5523 10 21C10 20.4477 9.55228 20 9 20H4.5451C4.39957 20 4.26028 19.9426 4.15804 19.8408C4.05668 19.7399 4 19.6037 4 19.4619V13Z"/><path d="M4 13H2V4.53808C2 3.86398 2.26889 3.21777 2.74705 2.74178C3.22434 2.26666 3.87105 2 4.5451 2H9C9.55228 2 10 2.44772 10 3C10 3.55228 9.55228 4 9 4H4.5451C4.39957 4 4.26028 4.05743 4.15804 4.15921C4.05668 4.26011 4 4.39633 4 4.53808V13Z"/></symbol><symbol id="icon-eds-i-download-medium" viewBox="0 0 16 16"><path d="m12.9975267 12.999368c.5467123 0 1.0024733.4478567 1.0024733 1.000316 0 .5563109-.4488226 1.000316-1.0024733 1.000316h-9.99505341c-.54671233 0-1.00247329-.4478567-1.00247329-1.000316 0-.5563109.44882258-1.000316 1.00247329-1.000316zm-4.9975267-11.999368c.55228475 0 1 .44497754 1 .99589209v6.80214418l2.4816273-2.48241149c.3928222-.39294628 1.0219732-.4006883 1.4030652-.01947579.3911302.39125371.3914806 1.02525073-.0001404 1.41699553l-4.17620792 4.17752758c-.39120769.3913313-1.02508144.3917306-1.41671995-.0000316l-4.17639421-4.17771394c-.39122513-.39134876-.39767006-1.01940351-.01657797-1.40061601.39113012-.39125372 1.02337105-.3931606 1.41951349.00310701l2.48183446 2.48261871v-6.80214418c0-.55001601.44386482-.99589209 1-.99589209z" fill-rule="evenodd"/></symbol><symbol id="icon-eds-i-info-filled-medium" viewBox="0 0 18 18"><path d="m9 0c4.9705627 0 9 4.02943725 9 9 0 4.9705627-4.0294373 9-9 9-4.97056275 0-9-4.0294373-9-9 0-4.97056275 4.02943725-9 9-9zm0 7h-1.5l-.11662113.00672773c-.49733868.05776511-.88337887.48043643-.88337887.99327227 0 .47338693.32893365.86994729.77070917.97358929l.1126697.01968298.11662113.00672773h.5v3h-.5l-.11662113.0067277c-.42082504.0488782-.76196299.3590206-.85696816.7639815l-.01968298.1126697-.00672773.1166211.00672773.1166211c.04887817.4208251.35902055.761963.76398144.8569682l.1126697.019683.11662113.0067277h3l.1166211-.0067277c.4973387-.0577651.8833789-.4804365.8833789-.9932723 0-.4733869-.3289337-.8699473-.7707092-.9735893l-.1126697-.019683-.1166211-.0067277h-.5v-4l-.00672773-.11662113c-.04887817-.42082504-.35902055-.76196299-.76398144-.85696816l-.1126697-.01968298zm0-3.25c-.69035594 0-1.25.55964406-1.25 1.25s.55964406 1.25 1.25 1.25 1.25-.55964406 1.25-1.25-.55964406-1.25-1.25-1.25z" fill-rule="evenodd"/></symbol><symbol id="icon-eds-i-institution-medium" viewBox="0 0 24 24"><g><path fill-rule="evenodd" clip-rule="evenodd" d="M11.9967 1C11.6364 1 11.279 1.0898 10.961 1.2646C10.9318 1.28061 10.9035 1.29806 10.8761 1.31689L2.79765 6.87C2.46776 7.08001 2.20618 7.38466 2.07836 7.76668C1.94823 8.15561 1.98027 8.55648 2.12665 8.90067C2.42086 9.59246 3.12798 10 3.90107 10H4.99994V16H4.49994C3.11923 16 1.99994 17.1193 1.99994 18.5V19.5C1.99994 20.8807 3.11923 22 4.49994 22H19.4999C20.8807 22 21.9999 20.8807 21.9999 19.5V18.5C21.9999 17.1193 20.8807 16 19.4999 16H18.9999V10H20.0922C20.8653 10 21.5725 9.59252 21.8667 8.90065C22.0131 8.55642 22.0451 8.15553 21.9149 7.7666C21.7871 7.38459 21.5255 7.07997 21.1956 6.86998L13.1172 1.31689C13.0898 1.29806 13.0615 1.28061 13.0324 1.2646C12.7143 1.0898 12.357 1 11.9967 1ZM4.6844 8L11.9472 3.00755C11.9616 3.00295 11.9783 3 11.9967 3C12.015 3 12.0318 3.00295 12.0461 3.00755L19.3089 8H4.6844ZM16.9999 16V10H14.9999V16H16.9999ZM12.9999 16V10H10.9999V16H12.9999ZM8.99994 16V10H6.99994V16H8.99994ZM3.99994 18.5C3.99994 18.2239 4.2238 18 4.49994 18H19.4999C19.7761 18 19.9999 18.2239 19.9999 18.5V19.5C19.9999 19.7761 19.7761 20 19.4999 20H4.49994C4.2238 20 3.99994 19.7761 3.99994 19.5V18.5Z"/></g></symbol><symbol id="icon-eds-i-mail-medium" viewBox="0 0 22 18"><path d="m19.462 0c1.413 0 2.538 1.184 2.538 2.619v12.762c0 1.435-1.125 2.619-2.538 2.619h-16.924c-1.413 0-2.538-1.184-2.538-2.619v-12.762c0-1.435 1.125-2.619 2.538-2.619zm.538 5.158-7.378 6.258a2.549 2.549 0 0 1 -3.253-.008l-7.369-6.248v10.222c0 .353.253.619.538.619h16.924c.285 0 .538-.266.538-.619zm-.538-3.158h-16.924c-.264 0-.5.228-.534.542l8.65 7.334c.2.165.492.165.684.007l8.656-7.342-.001-.025c-.044-.3-.274-.516-.531-.516z"/></symbol><symbol id="icon-eds-i-menu-medium" viewBox="0 0 24 24"><path d="M21 4a1 1 0 0 1 0 2H3a1 1 0 1 1 0-2h18Zm-4 7a1 1 0 0 1 0 2H3a1 1 0 0 1 0-2h14Zm4 7a1 1 0 0 1 0 2H3a1 1 0 0 1 0-2h18Z"/></symbol><symbol id="icon-eds-i-search-medium" viewBox="0 0 24 24"><path d="M11 1c5.523 0 10 4.477 10 10 0 2.4-.846 4.604-2.256 6.328l3.963 3.965a1 1 0 0 1-1.414 1.414l-3.965-3.963A9.959 9.959 0 0 1 11 21C5.477 21 1 16.523 1 11S5.477 1 11 1Zm0 2a8 8 0 1 0 0 16 8 8 0 0 0 0-16Z"/></symbol><symbol id="icon-eds-i-user-single-medium" viewBox="0 0 24 24"><path d="M12 1a5 5 0 1 1 0 10 5 5 0 0 1 0-10Zm0 2a3 3 0 1 0 0 6 3 3 0 0 0 0-6Zm-.406 9.008a8.965 8.965 0 0 1 6.596 2.494A9.161 9.161 0 0 1 21 21.025V22a1 1 0 0 1-1 1H4a1 1 0 0 1-1-1v-.985c.05-4.825 3.815-8.777 8.594-9.007Zm.39 1.992-.299.006c-3.63.175-6.518 3.127-6.678 6.775L5 21h13.998l-.009-.268a7.157 7.157 0 0 0-1.97-4.573l-.214-.213A6.967 6.967 0 0 0 11.984 14Z"/></symbol><symbol id="icon-eds-i-warning-filled-medium" viewBox="0 0 18 18"><path d="m9 11.75c.69035594 0 1.25.5596441 1.25 1.25s-.55964406 1.25-1.25 1.25-1.25-.5596441-1.25-1.25.55964406-1.25 1.25-1.25zm.41320045-7.75c.55228475 0 1.00000005.44771525 1.00000005 1l-.0034543.08304548-.3333333 4c-.043191.51829212-.47645714.91695452-.99654578.91695452h-.15973424c-.52008864 0-.95335475-.3986624-.99654576-.91695452l-.33333333-4c-.04586475-.55037702.36312325-1.03372649.91350028-1.07959124l.04148683-.00259031zm-.41320045 14c-4.97056275 0-9-4.0294373-9-9 0-4.97056275 4.02943725-9 9-9 4.9705627 0 9 4.02943725 9 9 0 4.9705627-4.0294373 9-9 9z" fill-rule="evenodd"/></symbol><symbol id="icon-expand-image" viewBox="0 0 18 18"><path d="m7.49754099 11.9178212c.38955542-.3895554.38761957-1.0207846-.00290473-1.4113089-.39324695-.3932469-1.02238878-.3918247-1.41130883-.0029047l-4.10273549 4.1027355.00055454-3.5103985c.00008852-.5603185-.44832171-1.006032-1.00155062-1.0059446-.53903074.0000852-.97857527.4487442-.97866268 1.0021075l-.00093318 5.9072465c-.00008751.553948.44841131 1.001882 1.00174994 1.0017946l5.906983-.0009331c.5539233-.0000875 1.00197907-.4486389 1.00206646-1.0018679.00008515-.5390307-.45026621-.9784332-1.00588841-.9783454l-3.51010549.0005545zm3.00571741-5.83449376c-.3895554.38955541-.3876196 1.02078454.0029047 1.41130883.393247.39324696 1.0223888.39182478 1.4113089.00290473l4.1027355-4.10273549-.0005546 3.5103985c-.0000885.56031852.4483217 1.006032 1.0015506 1.00594461.5390308-.00008516.9785753-.44874418.9786627-1.00210749l.0009332-5.9072465c.0000875-.553948-.4484113-1.00188204-1.0017499-1.00179463l-5.906983.00093313c-.5539233.00008751-1.0019791.44863892-1.0020665 1.00186784-.0000852.53903074.4502662.97843325 1.0058884.97834547l3.5101055-.00055449z" fill-rule="evenodd"/></symbol><symbol id="icon-github" viewBox="0 0 100 100"><path fill-rule="evenodd" clip-rule="evenodd" d="M48.854 0C21.839 0 0 22 0 49.217c0 21.756 13.993 40.172 33.405 46.69 2.427.49 3.316-1.059 3.316-2.362 0-1.141-.08-5.052-.08-9.127-13.59 2.934-16.42-5.867-16.42-5.867-2.184-5.704-5.42-7.17-5.42-7.17-4.448-3.015.324-3.015.324-3.015 4.934.326 7.523 5.052 7.523 5.052 4.367 7.496 11.404 5.378 14.235 4.074.404-3.178 1.699-5.378 3.074-6.6-10.839-1.141-22.243-5.378-22.243-24.283 0-5.378 1.94-9.778 5.014-13.2-.485-1.222-2.184-6.275.486-13.038 0 0 4.125-1.304 13.426 5.052a46.97 46.97 0 0 1 12.214-1.63c4.125 0 8.33.571 12.213 1.63 9.302-6.356 13.427-5.052 13.427-5.052 2.67 6.763.97 11.816.485 13.038 3.155 3.422 5.015 7.822 5.015 13.2 0 18.905-11.404 23.06-22.324 24.283 1.78 1.548 3.316 4.481 3.316 9.126 0 6.6-.08 11.897-.08 13.526 0 1.304.89 2.853 3.316 2.364 19.412-6.52 33.405-24.935 33.405-46.691C97.707 22 75.788 0 48.854 0z"/></symbol><symbol id="icon-orcid-logo" viewBox="0 0 40 40"><path fill-rule="evenodd" d="M12.281 10.453c.875 0 1.578-.719 1.578-1.578 0-.86-.703-1.578-1.578-1.578-.875 0-1.578.703-1.578 1.578 0 .86.703 1.578 1.578 1.578Zm-1.203 18.641h2.406V12.359h-2.406v16.735Z"/><path fill-rule="evenodd" d="M17.016 12.36h6.5c6.187 0 8.906 4.421 8.906 8.374 0 4.297-3.36 8.375-8.875 8.375h-6.531V12.36Zm6.234 14.578h-3.828V14.53h3.703c4.688 0 6.828 2.844 6.828 6.203 0 2.063-1.25 6.203-6.703 6.203Z" clip-rule="evenodd"/></symbol><symbol id="icon-springer-arrow-left"><path d="M15 7a1 1 0 000-2H3.385l2.482-2.482a.994.994 0 00.02-1.403 1.001 1.001 0 00-1.417 0L.294 5.292a1.001 1.001 0 000 1.416l4.176 4.177a.991.991 0 001.4.016 1 1 0 00-.003-1.42L3.385 7H15z"/></symbol><symbol id="icon-springer-arrow-right"><path d="M1 7a1 1 0 010-2h11.615l-2.482-2.482a.994.994 0 01-.02-1.403 1.001 1.001 0 011.417 0l4.176 4.177a1.001 1.001 0 010 1.416l-4.176 4.177a.991.991 0 01-1.4.016 1 1 0 01.003-1.42L12.615 7H1z"/></symbol><symbol id="icon-submit-open" viewBox="0 0 16 17"><path d="M12 0c1.10457 0 2 .895431 2 2v5c0 .276142-.223858.5-.5.5S13 7.276142 13 7V2c0-.512836-.38604-.935507-.883379-.993272L12 1H6v3c0 1.10457-.89543 2-2 2H1v8c0 .512836.38604.935507.883379.993272L2 15h6.5c.276142 0 .5.223858.5.5s-.223858.5-.5.5H2c-1.104569 0-2-.89543-2-2V5.828427c0-.530433.210714-1.039141.585786-1.414213L4.414214.585786C4.789286.210714 5.297994 0 5.828427 0H12Zm3.41 11.14c.250899.250899.250274.659726 0 .91-.242954.242954-.649606.245216-.9-.01l-1.863671-1.900337.001043 5.869492c0 .356992-.289839.637138-.647372.637138-.347077 0-.647371-.285256-.647371-.637138l-.001043-5.869492L9.5 12.04c-.253166.258042-.649726.260274-.9.01-.242954-.242954-.252269-.657731 0-.91l2.942184-2.951303c.250908-.250909.66127-.252277.91353-.000017L15.41 11.14ZM5 1.413 1.413 5H4c.552285 0 1-.447715 1-1V1.413ZM11 3c.276142 0 .5.223858.5.5s-.223858.5-.5.5H7.5c-.276142 0-.5-.223858-.5-.5s.223858-.5.5-.5H11Zm0 2c.276142 0 .5.223858.5.5s-.223858.5-.5.5H7.5c-.276142 0-.5-.223858-.5-.5s.223858-.5.5-.5H11Z" fill-rule="nonzero"/></symbol></svg>
</div>
</footer>




    


    

<div class="c-site-messages message u-hide u-hide-print c-site-messages--nature-briefing c-site-messages--nature-briefing-email-variant c-site-messages--nature-briefing-redesign-2020 sans-serif c-site-messages--nature-briefing-transres"
data-component-id="nature-briefing-banner"
data-component-expirydays="30"
data-component-trigger-scroll-percentage="15"
data-track="in-view"
data-track-action="in-view"
data-track-category="nature briefing"
data-track-label="Briefing banner visible: TranslationalResearch">

    
    <div class="c-site-messages__banner-large">

        
<div class="c-site-messages__close-container">
    <button class="c-site-messages__close"
        data-track="click"
        data-track-category="nature briefing"
        data-track-label="Briefing banner dismiss: TranslationalResearch">
        <svg width="25px" height="25px" focusable="false" aria-hidden="true" viewBox="0 0 25 25" version="1.1" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink">
            <title>Close banner</title>
            <defs></defs>
            <g stroke="none" stroke-width="1" fill="none" fill-rule="evenodd">
                <rect opacity="0" x="0" y="0" width="25" height="25"></rect>
                <path d="M6.29679575,16.2772478 C5.90020818,16.6738354 5.90240728,17.3100587 6.29617427,17.7038257 C6.69268654,18.100338 7.32864195,18.0973145 7.72275218,17.7032043 L12,13.4259564 L16.2772478,17.7032043 C16.6738354,18.0997918 17.3100587,18.0975927 17.7038257,17.7038257 C18.100338,17.3073135 18.0973145,16.671358 17.7032043,16.2772478 L13.4259564,12 L17.7032043,7.72275218 C18.0997918,7.32616461 18.0975927,6.68994127 17.7038257,6.29617427 C17.3073135,5.89966201 16.671358,5.90268552 16.2772478,6.29679575 L12,10.5740436 L7.72275218,6.29679575 C7.32616461,5.90020818 6.68994127,5.90240728 6.29617427,6.29617427 C5.89966201,6.69268654 5.90268552,7.32864195 6.29679575,7.72275218 L10.5740436,12 L6.29679575,16.2772478 Z" fill="#ffffff"></path>
            </g>
        </svg>
        <span class="visually-hidden">Close</span>
    </button>
</div>


        <div class="c-site-messages__form-container">

            <div class="grid grid-12 last">
                <div class="grid grid-4">
                    <img alt="Nature Briefing: Translational Research" src="/static/images/logos/nature-briefing-logo-transres-white-1245a3c374.svg" width="213" height="40">
                    <p class="c-site-messages--nature-briefing__strapline extra-tight-line-height">Sign up for the <em>Nature Briefing: Translational Research</em> newsletter  top stories in biotechnology, drug discovery and pharma.</p>
                </div>
                <div class="grid grid-8 last">
                    <form action="https://www.nature.com/briefing/translational_research" method="post" data-location="banner" data-track="signup_nature_briefing_banner" data-track-action="transmit-form" data-track-category="nature briefing" data-track-label="Briefing banner submit: TranslationalResearch">
                        <input id="briefing-banner-signup-form-input-track-originReferralPoint" type="hidden" name="track_originReferralPoint" value="TransResBriefingBanner">
                        <input id="briefing-banner-signup-form-input-track-formType" type="hidden" name="track_formType" value="DirectEmailBanner">

                        <input type="hidden" value="false" name="gdpr_tick" id="gdpr_tick_banner">
                        <input type="hidden" value="false" name="marketing" id="marketing_input_banner">
                        <input type="hidden" value="false" name="marketing_tick" id="marketing_tick_banner">
                        <input type="hidden" value="TransResBriefingBanner" name="brieferEntryPoint" id="brieferEntryPoint_banner">

                        <label class="nature-briefing-banner__email-label" for="emailAddress">Email address</label>

                        <div class="nature-briefing-banner__email-wrapper">
                            <input class="nature-briefing-banner__email-input box-sizing text14" type="email" id="emailAddress" name="emailAddress" value="" placeholder="e.g. jo.smith@university.ac.uk" required data-test-element="briefing-emailbanner-email-input">
                            
                            <input type="hidden" value="true" name="N:translational_research" id="defaultNewsletter_banner">
                            <button type="submit" class="nature-briefing-banner__submit-button box-sizing text14" data-test-element="briefing-emailbanner-signup-button">Sign up</button>
                        </div>

                        <div class="nature-briefing-banner__checkbox-wrapper grid grid-12 last">
                            <input class="nature-briefing-banner__checkbox-checkbox" id="gdpr-briefing-banner-checkbox" type="checkbox" name="gdpr" value="true" data-test-element="briefing-emailbanner-gdpr-checkbox" required>
                            <label class="nature-briefing-banner__checkbox-label box-sizing text13 sans-serif block tighten-line-height" for="gdpr-briefing-banner-checkbox">I agree my information will be processed in accordance with the <em>Nature</em> and Springer Nature Limited <a href="https://www.nature.com/info/privacy">Privacy Policy</a>.</label>
                        </div>
                    </form>
                </div>
            </div>

        </div>

    </div>

    
    <div class="c-site-messages__banner-small">

        
<div class="c-site-messages__close-container">
    <button class="c-site-messages__close"
        data-track="click"
        data-track-category="nature briefing"
        data-track-label="Briefing banner dismiss: TranslationalResearch">
        <svg width="25px" height="25px" focusable="false" aria-hidden="true" viewBox="0 0 25 25" version="1.1" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink">
            <title>Close banner</title>
            <defs></defs>
            <g stroke="none" stroke-width="1" fill="none" fill-rule="evenodd">
                <rect opacity="0" x="0" y="0" width="25" height="25"></rect>
                <path d="M6.29679575,16.2772478 C5.90020818,16.6738354 5.90240728,17.3100587 6.29617427,17.7038257 C6.69268654,18.100338 7.32864195,18.0973145 7.72275218,17.7032043 L12,13.4259564 L16.2772478,17.7032043 C16.6738354,18.0997918 17.3100587,18.0975927 17.7038257,17.7038257 C18.100338,17.3073135 18.0973145,16.671358 17.7032043,16.2772478 L13.4259564,12 L17.7032043,7.72275218 C18.0997918,7.32616461 18.0975927,6.68994127 17.7038257,6.29617427 C17.3073135,5.89966201 16.671358,5.90268552 16.2772478,6.29679575 L12,10.5740436 L7.72275218,6.29679575 C7.32616461,5.90020818 6.68994127,5.90240728 6.29617427,6.29617427 C5.89966201,6.69268654 5.90268552,7.32864195 6.29679575,7.72275218 L10.5740436,12 L6.29679575,16.2772478 Z" fill="#ffffff"></path>
            </g>
        </svg>
        <span class="visually-hidden">Close</span>
    </button>
</div>


        <div class="c-site-messages__content text14">
            <span class="c-site-messages--nature-briefing__strapline strong">Get what matters in translational research, free to your inbox weekly.</span>
            <a class="nature-briefing__link text14 sans-serif"
                data-track="click"
                data-track-category="nature briefing"
                data-track-label="Small-screen banner CTA to site"
                data-test-element="briefing-banner-link"
                target="_blank"
                rel="noreferrer noopener"
                href="/briefing/translational-research/?brieferEntryPoint=TransResBriefingBanner">Sign up for Nature Briefing: Translational Research
            </a>
        </div>

    </div>

</div>

    




<noscript>
    <img hidden src="https://verify.nature.com/verify/nature.png" width="0" height="0" style="display: none" alt="">
</noscript>




<script src="//content.readcube.com/ping?doi=10.1038/s41551-022-00898-y&amp;format=js&amp;last_modified=2022-07-04" async></script>
</body>
</html>